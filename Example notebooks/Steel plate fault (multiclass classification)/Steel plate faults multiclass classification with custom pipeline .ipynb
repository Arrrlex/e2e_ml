{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Steel plate faults multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'titanic_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-07cd570fe3f4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0me2eml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclassification\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mclassification_blueprints\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mcb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0me2eml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfull_processing\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpostprocessing\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0msave_to_production\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mload_for_production\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0me2eml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclassification_blueprints_test\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0msteel_fault_multiclass_data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmatthews_corrcoef\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/IdeaProjects/e2e_ml/e2eml/test/classification_blueprints_test.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    165\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    166\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 167\u001B[0;31m \u001B[0mblueprint_binary_test_titanic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mblueprint\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'lgbm'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'titanic'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/IdeaProjects/e2e_ml/e2eml/test/classification_blueprints_test.py\u001B[0m in \u001B[0;36mblueprint_binary_test_titanic\u001B[0;34m(blueprint, dataset)\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mblueprint_binary_test_titanic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mblueprint\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'logistic_regression'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'titanic'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mdataset\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'titanic'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 102\u001B[0;31m         \u001B[0mtest_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_target\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_df_target\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_categorical_cols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mload_titanic_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    103\u001B[0m         titanic_auto_ml = cb.ClassificationBluePrint(datasource=test_df,\n\u001B[1;32m    104\u001B[0m                                        \u001B[0mtarget_variable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtest_target\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/IdeaProjects/e2e_ml/e2eml/test/classification_blueprints_test.py\u001B[0m in \u001B[0;36mload_titanic_data\u001B[0;34m()\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;34m:\u001B[0m\u001B[0;32mreturn\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mSeveral\u001B[0m \u001B[0mdataframes\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mseries\u001B[0m \u001B[0mto\u001B[0m \u001B[0mbe\u001B[0m \u001B[0mprocessed\u001B[0m \u001B[0mby\u001B[0m \u001B[0mblueprint\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m     \"\"\"\n\u001B[0;32m---> 15\u001B[0;31m     \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"titanic_train.csv\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Create additional features and modify existing ones.'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0mdeck\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m\"A\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"B\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"C\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"D\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"E\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"F\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m6\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"G\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m7\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"U\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m8\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/rapids-0.17/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[1;32m    686\u001B[0m     )\n\u001B[1;32m    687\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 688\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    689\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    690\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/rapids-0.17/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    453\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 454\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfp_or_buf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    455\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    456\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/rapids-0.17/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    946\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    947\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 948\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    949\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    950\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/rapids-0.17/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1178\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"c\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1179\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"c\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1180\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCParserWrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1181\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1182\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"python\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/rapids-0.17/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m   2008\u001B[0m         \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"usecols\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0musecols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2009\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2010\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparsers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTextReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2011\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2012\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'titanic_train.csv'"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "from e2eml.classification import classification_blueprints as cb\n",
    "from e2eml.full_processing.postprocessing import save_to_production, load_for_production\n",
    "from e2eml.test.classification_blueprints_test import steel_fault_multiclass_data\n",
    "import pandas as pd\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import classification_report\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "Load & preprocess steel faults dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load steel faults data\n",
    "test_df, test_target, val_df, val_df_target, test_categorical_cols = steel_fault_multiclass_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using e2eml - Run and save a pipeline\n",
    "In this notebook we configure a custom pipeline. Due to the object oriented approach we can easily set this up.\n",
    "Under the hood the main and mostly used blueprint pipeline looks like this:\n",
    "\n",
    "def pipeline(self):\n",
    "        logging.info('Start blueprint.')\n",
    "        try:\n",
    "            if df.empty:\n",
    "                skip_train = False\n",
    "            else:\n",
    "                self.dataframe = df\n",
    "                skip_train = True\n",
    "        except AttributeError:\n",
    "            skip_train = False\n",
    "        self.train_test_split(how=self.train_split_type)\n",
    "        self.datetime_converter(datetime_handling='all', force_conversion=False)\n",
    "        if preprocessing_type == 'nlp':\n",
    "            self.pos_tagging_pca()\n",
    "        self.rare_feature_processor(threshold=0.03, mask_as='miscellaneous')\n",
    "        self.cardinality_remover(threshold=100)\n",
    "        self.onehot_pca()\n",
    "        self.category_encoding(algorithm='target')\n",
    "        self.delete_high_null_cols(threshold=0.5)\n",
    "        self.fill_nulls(how='static')\n",
    "        self.data_binning(nb_bins=10)\n",
    "        #self.skewness_removal()\n",
    "        self.outlier_care(method='isolation', how='append')\n",
    "        self.remove_collinearity(threshold=0.8)\n",
    "        self.clustering_as_a_feature(algorithm='dbscan', eps=0.3, n_jobs=-1, min_samples=10)\n",
    "        for nb_cluster in range(2, 10):\n",
    "            self.clustering_as_a_feature(algorithm='kmeans', nb_clusters=nb_cluster)\n",
    "        if self.low_memory_mode:\n",
    "            self.reduce_memory_footprint()\n",
    "        self.automated_feature_selection(metric='logloss')\n",
    "        self.sort_columns_alphabetically()\n",
    "        if skip_train:\n",
    "            pass\n",
    "        else:\n",
    "            self.lgbm_train(tune_mode=self.tune_mode)\n",
    "        self.lgbm_predict(feat_importance=True)\n",
    "        self.classification_eval('lgbm')\n",
    "        self.prediction_mode = True\n",
    "        logging.info('Finished blueprint.')\n",
    "\n",
    "From here we can make custom choices by:\n",
    "- skipping steps\n",
    "- changing parameters\n",
    "- or even extend\n",
    "\n",
    "We follow these steps:\n",
    "- instantiate class\n",
    "- define and run pipeline\n",
    "- save and load pipeline\n",
    "- predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate class\n",
    "steel_faults_ml = cb.ClassificationBluePrint(datasource=test_df,\n",
    "                                       target_variable=test_target,\n",
    "                                       categorical_columns=test_categorical_cols,\n",
    "                                       preferred_training_mode='auto',\n",
    "                                       tune_mode='accurate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define custom pipeline...\n",
    "- Please note, that there are logical and technical dependencies. Not everything is possible.\n",
    "\"\"\"\n",
    "def custom_pipeline(df):\n",
    "    try:\n",
    "        if df.empty:\n",
    "            skip_train = False\n",
    "        else:\n",
    "            steel_faults_ml.dataframe = df\n",
    "            skip_train = True\n",
    "    except AttributeError:\n",
    "        skip_train = False\n",
    "    steel_faults_ml.train_test_split(how=steel_faults_ml.train_split_type)\n",
    "    steel_faults_ml.datetime_converter(datetime_handling='all', force_conversion=False)\n",
    "    steel_faults_ml.pos_tagging_pca()\n",
    "    # we removed rare feature processing\n",
    "    steel_faults_ml.cardinality_remover(threshold=100)\n",
    "    steel_faults_ml.onehot_pca()\n",
    "    steel_faults_ml.category_encoding(algorithm='target')\n",
    "    steel_faults_ml.delete_high_null_cols(threshold=0.5)\n",
    "    steel_faults_ml.fill_nulls(how='iterative') # we changed to iterative filling\n",
    "    steel_faults_ml.data_binning(nb_bins=20) # we change the bins\n",
    "    steel_faults_ml.outlier_care(method='isolation', how='append')\n",
    "    steel_faults_ml.remove_collinearity(threshold=0.8)\n",
    "    steel_faults_ml.clustering_as_a_feature(algorithm='GLMM', eps=0.3, n_jobs=-1, min_samples=10)\n",
    "    for nb_cluster in range(2, 20):\n",
    "        steel_faults_ml.clustering_as_a_feature(algorithm='kmeans', nb_clusters=nb_cluster)\n",
    "    steel_faults_ml.automated_feature_selection(metric='mlogloss') # needs to be xgboost compatible\n",
    "    steel_faults_ml.sort_columns_alphabetically()\n",
    "    if skip_train:\n",
    "        pass\n",
    "    else:\n",
    "        steel_faults_ml.lgbm_train(tune_mode=steel_faults_ml.tune_mode)\n",
    "    steel_faults_ml.lgbm_predict(feat_importance=True)\n",
    "    steel_faults_ml.classification_eval('lgbm')\n",
    "    steel_faults_ml.prediction_mode = True # mandatory\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run custom blueprint\n",
    "custom_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pipeline\n",
    "save_to_production(steel_faults_ml, file_name='steel_faults_instance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on new data\n",
    "In the beginning we kept a holdout dataset. We use this to simulate prediction on completely new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stored pipeline\n",
    "steel_faults_ml_loaded = load_for_production(file_name='steel_faults_instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on new data\n",
    "custom_pipeline(val_df)\n",
    "\n",
    "# access predicted labels\n",
    "val_y_hat = steel_faults_ml_loaded.predicted_classes['lgbm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess prediction quality on holdout data\n",
    "print(classification_report(val_df_target, val_y_hat))\n",
    "try:\n",
    "    matthews = matthews_corrcoef(val_df_target, val_y_hat)\n",
    "except Exception:\n",
    "    print(\"Matthew failed.\")\n",
    "    matthews = 0\n",
    "print(matthews)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Housing prices regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from e2eml.regression import regression_blueprints as rb\n",
    "from e2eml.full_processing.postprocessing import save_to_production, load_for_production\n",
    "from e2eml.test.regression_blueprints_test import load_housingprices_data\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "Load & preprocess housing prices dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do dataframe splits.\n"
     ]
    }
   ],
   "source": [
    "# load Housing price data\n",
    "test_df, test_target, val_df, val_df_target, test_categorical_cols = load_housingprices_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using e2eml - Run and save a pipeline\n",
    "We only need a few steps to get ur full pipeline:\n",
    "- Instantiate class\n",
    "- Run chosen blueprint\n",
    "- Save blueprint for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferred training mode auto has been chosen. e2eml will automatically detect, if LGBM and Xgboost canuse GPU acceleration and optimize the workflow accordingly.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate class\n",
    "housing_ml = rb.RegressionBluePrint(datasource=test_df,\n",
    "                                         target_variable=test_target,\n",
    "                                         categorical_columns=test_categorical_cols, # here we specify cat columns (that is optional however)\n",
    "                                         preferred_training_mode='auto',\n",
    "                                         tune_mode='accurate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Execute test train split at 06:48:20.\n",
      "Started Apply datetime transformation at 06:48:21.\n",
      "Started Start Spacy, POS tagging + PCA at 06:48:21.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 800 entries, 928 to 799\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             800 non-null    int64  \n",
      " 1   MSSubClass     800 non-null    int64  \n",
      " 2   MSZoning       800 non-null    object \n",
      " 3   LotFrontage    662 non-null    float64\n",
      " 4   LotArea        800 non-null    int64  \n",
      " 5   Street         800 non-null    object \n",
      " 6   Alley          52 non-null     object \n",
      " 7   LotShape       800 non-null    object \n",
      " 8   LandContour    800 non-null    object \n",
      " 9   Utilities      800 non-null    object \n",
      " 10  LotConfig      800 non-null    object \n",
      " 11  LandSlope      800 non-null    object \n",
      " 12  Neighborhood   800 non-null    object \n",
      " 13  Condition1     800 non-null    object \n",
      " 14  Condition2     800 non-null    object \n",
      " 15  BldgType       800 non-null    object \n",
      " 16  HouseStyle     800 non-null    object \n",
      " 17  OverallQual    800 non-null    int64  \n",
      " 18  OverallCond    800 non-null    int64  \n",
      " 19  YearBuilt      800 non-null    int64  \n",
      " 20  YearRemodAdd   800 non-null    int64  \n",
      " 21  RoofStyle      800 non-null    object \n",
      " 22  RoofMatl       800 non-null    object \n",
      " 23  Exterior1st    800 non-null    object \n",
      " 24  Exterior2nd    800 non-null    object \n",
      " 25  MasVnrType     795 non-null    object \n",
      " 26  MasVnrArea     795 non-null    float64\n",
      " 27  ExterQual      800 non-null    object \n",
      " 28  ExterCond      800 non-null    object \n",
      " 29  Foundation     800 non-null    object \n",
      " 30  BsmtQual       780 non-null    object \n",
      " 31  BsmtCond       780 non-null    object \n",
      " 32  BsmtExposure   779 non-null    object \n",
      " 33  BsmtFinType1   780 non-null    object \n",
      " 34  BsmtFinSF1     800 non-null    int64  \n",
      " 35  BsmtFinType2   779 non-null    object \n",
      " 36  BsmtFinSF2     800 non-null    int64  \n",
      " 37  BsmtUnfSF      800 non-null    int64  \n",
      " 38  TotalBsmtSF    800 non-null    int64  \n",
      " 39  Heating        800 non-null    object \n",
      " 40  HeatingQC      800 non-null    object \n",
      " 41  CentralAir     800 non-null    object \n",
      " 42  Electrical     800 non-null    object \n",
      " 43  1stFlrSF       800 non-null    int64  \n",
      " 44  2ndFlrSF       800 non-null    int64  \n",
      " 45  LowQualFinSF   800 non-null    int64  \n",
      " 46  GrLivArea      800 non-null    int64  \n",
      " 47  BsmtFullBath   800 non-null    int64  \n",
      " 48  BsmtHalfBath   800 non-null    int64  \n",
      " 49  FullBath       800 non-null    int64  \n",
      " 50  HalfBath       800 non-null    int64  \n",
      " 51  BedroomAbvGr   800 non-null    int64  \n",
      " 52  KitchenAbvGr   800 non-null    int64  \n",
      " 53  KitchenQual    800 non-null    object \n",
      " 54  TotRmsAbvGrd   800 non-null    int64  \n",
      " 55  Functional     800 non-null    object \n",
      " 56  Fireplaces     800 non-null    int64  \n",
      " 57  FireplaceQu    411 non-null    object \n",
      " 58  GarageType     753 non-null    object \n",
      " 59  GarageYrBlt    753 non-null    float64\n",
      " 60  GarageFinish   753 non-null    object \n",
      " 61  GarageCars     800 non-null    int64  \n",
      " 62  GarageArea     800 non-null    int64  \n",
      " 63  GarageQual     753 non-null    object \n",
      " 64  GarageCond     753 non-null    object \n",
      " 65  PavedDrive     800 non-null    object \n",
      " 66  WoodDeckSF     800 non-null    int64  \n",
      " 67  OpenPorchSF    800 non-null    int64  \n",
      " 68  EnclosedPorch  800 non-null    int64  \n",
      " 69  3SsnPorch      800 non-null    int64  \n",
      " 70  ScreenPorch    800 non-null    int64  \n",
      " 71  PoolArea       800 non-null    int64  \n",
      " 72  PoolQC         1 non-null      object \n",
      " 73  Fence          155 non-null    object \n",
      " 74  MiscFeature    34 non-null     object \n",
      " 75  MiscVal        800 non-null    int64  \n",
      " 76  MoSold         800 non-null    int64  \n",
      " 77  YrSold         800 non-null    int64  \n",
      " 78  SaleType       800 non-null    object \n",
      " 79  SaleCondition  800 non-null    object \n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 506.2+ KB\n",
      "None\n",
      "Started Handle rare features at 06:48:21.\n",
      "Started Remove cardinality at 06:48:21.\n",
      "Started Onehot + PCA categorical features at 06:48:21.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Execute categorical encoding at 06:48:22.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started  Delete columns with high share of NULLs at 06:48:22.\n",
      "Started Fill nulls at 06:48:22.\n",
      "Started Execute numerical binning at 06:48:22.\n",
      "Started Handle outliers at 06:48:23.\n",
      "Started Remove collinearity at 06:48:23.\n",
      "Started Execute clustering as a feature at 06:48:23.\n",
      "Started Scale data at 06:48:23.\n",
      "Started Execute clustering as a feature at 06:48:24.\n",
      "Started Execute clustering as a feature at 06:48:24.\n",
      "Started Execute clustering as a feature at 06:48:25.\n",
      "Started Execute clustering as a feature at 06:48:25.\n",
      "Started Execute clustering as a feature at 06:48:26.\n",
      "Started Execute clustering as a feature at 06:48:26.\n",
      "Started Execute clustering as a feature at 06:48:27.\n",
      "Started Execute clustering as a feature at 06:48:27.\n",
      "Started Select best features at 06:48:28.\n",
      "Id\n",
      "MSSubClass\n",
      "MSZoning\n",
      "LotFrontage\n",
      "LotArea\n",
      "Street\n",
      "Alley\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition1\n",
      "Condition2\n",
      "BldgType\n",
      "HouseStyle\n",
      "OverallQual\n",
      "OverallCond\n",
      "YearBuilt\n",
      "YearRemodAdd\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "MasVnrType\n",
      "MasVnrArea\n",
      "ExterQual\n",
      "ExterCond\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinSF1\n",
      "BsmtFinType2\n",
      "BsmtFinSF2\n",
      "BsmtUnfSF\n",
      "TotalBsmtSF\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "2ndFlrSF\n",
      "LowQualFinSF\n",
      "GrLivArea\n",
      "BsmtFullBath\n",
      "BsmtHalfBath\n",
      "FullBath\n",
      "HalfBath\n",
      "BedroomAbvGr\n",
      "KitchenAbvGr\n",
      "KitchenQual\n",
      "Functional\n",
      "Fireplaces\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageYrBlt\n",
      "GarageFinish\n",
      "GarageCars\n",
      "PavedDrive\n",
      "WoodDeckSF\n",
      "OpenPorchSF\n",
      "EnclosedPorch\n",
      "3SsnPorch\n",
      "ScreenPorch\n",
      "PoolArea\n",
      "PoolQC\n",
      "Fence\n",
      "MiscFeature\n",
      "MiscVal\n",
      "MoSold\n",
      "YrSold\n",
      "SaleType\n",
      "PC-1_pca\n",
      "PC-2_pca\n",
      "isolation_probs\n",
      "isolation_class\n",
      "dbscan_cluster\n",
      "kmeans_clusters2\n",
      "kmeans_clusters3\n",
      "kmeans_clusters4\n",
      "kmeans_clusters5\n",
      "kmeans_clusters6\n",
      "kmeans_clusters7\n",
      "kmeans_clusters8\n",
      "kmeans_clusters9\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  1\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  2\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  3\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  4\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  5\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  6\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  7\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  8\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  9\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  10\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  1\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  2\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  3\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  4\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  5\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  6\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  7\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  8\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  9\n",
      "[06:48:28] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  10\n",
      "BoostARoota ran successfully! Algorithm went through  2  rounds.\n",
      " Selected features are... Id.\n",
      " Selected features are... MSSubClass.\n",
      " Selected features are... MSZoning.\n",
      " Selected features are... LotFrontage.\n",
      " Selected features are... LotArea.\n",
      " Selected features are... Alley.\n",
      " Selected features are... LotShape.\n",
      " Selected features are... LandContour.\n",
      " Selected features are... Utilities.\n",
      " Selected features are... LotConfig.\n",
      " Selected features are... LandSlope.\n",
      " Selected features are... Neighborhood.\n",
      " Selected features are... Condition1.\n",
      " Selected features are... Condition2.\n",
      " Selected features are... BldgType.\n",
      " Selected features are... HouseStyle.\n",
      " Selected features are... OverallQual.\n",
      " Selected features are... OverallCond.\n",
      " Selected features are... YearBuilt.\n",
      " Selected features are... YearRemodAdd.\n",
      " Selected features are... RoofStyle.\n",
      " Selected features are... RoofMatl.\n",
      " Selected features are... Exterior1st.\n",
      " Selected features are... MasVnrType.\n",
      " Selected features are... MasVnrArea.\n",
      " Selected features are... ExterCond.\n",
      " Selected features are... Foundation.\n",
      " Selected features are... BsmtQual.\n",
      " Selected features are... BsmtCond.\n",
      " Selected features are... BsmtExposure.\n",
      " Selected features are... BsmtFinType1.\n",
      " Selected features are... BsmtFinSF1.\n",
      " Selected features are... BsmtFinType2.\n",
      " Selected features are... BsmtFinSF2.\n",
      " Selected features are... BsmtUnfSF.\n",
      " Selected features are... TotalBsmtSF.\n",
      " Selected features are... Heating.\n",
      " Selected features are... HeatingQC.\n",
      " Selected features are... CentralAir.\n",
      " Selected features are... Electrical.\n",
      " Selected features are... 2ndFlrSF.\n",
      " Selected features are... GrLivArea.\n",
      " Selected features are... BsmtFullBath.\n",
      " Selected features are... FullBath.\n",
      " Selected features are... HalfBath.\n",
      " Selected features are... BedroomAbvGr.\n",
      " Selected features are... KitchenQual.\n",
      " Selected features are... Functional.\n",
      " Selected features are... Fireplaces.\n",
      " Selected features are... FireplaceQu.\n",
      " Selected features are... GarageType.\n",
      " Selected features are... GarageYrBlt.\n",
      " Selected features are... GarageFinish.\n",
      " Selected features are... GarageCars.\n",
      " Selected features are... PavedDrive.\n",
      " Selected features are... WoodDeckSF.\n",
      " Selected features are... OpenPorchSF.\n",
      " Selected features are... EnclosedPorch.\n",
      " Selected features are... ScreenPorch.\n",
      " Selected features are... Fence.\n",
      " Selected features are... MoSold.\n",
      " Selected features are... YrSold.\n",
      " Selected features are... SaleType.\n",
      " Selected features are... PC-1_pca.\n",
      " Selected features are... PC-2_pca.\n",
      " Selected features are... isolation_probs.\n",
      " Selected features are... kmeans_clusters2.\n",
      " Selected features are... kmeans_clusters3.\n",
      " Selected features are... kmeans_clusters4.\n",
      " Selected features are... kmeans_clusters5.\n",
      " Selected features are... kmeans_clusters6.\n",
      " Selected features are... kmeans_clusters8.\n",
      " Selected features are... kmeans_clusters9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:48:28,792]\u001B[0m A new study created in memory with name: no-name-004d05c4-c47c-4cb2-aae4-62b4ccced2e9\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Sort columns alphabetically at 06:48:28.\n",
      "Started Train Ngboost at 06:48:28.\n",
      "[iter 0] loss=12.5729 val_loss=12.4403 scale=2.0000 norm=1.3549\n",
      "[iter 100] loss=11.2319 val_loss=11.3382 scale=2.0000 norm=0.8572\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL149 (val_loss=11.2208)\n",
      "[iter 0] loss=12.5898 val_loss=12.4402 scale=2.0000 norm=1.3885\n",
      "[iter 100] loss=11.2077 val_loss=11.3281 scale=2.0000 norm=0.8549\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL151 (val_loss=11.1937)\n",
      "[iter 0] loss=12.6617 val_loss=12.4476 scale=2.0000 norm=1.3854\n",
      "[iter 100] loss=11.2260 val_loss=11.3371 scale=2.0000 norm=0.8317\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL139 (val_loss=11.2293)\n",
      "[iter 0] loss=12.6319 val_loss=12.4420 scale=2.0000 norm=1.4309\n",
      "[iter 100] loss=11.1825 val_loss=11.3644 scale=2.0000 norm=0.8396\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL138 (val_loss=11.2662)\n",
      "[iter 0] loss=12.6411 val_loss=12.4367 scale=2.0000 norm=1.4103\n",
      "[iter 100] loss=11.1732 val_loss=11.3579 scale=2.0000 norm=0.8282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:49:00,390]\u001B[0m Trial 0 finished with value: -868366768.6671002 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 34809, 'minibatch_frac': 0.4255325705603149, 'learning_rate': 0.01503813231997811}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL145 (val_loss=11.2565)\n",
      "[iter 0] loss=13.0962 val_loss=13.1064 scale=2.0000 norm=0.6594\n",
      "[iter 100] loss=13.0739 val_loss=13.0754 scale=2.0000 norm=0.4246\n",
      "[iter 200] loss=13.0451 val_loss=13.0601 scale=2.0000 norm=0.2778\n",
      "[iter 300] loss=13.0391 val_loss=13.0533 scale=2.0000 norm=0.1832\n",
      "[iter 400] loss=13.0225 val_loss=13.0500 scale=2.0000 norm=0.1175\n",
      "[iter 500] loss=13.0364 val_loss=13.0483 scale=2.0000 norm=0.0858\n",
      "[iter 600] loss=13.0144 val_loss=13.0474 scale=2.0000 norm=0.0598\n",
      "[iter 700] loss=13.0409 val_loss=13.0469 scale=2.0000 norm=0.0427\n",
      "[iter 800] loss=13.0297 val_loss=13.0467 scale=2.0000 norm=0.0341\n",
      "[iter 900] loss=13.0652 val_loss=13.0465 scale=2.0000 norm=0.0233\n",
      "[iter 1000] loss=13.0304 val_loss=13.0464 scale=2.0000 norm=0.0178\n",
      "[iter 1100] loss=13.0230 val_loss=13.0463 scale=2.0000 norm=0.0132\n",
      "[iter 1200] loss=13.0583 val_loss=13.0462 scale=2.0000 norm=0.0112\n",
      "[iter 1300] loss=13.0277 val_loss=13.0462 scale=2.0000 norm=0.0100\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1351 (val_loss=13.0462)\n",
      "[iter 0] loss=13.0937 val_loss=13.1064 scale=2.0000 norm=0.6508\n",
      "[iter 100] loss=13.0672 val_loss=13.0745 scale=2.0000 norm=0.4223\n",
      "[iter 200] loss=13.0445 val_loss=13.0595 scale=2.0000 norm=0.2815\n",
      "[iter 300] loss=13.0321 val_loss=13.0535 scale=2.0000 norm=0.1941\n",
      "[iter 400] loss=13.0308 val_loss=13.0500 scale=2.0000 norm=0.1146\n",
      "[iter 500] loss=13.0225 val_loss=13.0482 scale=2.0000 norm=0.0877\n",
      "[iter 600] loss=13.0085 val_loss=13.0472 scale=2.0000 norm=0.0622\n",
      "[iter 700] loss=13.0097 val_loss=13.0468 scale=2.0000 norm=0.0431\n",
      "[iter 800] loss=13.0160 val_loss=13.0465 scale=2.0000 norm=0.0337\n",
      "[iter 900] loss=13.0437 val_loss=13.0463 scale=2.0000 norm=0.0248\n",
      "[iter 1000] loss=13.0361 val_loss=13.0462 scale=2.0000 norm=0.0179\n",
      "[iter 1100] loss=13.0338 val_loss=13.0461 scale=2.0000 norm=0.0135\n",
      "[iter 1200] loss=13.0451 val_loss=13.0461 scale=2.0000 norm=0.0117\n",
      "[iter 1300] loss=13.0225 val_loss=13.0460 scale=2.0000 norm=0.0102\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1295 (val_loss=13.0460)\n",
      "[iter 0] loss=13.1374 val_loss=13.1071 scale=1.0000 norm=0.3480\n",
      "[iter 100] loss=13.0836 val_loss=13.0757 scale=2.0000 norm=0.4462\n",
      "[iter 200] loss=13.0628 val_loss=13.0604 scale=2.0000 norm=0.2880\n",
      "[iter 300] loss=13.0304 val_loss=13.0542 scale=2.0000 norm=0.2079\n",
      "[iter 400] loss=13.0468 val_loss=13.0508 scale=2.0000 norm=0.1187\n",
      "[iter 500] loss=13.0398 val_loss=13.0489 scale=2.0000 norm=0.0899\n",
      "[iter 600] loss=13.0257 val_loss=13.0479 scale=2.0000 norm=0.0589\n",
      "[iter 700] loss=13.0316 val_loss=13.0473 scale=2.0000 norm=0.0430\n",
      "[iter 800] loss=13.0418 val_loss=13.0470 scale=2.0000 norm=0.0325\n",
      "[iter 900] loss=13.0675 val_loss=13.0469 scale=2.0000 norm=0.0240\n",
      "[iter 1000] loss=13.0561 val_loss=13.0468 scale=2.0000 norm=0.0175\n",
      "[iter 1100] loss=13.0479 val_loss=13.0467 scale=2.0000 norm=0.0136\n",
      "[iter 1200] loss=13.0739 val_loss=13.0466 scale=2.0000 norm=0.0109\n",
      "[iter 1300] loss=13.0600 val_loss=13.0466 scale=2.0000 norm=0.0099\n",
      "[iter 1400] loss=13.0659 val_loss=13.0465 scale=2.0000 norm=0.0074\n",
      "[iter 1500] loss=13.0709 val_loss=13.0465 scale=2.0000 norm=0.0063\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1586 (val_loss=13.0465)\n",
      "[iter 0] loss=13.1004 val_loss=13.1064 scale=2.0000 norm=0.6639\n",
      "[iter 100] loss=13.0565 val_loss=13.0780 scale=2.0000 norm=0.4228\n",
      "[iter 200] loss=13.0333 val_loss=13.0657 scale=2.0000 norm=0.2750\n",
      "[iter 300] loss=12.9983 val_loss=13.0585 scale=2.0000 norm=0.1974\n",
      "[iter 400] loss=13.0365 val_loss=13.0544 scale=2.0000 norm=0.1095\n",
      "[iter 500] loss=13.0322 val_loss=13.0519 scale=2.0000 norm=0.0894\n",
      "[iter 600] loss=12.9869 val_loss=13.0504 scale=2.0000 norm=0.0622\n",
      "[iter 700] loss=12.9942 val_loss=13.0496 scale=2.0000 norm=0.0420\n",
      "[iter 800] loss=13.0100 val_loss=13.0491 scale=2.0000 norm=0.0338\n",
      "[iter 900] loss=13.0284 val_loss=13.0488 scale=2.0000 norm=0.0243\n",
      "[iter 1000] loss=13.0234 val_loss=13.0486 scale=2.0000 norm=0.0168\n",
      "[iter 1100] loss=13.0192 val_loss=13.0485 scale=2.0000 norm=0.0128\n",
      "[iter 1200] loss=13.0398 val_loss=13.0484 scale=2.0000 norm=0.0106\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1264 (val_loss=13.0484)\n",
      "[iter 0] loss=13.1201 val_loss=13.1066 scale=1.0000 norm=0.3373\n",
      "[iter 100] loss=13.0614 val_loss=13.0747 scale=2.0000 norm=0.3967\n",
      "[iter 200] loss=13.0291 val_loss=13.0622 scale=2.0000 norm=0.2742\n",
      "[iter 300] loss=13.0092 val_loss=13.0554 scale=2.0000 norm=0.1875\n",
      "[iter 400] loss=13.0394 val_loss=13.0519 scale=2.0000 norm=0.1100\n",
      "[iter 500] loss=13.0238 val_loss=13.0500 scale=2.0000 norm=0.0841\n",
      "[iter 600] loss=13.0251 val_loss=13.0488 scale=2.0000 norm=0.0618\n",
      "[iter 700] loss=12.9978 val_loss=13.0482 scale=2.0000 norm=0.0433\n",
      "[iter 800] loss=13.0199 val_loss=13.0478 scale=2.0000 norm=0.0344\n",
      "[iter 900] loss=13.0543 val_loss=13.0475 scale=2.0000 norm=0.0245\n",
      "[iter 1000] loss=13.0188 val_loss=13.0474 scale=2.0000 norm=0.0178\n",
      "[iter 1100] loss=13.0298 val_loss=13.0473 scale=2.0000 norm=0.0136\n",
      "[iter 1200] loss=13.0290 val_loss=13.0472 scale=2.0000 norm=0.0118\n",
      "[iter 1300] loss=13.0144 val_loss=13.0472 scale=2.0000 norm=0.0091\n",
      "[iter 1400] loss=13.0327 val_loss=13.0472 scale=2.0000 norm=0.0073\n",
      "[iter 1500] loss=13.0397 val_loss=13.0471 scale=2.0000 norm=0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:50:08,370]\u001B[0m Trial 1 finished with value: -979262513.1644522 and parameters: {'base_learner': 'DecTree_depthNone', 'Dist': 'Exponential', 'n_estimators': 45501, 'minibatch_frac': 0.5274111022795059, 'learning_rate': 0.0024473620880182062}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1562 (val_loss=13.0471)\n",
      "[iter 0] loss=12.5444 val_loss=12.4611 scale=1.0000 norm=0.6429\n",
      "[iter 100] loss=12.1997 val_loss=12.2303 scale=1.0000 norm=0.4838\n",
      "[iter 200] loss=11.9278 val_loss=12.0064 scale=1.0000 norm=0.4547\n",
      "[iter 300] loss=11.5863 val_loss=11.7332 scale=1.0000 norm=0.4260\n",
      "[iter 400] loss=11.3745 val_loss=11.5609 scale=2.0000 norm=0.8600\n",
      "[iter 500] loss=11.2197 val_loss=11.4931 scale=2.0000 norm=0.8468\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL553 (val_loss=11.4853)\n",
      "[iter 0] loss=12.5640 val_loss=12.4652 scale=1.0000 norm=0.6622\n",
      "[iter 100] loss=12.1965 val_loss=12.2100 scale=1.0000 norm=0.4838\n",
      "[iter 200] loss=11.9433 val_loss=11.9886 scale=1.0000 norm=0.4577\n",
      "[iter 300] loss=11.6453 val_loss=11.7440 scale=2.0000 norm=0.8716\n",
      "[iter 400] loss=11.4019 val_loss=11.5469 scale=1.0000 norm=0.4302\n",
      "[iter 500] loss=11.2341 val_loss=11.4584 scale=1.0000 norm=0.4268\n",
      "[iter 600] loss=11.1137 val_loss=11.4330 scale=1.0000 norm=0.4180\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL601 (val_loss=11.4327)\n",
      "[iter 0] loss=12.6050 val_loss=12.4701 scale=1.0000 norm=0.6562\n",
      "[iter 100] loss=12.2345 val_loss=12.2087 scale=1.0000 norm=0.4791\n",
      "[iter 200] loss=11.9241 val_loss=11.9573 scale=2.0000 norm=0.8865\n",
      "[iter 300] loss=11.6090 val_loss=11.6817 scale=1.0000 norm=0.4284\n",
      "[iter 400] loss=11.3889 val_loss=11.5069 scale=2.0000 norm=0.8191\n",
      "[iter 500] loss=11.2478 val_loss=11.4276 scale=1.0000 norm=0.4180\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL584 (val_loss=11.4068)\n",
      "[iter 0] loss=12.5575 val_loss=12.4658 scale=1.0000 norm=0.6685\n",
      "[iter 100] loss=12.1791 val_loss=12.2678 scale=1.0000 norm=0.4834\n",
      "[iter 200] loss=11.9075 val_loss=12.0349 scale=1.0000 norm=0.4514\n",
      "[iter 300] loss=11.6141 val_loss=11.7922 scale=2.0000 norm=0.8967\n",
      "[iter 400] loss=11.3735 val_loss=11.6261 scale=2.0000 norm=0.8682\n",
      "[iter 500] loss=11.2133 val_loss=11.5645 scale=1.0000 norm=0.4329\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL503 (val_loss=11.5641)\n",
      "[iter 0] loss=12.5333 val_loss=12.4638 scale=1.0000 norm=0.6528\n",
      "[iter 100] loss=12.1468 val_loss=12.2326 scale=1.0000 norm=0.4702\n",
      "[iter 200] loss=11.8832 val_loss=12.0189 scale=2.0000 norm=0.8963\n",
      "[iter 300] loss=11.6041 val_loss=11.7595 scale=2.0000 norm=0.8763\n",
      "[iter 400] loss=11.3735 val_loss=11.5800 scale=1.0000 norm=0.4229\n",
      "[iter 500] loss=11.2066 val_loss=11.5030 scale=1.0000 norm=0.4164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:50:29,177]\u001B[0m Trial 2 finished with value: -983834344.9944637 and parameters: {'base_learner': 'DecTree_depth2', 'Dist': 'LogNormal', 'n_estimators': 49249, 'minibatch_frac': 0.739419870470148, 'learning_rate': 0.0065552126767597155}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL577 (val_loss=11.4883)\n",
      "[iter 0] loss=12.5497 val_loss=12.4647 scale=1.0000 norm=0.6605\n",
      "[iter 100] loss=12.4189 val_loss=12.3683 scale=1.0000 norm=0.5379\n",
      "[iter 200] loss=12.2675 val_loss=12.2608 scale=2.0000 norm=0.9671\n",
      "[iter 300] loss=12.1518 val_loss=12.1651 scale=2.0000 norm=0.9089\n",
      "[iter 400] loss=12.0013 val_loss=12.0743 scale=2.0000 norm=0.8950\n",
      "[iter 500] loss=11.9272 val_loss=11.9845 scale=2.0000 norm=0.8831\n",
      "[iter 600] loss=11.8061 val_loss=11.8987 scale=2.0000 norm=0.8814\n",
      "[iter 700] loss=11.7190 val_loss=11.8170 scale=2.0000 norm=0.8777\n",
      "[iter 800] loss=11.6326 val_loss=11.7363 scale=2.0000 norm=0.8803\n",
      "[iter 900] loss=11.5451 val_loss=11.6600 scale=2.0000 norm=0.8773\n",
      "[iter 1000] loss=11.4301 val_loss=11.5882 scale=2.0000 norm=0.8681\n",
      "[iter 1100] loss=11.3316 val_loss=11.5220 scale=2.0000 norm=0.8707\n",
      "[iter 1200] loss=11.2752 val_loss=11.4623 scale=2.0000 norm=0.8635\n",
      "[iter 1300] loss=11.1814 val_loss=11.4115 scale=2.0000 norm=0.8457\n",
      "[iter 1400] loss=11.1124 val_loss=11.3695 scale=2.0000 norm=0.8367\n",
      "[iter 1500] loss=10.9903 val_loss=11.3381 scale=2.0000 norm=0.8341\n",
      "[iter 1600] loss=10.9108 val_loss=11.3179 scale=2.0000 norm=0.8254\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1685 (val_loss=11.3111)\n",
      "[iter 0] loss=12.5437 val_loss=12.4684 scale=1.0000 norm=0.6590\n",
      "[iter 100] loss=12.4215 val_loss=12.3718 scale=1.0000 norm=0.5414\n",
      "[iter 200] loss=12.2933 val_loss=12.2792 scale=2.0000 norm=0.9843\n",
      "[iter 300] loss=12.1904 val_loss=12.1840 scale=2.0000 norm=0.9217\n",
      "[iter 400] loss=12.0240 val_loss=12.0944 scale=2.0000 norm=0.8990\n",
      "[iter 500] loss=11.9432 val_loss=12.0073 scale=2.0000 norm=0.8928\n",
      "[iter 600] loss=11.8222 val_loss=11.9226 scale=2.0000 norm=0.8877\n",
      "[iter 700] loss=11.7182 val_loss=11.8403 scale=2.0000 norm=0.8804\n",
      "[iter 800] loss=11.6372 val_loss=11.7589 scale=2.0000 norm=0.8846\n",
      "[iter 900] loss=11.5599 val_loss=11.6808 scale=2.0000 norm=0.8766\n",
      "[iter 1000] loss=11.4608 val_loss=11.6070 scale=2.0000 norm=0.8706\n",
      "[iter 1100] loss=11.3609 val_loss=11.5391 scale=2.0000 norm=0.8720\n",
      "[iter 1200] loss=11.2784 val_loss=11.4779 scale=2.0000 norm=0.8637\n",
      "[iter 1300] loss=11.2086 val_loss=11.4227 scale=2.0000 norm=0.8464\n",
      "[iter 1400] loss=11.1262 val_loss=11.3761 scale=2.0000 norm=0.8375\n",
      "[iter 1500] loss=11.0094 val_loss=11.3394 scale=2.0000 norm=0.8396\n",
      "[iter 1600] loss=10.9299 val_loss=11.3123 scale=2.0000 norm=0.8233\n",
      "[iter 1700] loss=10.8666 val_loss=11.2975 scale=2.0000 norm=0.8054\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1758 (val_loss=11.2947)\n",
      "[iter 0] loss=12.6048 val_loss=12.4736 scale=1.0000 norm=0.6565\n",
      "[iter 100] loss=12.4648 val_loss=12.3748 scale=1.0000 norm=0.5442\n",
      "[iter 200] loss=12.2958 val_loss=12.2748 scale=2.0000 norm=0.9595\n",
      "[iter 300] loss=12.1973 val_loss=12.1767 scale=2.0000 norm=0.9173\n",
      "[iter 400] loss=12.0383 val_loss=12.0904 scale=2.0000 norm=0.8947\n",
      "[iter 500] loss=11.9555 val_loss=12.0053 scale=2.0000 norm=0.8914\n",
      "[iter 600] loss=11.8319 val_loss=11.9216 scale=2.0000 norm=0.8845\n",
      "[iter 700] loss=11.7472 val_loss=11.8387 scale=2.0000 norm=0.8811\n",
      "[iter 800] loss=11.6579 val_loss=11.7596 scale=2.0000 norm=0.8832\n",
      "[iter 900] loss=11.5881 val_loss=11.6833 scale=2.0000 norm=0.8800\n",
      "[iter 1000] loss=11.4805 val_loss=11.6123 scale=2.0000 norm=0.8756\n",
      "[iter 1100] loss=11.3718 val_loss=11.5475 scale=2.0000 norm=0.8733\n",
      "[iter 1200] loss=11.2913 val_loss=11.4899 scale=2.0000 norm=0.8678\n",
      "[iter 1300] loss=11.2350 val_loss=11.4413 scale=2.0000 norm=0.8483\n",
      "[iter 1400] loss=11.1354 val_loss=11.4027 scale=2.0000 norm=0.8482\n",
      "[iter 1500] loss=11.0372 val_loss=11.3760 scale=2.0000 norm=0.8427\n",
      "[iter 1600] loss=10.9530 val_loss=11.3612 scale=2.0000 norm=0.8257\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1650 (val_loss=11.3590)\n",
      "[iter 0] loss=12.5595 val_loss=12.4692 scale=1.0000 norm=0.6704\n",
      "[iter 100] loss=12.4173 val_loss=12.3957 scale=1.0000 norm=0.5508\n",
      "[iter 200] loss=12.2723 val_loss=12.3168 scale=2.0000 norm=0.9820\n",
      "[iter 300] loss=12.1566 val_loss=12.2320 scale=2.0000 norm=0.9174\n",
      "[iter 400] loss=12.0307 val_loss=12.1575 scale=2.0000 norm=0.8986\n",
      "[iter 500] loss=11.9571 val_loss=12.0802 scale=2.0000 norm=0.8941\n",
      "[iter 600] loss=11.8098 val_loss=12.0048 scale=2.0000 norm=0.8835\n",
      "[iter 700] loss=11.7211 val_loss=11.9256 scale=2.0000 norm=0.8831\n",
      "[iter 800] loss=11.6435 val_loss=11.8513 scale=2.0000 norm=0.8794\n",
      "[iter 900] loss=11.5638 val_loss=11.7811 scale=2.0000 norm=0.8741\n",
      "[iter 1000] loss=11.4475 val_loss=11.7177 scale=2.0000 norm=0.8758\n",
      "[iter 1100] loss=11.3552 val_loss=11.6602 scale=2.0000 norm=0.8677\n",
      "[iter 1200] loss=11.2638 val_loss=11.6130 scale=2.0000 norm=0.8652\n",
      "[iter 1300] loss=11.1901 val_loss=11.5763 scale=2.0000 norm=0.8603\n",
      "[iter 1400] loss=11.1156 val_loss=11.5505 scale=2.0000 norm=0.8526\n",
      "[iter 1500] loss=11.0159 val_loss=11.5397 scale=2.0000 norm=0.8452\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1545 (val_loss=11.5385)\n",
      "[iter 0] loss=12.5653 val_loss=12.4647 scale=1.0000 norm=0.6670\n",
      "[iter 100] loss=12.3771 val_loss=12.3842 scale=1.0000 norm=0.5251\n",
      "[iter 200] loss=12.2625 val_loss=12.2978 scale=1.0000 norm=0.4867\n",
      "[iter 300] loss=12.1276 val_loss=12.2036 scale=2.0000 norm=0.8987\n",
      "[iter 400] loss=12.0248 val_loss=12.1180 scale=2.0000 norm=0.8872\n",
      "[iter 500] loss=11.9303 val_loss=12.0411 scale=2.0000 norm=0.8858\n",
      "[iter 600] loss=11.8186 val_loss=11.9571 scale=2.0000 norm=0.8782\n",
      "[iter 700] loss=11.7050 val_loss=11.8733 scale=2.0000 norm=0.8784\n",
      "[iter 800] loss=11.6409 val_loss=11.7936 scale=2.0000 norm=0.8709\n",
      "[iter 900] loss=11.5727 val_loss=11.7212 scale=2.0000 norm=0.8729\n",
      "[iter 1000] loss=11.4250 val_loss=11.6541 scale=2.0000 norm=0.8688\n",
      "[iter 1100] loss=11.3437 val_loss=11.5930 scale=2.0000 norm=0.8681\n",
      "[iter 1200] loss=11.2596 val_loss=11.5403 scale=2.0000 norm=0.8516\n",
      "[iter 1300] loss=11.1786 val_loss=11.4980 scale=2.0000 norm=0.8503\n",
      "[iter 1400] loss=11.0872 val_loss=11.4659 scale=2.0000 norm=0.8482\n",
      "[iter 1500] loss=11.0103 val_loss=11.4468 scale=2.0000 norm=0.8330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:51:47,278]\u001B[0m Trial 3 finished with value: -937349989.6176481 and parameters: {'base_learner': 'DecTree_depth5', 'Dist': 'LogNormal', 'n_estimators': 2754, 'minibatch_frac': 0.6032950433318143, 'learning_rate': 0.0010909736641288672}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1586 (val_loss=11.4406)\n",
      "[iter 0] loss=12.5422 val_loss=12.3177 scale=2.0000 norm=1.2897\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL17 (val_loss=11.5755)\n",
      "[iter 0] loss=12.5471 val_loss=12.3472 scale=2.0000 norm=1.3015\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL20 (val_loss=11.5335)\n",
      "[iter 0] loss=12.5942 val_loss=12.3472 scale=2.0000 norm=1.2943\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL18 (val_loss=11.4998)\n",
      "[iter 0] loss=12.5470 val_loss=12.3353 scale=2.0000 norm=1.3166\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL14 (val_loss=11.8198)\n",
      "[iter 0] loss=12.5448 val_loss=12.3628 scale=2.0000 norm=1.3060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:51:49,893]\u001B[0m Trial 4 finished with value: -1176152039.8901126 and parameters: {'base_learner': 'DecTree_depthNone', 'Dist': 'LogNormal', 'n_estimators': 40941, 'minibatch_frac': 0.6798412514071572, 'learning_rate': 0.07213063142382377}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL17 (val_loss=11.6373)\n",
      "[iter 0] loss=13.1019 val_loss=13.1017 scale=1.0000 norm=0.3263\n",
      "[iter 100] loss=13.0437 val_loss=13.0461 scale=2.0000 norm=0.1369\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL144 (val_loss=13.0457)\n",
      "[iter 0] loss=13.1001 val_loss=13.1023 scale=1.0000 norm=0.3252\n",
      "[iter 100] loss=13.0381 val_loss=13.0470 scale=2.0000 norm=0.1388\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL127 (val_loss=13.0468)\n",
      "[iter 0] loss=13.1293 val_loss=13.1024 scale=1.0000 norm=0.3452\n",
      "[iter 100] loss=13.0562 val_loss=13.0464 scale=2.0000 norm=0.1363\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL128 (val_loss=13.0462)\n",
      "[iter 0] loss=13.0893 val_loss=13.1019 scale=1.0000 norm=0.3277\n",
      "[iter 100] loss=13.0263 val_loss=13.0490 scale=2.0000 norm=0.1275\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL110 (val_loss=13.0488)\n",
      "[iter 0] loss=13.0980 val_loss=13.1033 scale=1.0000 norm=0.3309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:51:53,493]\u001B[0m Trial 5 finished with value: -993829200.3419892 and parameters: {'base_learner': 'DecTree_depth2', 'Dist': 'Exponential', 'n_estimators': 26104, 'minibatch_frac': 0.656091511419505, 'learning_rate': 0.05539786127593042}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 100] loss=13.0247 val_loss=13.0483 scale=2.0000 norm=0.1369\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL103 (val_loss=13.0482)\n",
      "[iter 0] loss=12.5395 val_loss=12.4520 scale=1.0000 norm=0.6401\n",
      "[iter 100] loss=11.6787 val_loss=11.7415 scale=1.0000 norm=0.4371\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL189 (val_loss=11.4523)\n",
      "[iter 0] loss=12.5590 val_loss=12.4576 scale=1.0000 norm=0.6591\n",
      "[iter 100] loss=11.6626 val_loss=11.7742 scale=1.0000 norm=0.4493\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL187 (val_loss=11.5106)\n",
      "[iter 0] loss=12.5993 val_loss=12.4613 scale=1.0000 norm=0.6533\n",
      "[iter 100] loss=11.6465 val_loss=11.7110 scale=2.0000 norm=0.8529\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL187 (val_loss=11.4577)\n",
      "[iter 0] loss=12.5525 val_loss=12.4579 scale=1.0000 norm=0.6653\n",
      "[iter 100] loss=11.6424 val_loss=11.8175 scale=2.0000 norm=0.8911\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL172 (val_loss=11.6082)\n",
      "[iter 0] loss=12.5271 val_loss=12.4606 scale=1.0000 norm=0.6498\n",
      "[iter 100] loss=11.6261 val_loss=11.7796 scale=2.0000 norm=0.8649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:52:00,780]\u001B[0m Trial 6 finished with value: -1011124625.7909935 and parameters: {'base_learner': 'DecTree_depth2', 'Dist': 'LogNormal', 'n_estimators': 461, 'minibatch_frac': 0.7500226410655508, 'learning_rate': 0.018793167920555572}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 200] loss=11.1096 val_loss=11.4895 scale=2.0000 norm=0.8324\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL199 (val_loss=11.4888)\n",
      "[iter 0] loss=12.7216 val_loss=12.5879 scale=1.0000 norm=59225.2607\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL86 (val_loss=11.4986)\n",
      "[iter 0] loss=12.7250 val_loss=12.5833 scale=1.0000 norm=58981.9516\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL88 (val_loss=11.4267)\n",
      "[iter 0] loss=12.7688 val_loss=12.6007 scale=1.0000 norm=62890.3923\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL79 (val_loss=11.5669)\n",
      "[iter 0] loss=12.7339 val_loss=12.5789 scale=1.0000 norm=58495.7370\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL82 (val_loss=11.5426)\n",
      "[iter 0] loss=12.6821 val_loss=12.5654 scale=1.0000 norm=57579.2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:52:05,644]\u001B[0m Trial 7 finished with value: -1005447683.968869 and parameters: {'base_learner': 'DecTree_depth5', 'Dist': 'Normal', 'n_estimators': 42533, 'minibatch_frac': 0.8917603080121715, 'learning_rate': 0.02042941296412333}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL87 (val_loss=11.3737)\n",
      "[iter 0] loss=13.0990 val_loss=13.1065 scale=1.0000 norm=0.3212\n",
      "[iter 100] loss=13.0861 val_loss=13.0776 scale=1.0000 norm=0.2201\n",
      "[iter 200] loss=13.0591 val_loss=13.0625 scale=2.0000 norm=0.2769\n",
      "[iter 300] loss=13.0485 val_loss=13.0544 scale=2.0000 norm=0.1992\n",
      "[iter 400] loss=13.0398 val_loss=13.0513 scale=2.0000 norm=0.1737\n",
      "[iter 500] loss=13.0439 val_loss=13.0500 scale=2.0000 norm=0.1666\n",
      "[iter 600] loss=13.0228 val_loss=13.0494 scale=2.0000 norm=0.1557\n",
      "[iter 700] loss=13.0410 val_loss=13.0490 scale=2.0000 norm=0.1504\n",
      "[iter 800] loss=13.0412 val_loss=13.0487 scale=2.0000 norm=0.1452\n",
      "[iter 900] loss=13.0447 val_loss=13.0485 scale=2.0000 norm=0.1365\n",
      "[iter 1000] loss=13.0362 val_loss=13.0484 scale=1.0000 norm=0.0665\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1022 (val_loss=13.0484)\n",
      "[iter 0] loss=13.0973 val_loss=13.1065 scale=1.0000 norm=0.3200\n",
      "[iter 100] loss=13.0794 val_loss=13.0749 scale=2.0000 norm=0.4246\n",
      "[iter 200] loss=13.0554 val_loss=13.0607 scale=2.0000 norm=0.2691\n",
      "[iter 300] loss=13.0390 val_loss=13.0533 scale=2.0000 norm=0.2061\n",
      "[iter 400] loss=13.0373 val_loss=13.0505 scale=1.0000 norm=0.0874\n",
      "[iter 500] loss=13.0267 val_loss=13.0493 scale=2.0000 norm=0.1687\n",
      "[iter 600] loss=13.0182 val_loss=13.0486 scale=2.0000 norm=0.1552\n",
      "[iter 700] loss=13.0176 val_loss=13.0483 scale=1.0000 norm=0.0767\n",
      "[iter 800] loss=13.0280 val_loss=13.0480 scale=2.0000 norm=0.1488\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL863 (val_loss=13.0478)\n",
      "[iter 0] loss=13.1220 val_loss=13.1069 scale=1.0000 norm=0.3399\n",
      "[iter 100] loss=13.0982 val_loss=13.0751 scale=2.0000 norm=0.4283\n",
      "[iter 200] loss=13.0721 val_loss=13.0596 scale=2.0000 norm=0.2590\n",
      "[iter 300] loss=13.0487 val_loss=13.0529 scale=2.0000 norm=0.2079\n",
      "[iter 400] loss=13.0501 val_loss=13.0499 scale=1.0000 norm=0.0887\n",
      "[iter 500] loss=13.0472 val_loss=13.0486 scale=2.0000 norm=0.1673\n",
      "[iter 600] loss=13.0305 val_loss=13.0480 scale=2.0000 norm=0.1517\n",
      "[iter 700] loss=13.0418 val_loss=13.0476 scale=1.0000 norm=0.0761\n",
      "[iter 800] loss=13.0529 val_loss=13.0474 scale=2.0000 norm=0.1479\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL863 (val_loss=13.0473)\n",
      "[iter 0] loss=13.0845 val_loss=13.1069 scale=1.0000 norm=0.3236\n",
      "[iter 100] loss=13.0684 val_loss=13.0805 scale=1.0000 norm=0.2078\n",
      "[iter 200] loss=13.0447 val_loss=13.0638 scale=2.0000 norm=0.2611\n",
      "[iter 300] loss=13.0206 val_loss=13.0558 scale=2.0000 norm=0.2029\n",
      "[iter 400] loss=13.0385 val_loss=13.0526 scale=2.0000 norm=0.1736\n",
      "[iter 500] loss=13.0326 val_loss=13.0509 scale=2.0000 norm=0.1620\n",
      "[iter 600] loss=12.9965 val_loss=13.0501 scale=1.0000 norm=0.0746\n",
      "[iter 700] loss=13.0152 val_loss=13.0495 scale=1.0000 norm=0.0744\n",
      "[iter 800] loss=13.0254 val_loss=13.0492 scale=1.0000 norm=0.0725\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL864 (val_loss=13.0491)\n",
      "[iter 0] loss=13.0932 val_loss=13.1066 scale=1.0000 norm=0.3256\n",
      "[iter 100] loss=13.0601 val_loss=13.0762 scale=2.0000 norm=0.3906\n",
      "[iter 200] loss=13.0367 val_loss=13.0613 scale=2.0000 norm=0.2530\n",
      "[iter 300] loss=13.0324 val_loss=13.0541 scale=2.0000 norm=0.2004\n",
      "[iter 400] loss=13.0410 val_loss=13.0511 scale=2.0000 norm=0.1766\n",
      "[iter 500] loss=13.0298 val_loss=13.0499 scale=2.0000 norm=0.1667\n",
      "[iter 600] loss=13.0161 val_loss=13.0493 scale=2.0000 norm=0.1512\n",
      "[iter 700] loss=13.0172 val_loss=13.0488 scale=2.0000 norm=0.1551\n",
      "[iter 800] loss=13.0316 val_loss=13.0486 scale=1.0000 norm=0.0757\n",
      "[iter 900] loss=13.0625 val_loss=13.0484 scale=2.0000 norm=0.1405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:52:30,880]\u001B[0m Trial 8 finished with value: -993420832.9245838 and parameters: {'base_learner': 'DecTree_depth2', 'Dist': 'Exponential', 'n_estimators': 41943, 'minibatch_frac': 0.6967741763386246, 'learning_rate': 0.004985913883887544}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL984 (val_loss=13.0482)\n",
      "[iter 0] loss=12.6789 val_loss=12.5477 scale=2.0000 norm=117449.9838\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL47 (val_loss=11.4285)\n",
      "[iter 0] loss=12.6866 val_loss=12.5360 scale=2.0000 norm=117817.6941\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL47 (val_loss=11.3558)\n",
      "[iter 0] loss=12.7516 val_loss=12.5612 scale=2.0000 norm=127281.1614\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL44 (val_loss=11.4813)\n",
      "[iter 0] loss=12.6980 val_loss=12.5369 scale=2.0000 norm=117565.2260\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL46 (val_loss=11.4897)\n",
      "[iter 0] loss=12.6740 val_loss=12.5239 scale=2.0000 norm=116204.7415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:53:18,334]\u001B[0m Trial 9 finished with value: -911117485.5259203 and parameters: {'base_learner': 'GradientBoost_depth5', 'Dist': 'Normal', 'n_estimators': 44067, 'minibatch_frac': 0.7457541934249898, 'learning_rate': 0.03379871392671105}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL49 (val_loss=11.3478)\n",
      "[iter 0] loss=12.5746 val_loss=12.4443 scale=2.0000 norm=1.3562\n",
      "[iter 100] loss=11.4145 val_loss=11.4820 scale=2.0000 norm=0.8739\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL189 (val_loss=11.2110)\n",
      "[iter 0] loss=12.5930 val_loss=12.4456 scale=2.0000 norm=1.3958\n",
      "[iter 100] loss=11.4182 val_loss=11.4903 scale=2.0000 norm=0.8835\n",
      "[iter 200] loss=10.9178 val_loss=11.2022 scale=2.0000 norm=0.8812\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL194 (val_loss=11.1998)\n",
      "[iter 0] loss=12.6687 val_loss=12.4537 scale=2.0000 norm=1.3949\n",
      "[iter 100] loss=11.4325 val_loss=11.4971 scale=2.0000 norm=0.8549\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL180 (val_loss=11.2384)\n",
      "[iter 0] loss=12.6384 val_loss=12.4513 scale=2.0000 norm=1.4428\n",
      "[iter 100] loss=11.3917 val_loss=11.5162 scale=2.0000 norm=0.8580\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL175 (val_loss=11.2713)\n",
      "[iter 0] loss=12.6601 val_loss=12.4413 scale=2.0000 norm=1.4335\n",
      "[iter 100] loss=11.3786 val_loss=11.5070 scale=2.0000 norm=0.8452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:53:58,944]\u001B[0m Trial 10 finished with value: -872849504.6309563 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 27940, 'minibatch_frac': 0.40496666318149277, 'learning_rate': 0.011729289815382935}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL181 (val_loss=11.2565)\n",
      "[iter 0] loss=12.5634 val_loss=12.4436 scale=2.0000 norm=1.3483\n",
      "[iter 100] loss=11.3464 val_loss=11.4315 scale=2.0000 norm=0.8641\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL168 (val_loss=11.2251)\n",
      "[iter 0] loss=12.5797 val_loss=12.4465 scale=2.0000 norm=1.3829\n",
      "[iter 100] loss=11.3428 val_loss=11.4333 scale=2.0000 norm=0.8748\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL179 (val_loss=11.2110)\n",
      "[iter 0] loss=12.6533 val_loss=12.4525 scale=2.0000 norm=1.3820\n",
      "[iter 100] loss=11.3573 val_loss=11.4368 scale=2.0000 norm=0.8516\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL160 (val_loss=11.2473)\n",
      "[iter 0] loss=12.6220 val_loss=12.4516 scale=2.0000 norm=1.4261\n",
      "[iter 100] loss=11.3135 val_loss=11.4657 scale=2.0000 norm=0.8546\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL160 (val_loss=11.2801)\n",
      "[iter 0] loss=12.6445 val_loss=12.4400 scale=2.0000 norm=1.4153\n",
      "[iter 100] loss=11.2983 val_loss=11.4513 scale=2.0000 norm=0.8408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:54:37,660]\u001B[0m Trial 11 finished with value: -887215769.2003676 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 26987, 'minibatch_frac': 0.41827308439470645, 'learning_rate': 0.012773172253446092}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL168 (val_loss=11.2584)\n",
      "[iter 0] loss=12.5764 val_loss=12.4532 scale=2.0000 norm=1.3576\n",
      "[iter 100] loss=11.7232 val_loss=11.7576 scale=2.0000 norm=0.8936\n",
      "[iter 200] loss=11.2391 val_loss=11.3350 scale=2.0000 norm=0.8873\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL289 (val_loss=11.2164)\n",
      "[iter 0] loss=12.5949 val_loss=12.4549 scale=2.0000 norm=1.3974\n",
      "[iter 100] loss=11.7320 val_loss=11.7656 scale=2.0000 norm=0.8997\n",
      "[iter 200] loss=11.2394 val_loss=11.3394 scale=2.0000 norm=0.8662\n",
      "[iter 300] loss=10.9227 val_loss=11.2062 scale=2.0000 norm=0.7968\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL293 (val_loss=11.2059)\n",
      "[iter 0] loss=12.6707 val_loss=12.4606 scale=2.0000 norm=1.3964\n",
      "[iter 100] loss=11.7582 val_loss=11.7765 scale=2.0000 norm=0.8773\n",
      "[iter 200] loss=11.2109 val_loss=11.3447 scale=2.0000 norm=0.8454\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL283 (val_loss=11.2314)\n",
      "[iter 0] loss=12.6404 val_loss=12.4573 scale=2.0000 norm=1.4446\n",
      "[iter 100] loss=11.7146 val_loss=11.7886 scale=2.0000 norm=0.8771\n",
      "[iter 200] loss=11.1671 val_loss=11.3680 scale=2.0000 norm=0.8496\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL279 (val_loss=11.2618)\n",
      "[iter 0] loss=12.6618 val_loss=12.4499 scale=2.0000 norm=1.4354\n",
      "[iter 100] loss=11.6939 val_loss=11.7779 scale=2.0000 norm=0.8635\n",
      "[iter 200] loss=11.1773 val_loss=11.3672 scale=2.0000 norm=0.8345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:55:38,365]\u001B[0m Trial 12 finished with value: -891300848.9282259 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 18570, 'minibatch_frac': 0.40385848761655185, 'learning_rate': 0.007503150947677386}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL289 (val_loss=11.2623)\n",
      "[iter 0] loss=12.5661 val_loss=12.4602 scale=2.0000 norm=1.3362\n",
      "[iter 100] loss=12.0954 val_loss=12.1106 scale=2.0000 norm=0.9116\n",
      "[iter 200] loss=11.8122 val_loss=11.8553 scale=2.0000 norm=0.8939\n",
      "[iter 300] loss=11.5496 val_loss=11.6307 scale=2.0000 norm=0.8734\n",
      "[iter 400] loss=11.3301 val_loss=11.4494 scale=2.0000 norm=0.8623\n",
      "[iter 500] loss=11.1899 val_loss=11.3207 scale=2.0000 norm=0.8458\n",
      "[iter 600] loss=10.9799 val_loss=11.2515 scale=2.0000 norm=0.8494\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL670 (val_loss=11.2351)\n",
      "[iter 0] loss=12.5797 val_loss=12.4635 scale=2.0000 norm=1.3629\n",
      "[iter 100] loss=12.1065 val_loss=12.1145 scale=2.0000 norm=0.9227\n",
      "[iter 200] loss=11.8197 val_loss=11.8585 scale=2.0000 norm=0.9036\n",
      "[iter 300] loss=11.5713 val_loss=11.6327 scale=2.0000 norm=0.8721\n",
      "[iter 400] loss=11.3377 val_loss=11.4481 scale=2.0000 norm=0.8664\n",
      "[iter 500] loss=11.1835 val_loss=11.3136 scale=2.0000 norm=0.8274\n",
      "[iter 600] loss=10.9736 val_loss=11.2359 scale=2.0000 norm=0.8266\n",
      "[iter 700] loss=10.8903 val_loss=11.2077 scale=2.0000 norm=0.8043\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL698 (val_loss=11.2075)\n",
      "[iter 0] loss=12.6443 val_loss=12.4684 scale=2.0000 norm=1.3463\n",
      "[iter 100] loss=12.1445 val_loss=12.1241 scale=2.0000 norm=0.9099\n",
      "[iter 200] loss=11.8296 val_loss=11.8641 scale=2.0000 norm=0.8881\n",
      "[iter 300] loss=11.5766 val_loss=11.6343 scale=2.0000 norm=0.8738\n",
      "[iter 400] loss=11.3506 val_loss=11.4456 scale=2.0000 norm=0.8627\n",
      "[iter 500] loss=11.1946 val_loss=11.3098 scale=2.0000 norm=0.8265\n",
      "[iter 600] loss=10.9670 val_loss=11.2350 scale=2.0000 norm=0.7976\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL671 (val_loss=11.2185)\n",
      "[iter 0] loss=12.6063 val_loss=12.4636 scale=2.0000 norm=1.3856\n",
      "[iter 100] loss=12.1000 val_loss=12.1313 scale=2.0000 norm=0.9156\n",
      "[iter 200] loss=11.7773 val_loss=11.8789 scale=2.0000 norm=0.8968\n",
      "[iter 300] loss=11.5410 val_loss=11.6567 scale=2.0000 norm=0.8846\n",
      "[iter 400] loss=11.2993 val_loss=11.4758 scale=2.0000 norm=0.8890\n",
      "[iter 500] loss=11.1694 val_loss=11.3524 scale=2.0000 norm=0.8412\n",
      "[iter 600] loss=10.9393 val_loss=11.2944 scale=2.0000 norm=0.8133\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL652 (val_loss=11.2875)\n",
      "[iter 0] loss=12.5975 val_loss=12.4583 scale=2.0000 norm=1.3580\n",
      "[iter 100] loss=12.0729 val_loss=12.1152 scale=2.0000 norm=0.8913\n",
      "[iter 200] loss=11.7742 val_loss=11.8606 scale=2.0000 norm=0.8892\n",
      "[iter 300] loss=11.5438 val_loss=11.6423 scale=2.0000 norm=0.8784\n",
      "[iter 400] loss=11.3152 val_loss=11.4661 scale=2.0000 norm=0.8650\n",
      "[iter 500] loss=11.1653 val_loss=11.3458 scale=2.0000 norm=0.8339\n",
      "[iter 600] loss=11.0246 val_loss=11.2848 scale=2.0000 norm=0.8135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:58:23,751]\u001B[0m Trial 13 finished with value: -888160635.7218754 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 32993, 'minibatch_frac': 0.4824556089595179, 'learning_rate': 0.0031380954406529694}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL674 (val_loss=11.2734)\n",
      "[iter 0] loss=12.5496 val_loss=12.4057 scale=2.0000 norm=1.3247\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL65 (val_loss=11.2164)\n",
      "[iter 0] loss=12.5625 val_loss=12.4070 scale=2.0000 norm=1.3498\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL64 (val_loss=11.2036)\n",
      "[iter 0] loss=12.6297 val_loss=12.4144 scale=2.0000 norm=1.3386\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL61 (val_loss=11.2295)\n",
      "[iter 0] loss=12.5899 val_loss=12.4083 scale=2.0000 norm=1.3704\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL58 (val_loss=11.2826)\n",
      "[iter 0] loss=12.5842 val_loss=12.4052 scale=2.0000 norm=1.3435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:58:41,033]\u001B[0m Trial 14 finished with value: -893760424.0994594 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 12880, 'minibatch_frac': 0.5010206591472192, 'learning_rate': 0.03355684893970818}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL63 (val_loss=11.2551)\n",
      "[iter 0] loss=12.7201 val_loss=12.5750 scale=2.0000 norm=118528.1665\n",
      "[iter 100] loss=11.2810 val_loss=11.6328 scale=2.0000 norm=22579.3879\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL108 (val_loss=11.6226)\n",
      "[iter 0] loss=12.7221 val_loss=12.5651 scale=2.0000 norm=118044.3562\n",
      "[iter 100] loss=11.2616 val_loss=11.4914 scale=2.0000 norm=21825.9255\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL124 (val_loss=11.4380)\n",
      "[iter 0] loss=12.7715 val_loss=12.5881 scale=2.0000 norm=126495.4393\n",
      "[iter 100] loss=11.3200 val_loss=11.5707 scale=2.0000 norm=24012.4486\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL119 (val_loss=11.5311)\n",
      "[iter 0] loss=12.7389 val_loss=12.5643 scale=2.0000 norm=118308.1225\n",
      "[iter 100] loss=11.2238 val_loss=11.6768 scale=2.0000 norm=20332.1220\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL99 (val_loss=11.6764)\n",
      "[iter 0] loss=12.6875 val_loss=12.5541 scale=2.0000 norm=116132.5832\n",
      "[iter 100] loss=11.2449 val_loss=11.4899 scale=2.0000 norm=22298.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 06:59:44,825]\u001B[0m Trial 15 finished with value: -1002927120.8404438 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'Normal', 'n_estimators': 35713, 'minibatch_frac': 0.9414549020007512, 'learning_rate': 0.014726569441982914}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL127 (val_loss=11.4352)\n",
      "[iter 0] loss=12.5764 val_loss=12.4114 scale=2.0000 norm=1.3515\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL62 (val_loss=11.2500)\n",
      "[iter 0] loss=12.5932 val_loss=12.4085 scale=2.0000 norm=1.3850\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL66 (val_loss=11.2199)\n",
      "[iter 0] loss=12.6680 val_loss=12.4164 scale=2.0000 norm=1.3855\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL64 (val_loss=11.2325)\n",
      "[iter 0] loss=12.6393 val_loss=12.4181 scale=2.0000 norm=1.4320\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL62 (val_loss=11.3033)\n",
      "[iter 0] loss=12.6438 val_loss=12.4015 scale=2.0000 norm=1.4113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 07:00:00,747]\u001B[0m Trial 16 finished with value: -887966273.9122204 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 18617, 'minibatch_frac': 0.4281498025125121, 'learning_rate': 0.03248804347663259}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL62 (val_loss=11.2824)\n",
      "[iter 0] loss=12.5522 val_loss=12.4453 scale=2.0000 norm=1.3297\n",
      "[iter 100] loss=11.4256 val_loss=11.5553 scale=2.0000 norm=0.9082\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL171 (val_loss=11.2773)\n",
      "[iter 0] loss=12.5486 val_loss=12.4476 scale=2.0000 norm=1.3279\n",
      "[iter 100] loss=11.4353 val_loss=11.5542 scale=2.0000 norm=0.9093\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL182 (val_loss=11.2239)\n",
      "[iter 0] loss=12.6120 val_loss=12.4538 scale=2.0000 norm=1.3224\n",
      "[iter 100] loss=11.4697 val_loss=11.5785 scale=2.0000 norm=0.9117\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL171 (val_loss=11.2978)\n",
      "[iter 0] loss=12.5706 val_loss=12.4496 scale=2.0000 norm=1.3555\n",
      "[iter 100] loss=11.4119 val_loss=11.6214 scale=2.0000 norm=0.9100\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL161 (val_loss=11.3937)\n",
      "[iter 0] loss=12.5752 val_loss=12.4508 scale=2.0000 norm=1.3426\n",
      "[iter 100] loss=11.4024 val_loss=11.5746 scale=2.0000 norm=0.9032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 07:01:34,456]\u001B[0m Trial 17 finished with value: -878151935.1915381 and parameters: {'base_learner': 'GradientBoost_depth5', 'Dist': 'LogNormal', 'n_estimators': 33040, 'minibatch_frac': 0.5777341650804667, 'learning_rate': 0.00983752593537482}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL168 (val_loss=11.3173)\n",
      "[iter 0] loss=12.5699 val_loss=12.4585 scale=2.0000 norm=1.3393\n",
      "[iter 100] loss=11.9867 val_loss=12.0071 scale=2.0000 norm=0.9009\n",
      "[iter 200] loss=11.6271 val_loss=11.6782 scale=2.0000 norm=0.8890\n",
      "[iter 300] loss=11.3045 val_loss=11.4249 scale=2.0000 norm=0.8480\n",
      "[iter 400] loss=11.0664 val_loss=11.2725 scale=2.0000 norm=0.8359\n",
      "[iter 500] loss=10.9302 val_loss=11.2278 scale=2.0000 norm=0.8390\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL500 (val_loss=11.2278)\n",
      "[iter 0] loss=12.5844 val_loss=12.4605 scale=2.0000 norm=1.3659\n",
      "[iter 100] loss=11.9989 val_loss=12.0168 scale=2.0000 norm=0.9117\n",
      "[iter 200] loss=11.6395 val_loss=11.6894 scale=2.0000 norm=0.8954\n",
      "[iter 300] loss=11.3230 val_loss=11.4304 scale=2.0000 norm=0.8429\n",
      "[iter 400] loss=11.0748 val_loss=11.2696 scale=2.0000 norm=0.8245\n",
      "[iter 500] loss=10.9334 val_loss=11.2101 scale=2.0000 norm=0.7991\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL515 (val_loss=11.2093)\n",
      "[iter 0] loss=12.6514 val_loss=12.4653 scale=2.0000 norm=1.3502\n",
      "[iter 100] loss=12.0345 val_loss=12.0256 scale=2.0000 norm=0.8965\n",
      "[iter 200] loss=11.6412 val_loss=11.6904 scale=2.0000 norm=0.8817\n",
      "[iter 300] loss=11.3243 val_loss=11.4285 scale=2.0000 norm=0.8459\n",
      "[iter 400] loss=11.0797 val_loss=11.2700 scale=2.0000 norm=0.8176\n",
      "[iter 500] loss=10.9482 val_loss=11.2257 scale=2.0000 norm=0.7996\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL495 (val_loss=11.2254)\n",
      "[iter 0] loss=12.6118 val_loss=12.4615 scale=2.0000 norm=1.3898\n",
      "[iter 100] loss=11.9918 val_loss=12.0340 scale=2.0000 norm=0.9016\n",
      "[iter 200] loss=11.5938 val_loss=11.7115 scale=2.0000 norm=0.8900\n",
      "[iter 300] loss=11.2929 val_loss=11.4621 scale=2.0000 norm=0.8668\n",
      "[iter 400] loss=11.0250 val_loss=11.3148 scale=2.0000 norm=0.8489\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL475 (val_loss=11.2839)\n",
      "[iter 0] loss=12.6124 val_loss=12.4562 scale=2.0000 norm=1.3700\n",
      "[iter 100] loss=11.9649 val_loss=12.0168 scale=2.0000 norm=0.8837\n",
      "[iter 200] loss=11.5918 val_loss=11.6952 scale=2.0000 norm=0.8786\n",
      "[iter 300] loss=11.3066 val_loss=11.4491 scale=2.0000 norm=0.8595\n",
      "[iter 400] loss=11.0559 val_loss=11.3057 scale=2.0000 norm=0.8216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 07:03:32,753]\u001B[0m Trial 18 finished with value: -887414800.4907106 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 20406, 'minibatch_frac': 0.467545359993562, 'learning_rate': 0.004314063438935396}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL487 (val_loss=11.2670)\n",
      "[iter 0] loss=13.0899 val_loss=13.1066 scale=2.0000 norm=0.6528\n",
      "[iter 100] loss=13.0944 val_loss=13.0820 scale=2.0000 norm=0.4850\n",
      "[iter 200] loss=13.0675 val_loss=13.0680 scale=2.0000 norm=0.3567\n",
      "[iter 300] loss=13.0561 val_loss=13.0598 scale=2.0000 norm=0.2778\n",
      "[iter 400] loss=13.0381 val_loss=13.0547 scale=2.0000 norm=0.2105\n",
      "[iter 500] loss=13.0440 val_loss=13.0516 scale=2.0000 norm=0.1873\n",
      "[iter 600] loss=13.0238 val_loss=13.0497 scale=2.0000 norm=0.1658\n",
      "[iter 700] loss=13.0488 val_loss=13.0484 scale=2.0000 norm=0.1455\n",
      "[iter 800] loss=13.0305 val_loss=13.0476 scale=2.0000 norm=0.1466\n",
      "[iter 900] loss=13.0567 val_loss=13.0469 scale=2.0000 norm=0.1257\n",
      "[iter 1000] loss=13.0272 val_loss=13.0465 scale=4.0000 norm=0.2445\n",
      "[iter 1100] loss=13.0275 val_loss=13.0462 scale=4.0000 norm=0.2273\n",
      "[iter 1200] loss=13.0519 val_loss=13.0460 scale=4.0000 norm=0.2240\n",
      "[iter 1300] loss=13.0400 val_loss=13.0459 scale=4.0000 norm=0.2321\n",
      "[iter 1400] loss=13.0598 val_loss=13.0458 scale=4.0000 norm=0.2214\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1476 (val_loss=13.0457)\n",
      "[iter 0] loss=13.0890 val_loss=13.1066 scale=2.0000 norm=0.6435\n",
      "[iter 100] loss=13.0872 val_loss=13.0815 scale=2.0000 norm=0.4940\n",
      "[iter 200] loss=13.0706 val_loss=13.0672 scale=2.0000 norm=0.3677\n",
      "[iter 300] loss=13.0524 val_loss=13.0591 scale=2.0000 norm=0.2949\n",
      "[iter 400] loss=13.0435 val_loss=13.0541 scale=2.0000 norm=0.2088\n",
      "[iter 500] loss=13.0276 val_loss=13.0510 scale=2.0000 norm=0.1971\n",
      "[iter 600] loss=13.0248 val_loss=13.0490 scale=2.0000 norm=0.1599\n",
      "[iter 700] loss=13.0183 val_loss=13.0479 scale=2.0000 norm=0.1471\n",
      "[iter 800] loss=13.0220 val_loss=13.0471 scale=4.0000 norm=0.2834\n",
      "[iter 900] loss=13.0390 val_loss=13.0464 scale=2.0000 norm=0.1281\n",
      "[iter 1000] loss=13.0291 val_loss=13.0460 scale=4.0000 norm=0.2457\n",
      "[iter 1100] loss=13.0379 val_loss=13.0458 scale=4.0000 norm=0.2333\n",
      "[iter 1200] loss=13.0398 val_loss=13.0456 scale=4.0000 norm=0.2257\n",
      "[iter 1300] loss=13.0349 val_loss=13.0455 scale=4.0000 norm=0.2401\n",
      "[iter 1400] loss=13.0567 val_loss=13.0454 scale=4.0000 norm=0.2215\n",
      "[iter 1500] loss=13.0249 val_loss=13.0453 scale=4.0000 norm=0.2118\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1558 (val_loss=13.0453)\n",
      "[iter 0] loss=13.1294 val_loss=13.1070 scale=2.0000 norm=0.6903\n",
      "[iter 100] loss=13.1049 val_loss=13.0825 scale=2.0000 norm=0.5172\n",
      "[iter 200] loss=13.0870 val_loss=13.0682 scale=2.0000 norm=0.3710\n",
      "[iter 300] loss=13.0539 val_loss=13.0598 scale=2.0000 norm=0.3063\n",
      "[iter 400] loss=13.0601 val_loss=13.0547 scale=2.0000 norm=0.2154\n",
      "[iter 500] loss=13.0439 val_loss=13.0514 scale=2.0000 norm=0.2030\n",
      "[iter 600] loss=13.0423 val_loss=13.0494 scale=2.0000 norm=0.1598\n",
      "[iter 700] loss=13.0377 val_loss=13.0481 scale=2.0000 norm=0.1508\n",
      "[iter 800] loss=13.0423 val_loss=13.0473 scale=2.0000 norm=0.1424\n",
      "[iter 900] loss=13.0646 val_loss=13.0467 scale=2.0000 norm=0.1299\n",
      "[iter 1000] loss=13.0469 val_loss=13.0462 scale=4.0000 norm=0.2474\n",
      "[iter 1100] loss=13.0557 val_loss=13.0460 scale=4.0000 norm=0.2295\n",
      "[iter 1200] loss=13.0688 val_loss=13.0458 scale=4.0000 norm=0.2272\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1289 (val_loss=13.0457)\n",
      "[iter 0] loss=13.0955 val_loss=13.1066 scale=2.0000 norm=0.6563\n",
      "[iter 100] loss=13.0720 val_loss=13.0831 scale=2.0000 norm=0.4913\n",
      "[iter 200] loss=13.0523 val_loss=13.0698 scale=2.0000 norm=0.3573\n",
      "[iter 300] loss=13.0149 val_loss=13.0614 scale=2.0000 norm=0.2901\n",
      "[iter 400] loss=13.0462 val_loss=13.0563 scale=2.0000 norm=0.2014\n",
      "[iter 500] loss=13.0331 val_loss=13.0529 scale=2.0000 norm=0.1975\n",
      "[iter 600] loss=13.0059 val_loss=13.0507 scale=2.0000 norm=0.1623\n",
      "[iter 700] loss=12.9982 val_loss=13.0493 scale=2.0000 norm=0.1463\n",
      "[iter 800] loss=13.0110 val_loss=13.0484 scale=4.0000 norm=0.2833\n",
      "[iter 900] loss=13.0287 val_loss=13.0477 scale=2.0000 norm=0.1323\n",
      "[iter 1000] loss=13.0188 val_loss=13.0472 scale=4.0000 norm=0.2388\n",
      "[iter 1100] loss=13.0306 val_loss=13.0469 scale=4.0000 norm=0.2263\n",
      "[iter 1200] loss=13.0409 val_loss=13.0467 scale=4.0000 norm=0.2157\n",
      "[iter 1300] loss=13.0290 val_loss=13.0465 scale=4.0000 norm=0.2216\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1324 (val_loss=13.0465)\n",
      "[iter 0] loss=13.1089 val_loss=13.1066 scale=2.0000 norm=0.6663\n",
      "[iter 100] loss=13.0727 val_loss=13.0814 scale=2.0000 norm=0.4642\n",
      "[iter 200] loss=13.0463 val_loss=13.0682 scale=2.0000 norm=0.3557\n",
      "[iter 300] loss=13.0268 val_loss=13.0601 scale=2.0000 norm=0.2839\n",
      "[iter 400] loss=13.0532 val_loss=13.0552 scale=2.0000 norm=0.2101\n",
      "[iter 500] loss=13.0257 val_loss=13.0520 scale=2.0000 norm=0.1984\n",
      "[iter 600] loss=13.0365 val_loss=13.0501 scale=2.0000 norm=0.1696\n",
      "[iter 700] loss=13.0028 val_loss=13.0488 scale=2.0000 norm=0.1543\n",
      "[iter 800] loss=13.0232 val_loss=13.0479 scale=2.0000 norm=0.1485\n",
      "[iter 900] loss=13.0606 val_loss=13.0473 scale=4.0000 norm=0.2714\n",
      "[iter 1000] loss=13.0191 val_loss=13.0468 scale=4.0000 norm=0.2481\n",
      "[iter 1100] loss=13.0392 val_loss=13.0466 scale=4.0000 norm=0.2393\n",
      "[iter 1200] loss=13.0364 val_loss=13.0464 scale=8.0000 norm=0.4807\n",
      "[iter 1300] loss=13.0281 val_loss=13.0463 scale=4.0000 norm=0.2309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-18 07:07:26,741]\u001B[0m Trial 19 finished with value: -926847209.8508819 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'Exponential', 'n_estimators': 10905, 'minibatch_frac': 0.5650347385428828, 'learning_rate': 0.0017143428470539858}. Best is trial 0 with value: -868366768.6671002.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1317 (val_loss=13.0463)\n",
      "[iter 0] loss=12.5986 val_loss=12.4423 scale=2.0000 norm=1.3468\n",
      "[iter 100] loss=11.2160 val_loss=11.3539 scale=2.0000 norm=0.8273\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL146 (val_loss=11.2400)\n",
      "Started Predict with Ngboost at 07:07:35.\n",
      "The R2 score is 0.8894877021795203\n",
      "The MAE score is 15826.206975129666\n",
      "The Median absolute error score is 10269.211140466694\n",
      "The MSE score is 23323.225503848906\n",
      "The RMSE score is 543972847.903388\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this case we chose Ngboost, which is uses natural gradient. It is really strong for regression problem, but\n",
    "does not have GPU acceleration at all unfortunately. However we always recommend trying Ngboost if posible.\n",
    "\"\"\"\n",
    "housing_ml.ml_bp14_regressions_full_processing_ngboost(preprocessing_type='nlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pipeline\n",
    "save_to_production(housing_ml, file_name='housing_automl_instance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on new data\n",
    "In the beginning we kept a holdout dataset. We use this to simulate prediction on completely new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stored pipeline\n",
    "housing_ml_loaded = load_for_production(file_name='housing_automl_instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Execute test train split at 07:07:35.\n",
      "Started Apply datetime transformation at 07:07:35.\n",
      "Started Handle rare features at 07:07:35.\n",
      "Started Remove cardinality at 07:07:35.\n",
      "Started Onehot + PCA categorical features at 07:07:35.\n",
      "Started Execute categorical encoding at 07:07:35.\n",
      "Started  Delete columns with high share of NULLs at 07:07:35.\n",
      "Started Fill nulls at 07:07:35.\n",
      "Started Execute numerical binning at 07:07:35.\n",
      "Started Handle outliers at 07:07:36.\n",
      "Started Remove collinearity at 07:07:36.\n",
      "Started Execute clustering as a feature at 07:07:36.\n",
      "Started Execute clustering as a feature at 07:07:36.\n",
      "Started Execute clustering as a feature at 07:07:36.\n",
      "Started Execute clustering as a feature at 07:07:36.\n",
      "Started Execute clustering as a feature at 07:07:36.\n",
      "Started Execute clustering as a feature at 07:07:37.\n",
      "Started Execute clustering as a feature at 07:07:37.\n",
      "Started Execute clustering as a feature at 07:07:37.\n",
      "Started Execute clustering as a feature at 07:07:37.\n",
      "Started Select best features at 07:07:37.\n",
      "Started Sort columns alphabetically at 07:07:37.\n",
      "Started Predict with Ngboost at 07:07:37.\n"
     ]
    }
   ],
   "source": [
    "# predict on new data\n",
    "housing_ml_loaded.ml_bp14_regressions_full_processing_ngboost(val_df, preprocessing_type='full')\n",
    "\n",
    "# access predicted labels\n",
    "val_y_hat = housing_ml_loaded.predicted_values['ngboost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16054.641582630808\n"
     ]
    }
   ],
   "source": [
    "# Assess prediction quality on holdout data\n",
    "mae = mean_absolute_error(val_df_target, val_y_hat)\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Titanic survival classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from e2eml.regression import regression_blueprints as rb\n",
    "from e2eml.full_processing.postprocessing import save_to_production, load_for_production\n",
    "from e2eml.test.regression_blueprints_test import load_housingprices_data\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "Load & preprocess housing prices dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do dataframe splits.\n"
     ]
    }
   ],
   "source": [
    "# load Housing price data\n",
    "test_df, test_target, val_df, val_df_target, test_categorical_cols = load_housingprices_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using e2eml - Run and save a pipeline\n",
    "We only need a few steps to get ur full pipeline:\n",
    "- Instantiate class\n",
    "- Run chosen blueprint\n",
    "- Save blueprint for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferred training mode auto has been chosen. e2eml will automatically detect, if LGBM and Xgboost canuse GPU acceleration and optimize the workflow accordingly.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate class\n",
    "housing_ml = rb.RegressionBluePrint(datasource=test_df,\n",
    "                                         target_variable=test_target,\n",
    "                                         categorical_columns=test_categorical_cols, # here we specify cat columns (that is optional however)\n",
    "                                         preferred_training_mode='auto',\n",
    "                                         tune_mode='accurate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Execute test train split at 15:27:37.\n",
      "Started Apply datetime transformation at 15:27:37.\n",
      "Started Start Spacy, POS tagging + PCA at 15:27:37.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 800 entries, 613 to 470\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             800 non-null    int64  \n",
      " 1   MSSubClass     800 non-null    int64  \n",
      " 2   MSZoning       800 non-null    object \n",
      " 3   LotFrontage    661 non-null    float64\n",
      " 4   LotArea        800 non-null    int64  \n",
      " 5   Street         800 non-null    object \n",
      " 6   Alley          51 non-null     object \n",
      " 7   LotShape       800 non-null    object \n",
      " 8   LandContour    800 non-null    object \n",
      " 9   Utilities      800 non-null    object \n",
      " 10  LotConfig      800 non-null    object \n",
      " 11  LandSlope      800 non-null    object \n",
      " 12  Neighborhood   800 non-null    object \n",
      " 13  Condition1     800 non-null    object \n",
      " 14  Condition2     800 non-null    object \n",
      " 15  BldgType       800 non-null    object \n",
      " 16  HouseStyle     800 non-null    object \n",
      " 17  OverallQual    800 non-null    int64  \n",
      " 18  OverallCond    800 non-null    int64  \n",
      " 19  YearBuilt      800 non-null    int64  \n",
      " 20  YearRemodAdd   800 non-null    int64  \n",
      " 21  RoofStyle      800 non-null    object \n",
      " 22  RoofMatl       800 non-null    object \n",
      " 23  Exterior1st    800 non-null    object \n",
      " 24  Exterior2nd    800 non-null    object \n",
      " 25  MasVnrType     794 non-null    object \n",
      " 26  MasVnrArea     794 non-null    float64\n",
      " 27  ExterQual      800 non-null    object \n",
      " 28  ExterCond      800 non-null    object \n",
      " 29  Foundation     800 non-null    object \n",
      " 30  BsmtQual       783 non-null    object \n",
      " 31  BsmtCond       783 non-null    object \n",
      " 32  BsmtExposure   782 non-null    object \n",
      " 33  BsmtFinType1   783 non-null    object \n",
      " 34  BsmtFinSF1     800 non-null    int64  \n",
      " 35  BsmtFinType2   783 non-null    object \n",
      " 36  BsmtFinSF2     800 non-null    int64  \n",
      " 37  BsmtUnfSF      800 non-null    int64  \n",
      " 38  TotalBsmtSF    800 non-null    int64  \n",
      " 39  Heating        800 non-null    object \n",
      " 40  HeatingQC      800 non-null    object \n",
      " 41  CentralAir     800 non-null    object \n",
      " 42  Electrical     800 non-null    object \n",
      " 43  1stFlrSF       800 non-null    int64  \n",
      " 44  2ndFlrSF       800 non-null    int64  \n",
      " 45  LowQualFinSF   800 non-null    int64  \n",
      " 46  GrLivArea      800 non-null    int64  \n",
      " 47  BsmtFullBath   800 non-null    int64  \n",
      " 48  BsmtHalfBath   800 non-null    int64  \n",
      " 49  FullBath       800 non-null    int64  \n",
      " 50  HalfBath       800 non-null    int64  \n",
      " 51  BedroomAbvGr   800 non-null    int64  \n",
      " 52  KitchenAbvGr   800 non-null    int64  \n",
      " 53  KitchenQual    800 non-null    object \n",
      " 54  TotRmsAbvGrd   800 non-null    int64  \n",
      " 55  Functional     800 non-null    object \n",
      " 56  Fireplaces     800 non-null    int64  \n",
      " 57  FireplaceQu    413 non-null    object \n",
      " 58  GarageType     757 non-null    object \n",
      " 59  GarageYrBlt    757 non-null    float64\n",
      " 60  GarageFinish   757 non-null    object \n",
      " 61  GarageCars     800 non-null    int64  \n",
      " 62  GarageArea     800 non-null    int64  \n",
      " 63  GarageQual     757 non-null    object \n",
      " 64  GarageCond     757 non-null    object \n",
      " 65  PavedDrive     800 non-null    object \n",
      " 66  WoodDeckSF     800 non-null    int64  \n",
      " 67  OpenPorchSF    800 non-null    int64  \n",
      " 68  EnclosedPorch  800 non-null    int64  \n",
      " 69  3SsnPorch      800 non-null    int64  \n",
      " 70  ScreenPorch    800 non-null    int64  \n",
      " 71  PoolArea       800 non-null    int64  \n",
      " 72  PoolQC         2 non-null      object \n",
      " 73  Fence          159 non-null    object \n",
      " 74  MiscFeature    34 non-null     object \n",
      " 75  MiscVal        800 non-null    int64  \n",
      " 76  MoSold         800 non-null    int64  \n",
      " 77  YrSold         800 non-null    int64  \n",
      " 78  SaleType       800 non-null    object \n",
      " 79  SaleCondition  800 non-null    object \n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 506.2+ KB\n",
      "None\n",
      "Started Handle rare features at 15:27:37.\n",
      "Started Remove cardinality at 15:27:37.\n",
      "Started Onehot + PCA categorical features at 15:27:38.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Execute categorical encoding at 15:27:38.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started  Delete columns with high share of NULLs at 15:27:38.\n",
      "Started Fill nulls at 15:27:39.\n",
      "Started Execute numerical binning at 15:27:39.\n",
      "Started Handle outliers at 15:27:39.\n",
      "Started Remove collinearity at 15:27:39.\n",
      "Started Execute clustering as a feature at 15:27:40.\n",
      "Started Scale data at 15:27:40.\n",
      "Started Execute clustering as a feature at 15:27:40.\n",
      "Started Execute clustering as a feature at 15:27:41.\n",
      "Started Execute clustering as a feature at 15:27:41.\n",
      "Started Execute clustering as a feature at 15:27:42.\n",
      "Started Execute clustering as a feature at 15:27:42.\n",
      "Started Execute clustering as a feature at 15:27:43.\n",
      "Started Execute clustering as a feature at 15:27:43.\n",
      "Started Execute clustering as a feature at 15:27:44.\n",
      "Started Select best features at 15:27:45.\n",
      "Id\n",
      "MSSubClass\n",
      "MSZoning\n",
      "LotFrontage\n",
      "LotArea\n",
      "Street\n",
      "Alley\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition1\n",
      "Condition2\n",
      "BldgType\n",
      "HouseStyle\n",
      "OverallQual\n",
      "OverallCond\n",
      "YearBuilt\n",
      "YearRemodAdd\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "MasVnrType\n",
      "MasVnrArea\n",
      "ExterQual\n",
      "ExterCond\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinSF1\n",
      "BsmtFinType2\n",
      "BsmtFinSF2\n",
      "BsmtUnfSF\n",
      "TotalBsmtSF\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "2ndFlrSF\n",
      "LowQualFinSF\n",
      "GrLivArea\n",
      "BsmtFullBath\n",
      "BsmtHalfBath\n",
      "FullBath\n",
      "HalfBath\n",
      "BedroomAbvGr\n",
      "KitchenAbvGr\n",
      "KitchenQual\n",
      "Functional\n",
      "Fireplaces\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageYrBlt\n",
      "GarageFinish\n",
      "GarageCars\n",
      "PavedDrive\n",
      "WoodDeckSF\n",
      "OpenPorchSF\n",
      "EnclosedPorch\n",
      "3SsnPorch\n",
      "ScreenPorch\n",
      "PoolArea\n",
      "Fence\n",
      "MiscFeature\n",
      "MiscVal\n",
      "MoSold\n",
      "YrSold\n",
      "SaleType\n",
      "PC-1_pca\n",
      "PC-2_pca\n",
      "isolation_probs\n",
      "isolation_class\n",
      "dbscan_cluster\n",
      "kmeans_clusters2\n",
      "kmeans_clusters3\n",
      "kmeans_clusters4\n",
      "kmeans_clusters5\n",
      "kmeans_clusters6\n",
      "kmeans_clusters7\n",
      "kmeans_clusters8\n",
      "kmeans_clusters9\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  1\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  2\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  3\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  4\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  5\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  6\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  7\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  8\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  9\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  10\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  1\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  2\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  3\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  4\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  5\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  6\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  7\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  8\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  9\n",
      "[15:27:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1607619219243/work/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  10\n",
      "BoostARoota ran successfully! Algorithm went through  2  rounds.\n",
      " Selected features are... Id.\n",
      " Selected features are... MSSubClass.\n",
      " Selected features are... MSZoning.\n",
      " Selected features are... LotFrontage.\n",
      " Selected features are... LotArea.\n",
      " Selected features are... Alley.\n",
      " Selected features are... LotShape.\n",
      " Selected features are... LandContour.\n",
      " Selected features are... LotConfig.\n",
      " Selected features are... LandSlope.\n",
      " Selected features are... Neighborhood.\n",
      " Selected features are... Condition1.\n",
      " Selected features are... BldgType.\n",
      " Selected features are... HouseStyle.\n",
      " Selected features are... OverallQual.\n",
      " Selected features are... OverallCond.\n",
      " Selected features are... YearBuilt.\n",
      " Selected features are... YearRemodAdd.\n",
      " Selected features are... RoofStyle.\n",
      " Selected features are... RoofMatl.\n",
      " Selected features are... Exterior1st.\n",
      " Selected features are... MasVnrType.\n",
      " Selected features are... MasVnrArea.\n",
      " Selected features are... ExterQual.\n",
      " Selected features are... ExterCond.\n",
      " Selected features are... Foundation.\n",
      " Selected features are... BsmtQual.\n",
      " Selected features are... BsmtCond.\n",
      " Selected features are... BsmtExposure.\n",
      " Selected features are... BsmtFinType1.\n",
      " Selected features are... BsmtFinSF1.\n",
      " Selected features are... BsmtFinType2.\n",
      " Selected features are... BsmtFinSF2.\n",
      " Selected features are... BsmtUnfSF.\n",
      " Selected features are... TotalBsmtSF.\n",
      " Selected features are... HeatingQC.\n",
      " Selected features are... CentralAir.\n",
      " Selected features are... Electrical.\n",
      " Selected features are... 2ndFlrSF.\n",
      " Selected features are... LowQualFinSF.\n",
      " Selected features are... GrLivArea.\n",
      " Selected features are... BsmtFullBath.\n",
      " Selected features are... BsmtHalfBath.\n",
      " Selected features are... FullBath.\n",
      " Selected features are... HalfBath.\n",
      " Selected features are... BedroomAbvGr.\n",
      " Selected features are... KitchenQual.\n",
      " Selected features are... Functional.\n",
      " Selected features are... Fireplaces.\n",
      " Selected features are... FireplaceQu.\n",
      " Selected features are... GarageType.\n",
      " Selected features are... GarageYrBlt.\n",
      " Selected features are... GarageFinish.\n",
      " Selected features are... GarageCars.\n",
      " Selected features are... PavedDrive.\n",
      " Selected features are... WoodDeckSF.\n",
      " Selected features are... OpenPorchSF.\n",
      " Selected features are... EnclosedPorch.\n",
      " Selected features are... 3SsnPorch.\n",
      " Selected features are... ScreenPorch.\n",
      " Selected features are... Fence.\n",
      " Selected features are... MoSold.\n",
      " Selected features are... YrSold.\n",
      " Selected features are... SaleType.\n",
      " Selected features are... PC-1_pca.\n",
      " Selected features are... PC-2_pca.\n",
      " Selected features are... isolation_probs.\n",
      " Selected features are... kmeans_clusters2.\n",
      " Selected features are... kmeans_clusters3.\n",
      " Selected features are... kmeans_clusters4.\n",
      " Selected features are... kmeans_clusters5.\n",
      " Selected features are... kmeans_clusters6.\n",
      " Selected features are... kmeans_clusters7.\n",
      " Selected features are... kmeans_clusters8.\n",
      " Selected features are... kmeans_clusters9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:27:45,768]\u001B[0m A new study created in memory with name: no-name-e12e1d7f-5b44-461f-868e-d205c305c562\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Sort columns alphabetically at 15:27:45.\n",
      "Started Train Ngboost at 15:27:45.\n",
      "[iter 0] loss=12.5781 val_loss=12.5657 scale=1.0000 norm=0.6577\n",
      "[iter 100] loss=12.4590 val_loss=12.5243 scale=1.0000 norm=0.5762\n",
      "[iter 200] loss=12.3328 val_loss=12.4830 scale=1.0000 norm=0.5261\n",
      "[iter 300] loss=12.2669 val_loss=12.4390 scale=1.0000 norm=0.5054\n",
      "[iter 400] loss=12.2170 val_loss=12.3974 scale=1.0000 norm=0.5009\n",
      "[iter 500] loss=12.1786 val_loss=12.3501 scale=1.0000 norm=0.4739\n",
      "[iter 600] loss=12.0775 val_loss=12.3031 scale=1.0000 norm=0.4649\n",
      "[iter 700] loss=12.0168 val_loss=12.2626 scale=1.0000 norm=0.4733\n",
      "[iter 800] loss=11.9868 val_loss=12.2181 scale=2.0000 norm=0.9267\n",
      "[iter 900] loss=11.8840 val_loss=12.1739 scale=2.0000 norm=0.8954\n",
      "[iter 1000] loss=11.8512 val_loss=12.1272 scale=1.0000 norm=0.4475\n",
      "[iter 1100] loss=11.8295 val_loss=12.0824 scale=1.0000 norm=0.4490\n",
      "[iter 1200] loss=11.7621 val_loss=12.0377 scale=1.0000 norm=0.4405\n",
      "[iter 1300] loss=11.6926 val_loss=11.9964 scale=1.0000 norm=0.4305\n",
      "[iter 1400] loss=11.6195 val_loss=11.9588 scale=2.0000 norm=0.8473\n",
      "[iter 1500] loss=11.5874 val_loss=11.9271 scale=2.0000 norm=0.8525\n",
      "[iter 1600] loss=11.5762 val_loss=11.8983 scale=1.0000 norm=0.4128\n",
      "[iter 1700] loss=11.4960 val_loss=11.8753 scale=1.0000 norm=0.4231\n",
      "[iter 1800] loss=11.4108 val_loss=11.8599 scale=2.0000 norm=0.8432\n",
      "[iter 1900] loss=11.3843 val_loss=11.8484 scale=1.0000 norm=0.4168\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1940 (val_loss=11.8454)\n",
      "[iter 0] loss=12.5617 val_loss=12.5657 scale=1.0000 norm=0.6416\n",
      "[iter 100] loss=12.4325 val_loss=12.5184 scale=1.0000 norm=0.5566\n",
      "[iter 200] loss=12.3022 val_loss=12.4771 scale=1.0000 norm=0.5234\n",
      "[iter 300] loss=12.2298 val_loss=12.4309 scale=1.0000 norm=0.4960\n",
      "[iter 400] loss=12.1751 val_loss=12.3899 scale=1.0000 norm=0.4846\n",
      "[iter 500] loss=12.1628 val_loss=12.3484 scale=1.0000 norm=0.4679\n",
      "[iter 600] loss=12.0556 val_loss=12.3076 scale=1.0000 norm=0.4585\n",
      "[iter 700] loss=12.0109 val_loss=12.2613 scale=1.0000 norm=0.4601\n",
      "[iter 800] loss=11.9448 val_loss=12.2161 scale=1.0000 norm=0.4592\n",
      "[iter 900] loss=11.8496 val_loss=12.1699 scale=2.0000 norm=0.8820\n",
      "[iter 1000] loss=11.8351 val_loss=12.1237 scale=1.0000 norm=0.4456\n",
      "[iter 1100] loss=11.7671 val_loss=12.0743 scale=1.0000 norm=0.4426\n",
      "[iter 1200] loss=11.6960 val_loss=12.0319 scale=1.0000 norm=0.4376\n",
      "[iter 1300] loss=11.6568 val_loss=11.9908 scale=1.0000 norm=0.4337\n",
      "[iter 1400] loss=11.5770 val_loss=11.9538 scale=2.0000 norm=0.8570\n",
      "[iter 1500] loss=11.5451 val_loss=11.9233 scale=1.0000 norm=0.4293\n",
      "[iter 1600] loss=11.5281 val_loss=11.9014 scale=1.0000 norm=0.4209\n",
      "[iter 1700] loss=11.4282 val_loss=11.8852 scale=1.0000 norm=0.4288\n",
      "[iter 1800] loss=11.3490 val_loss=11.8734 scale=1.0000 norm=0.4233\n",
      "[iter 1900] loss=11.3383 val_loss=11.8670 scale=2.0000 norm=0.8367\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1945 (val_loss=11.8652)\n",
      "[iter 0] loss=12.5688 val_loss=12.5694 scale=1.0000 norm=0.6605\n",
      "[iter 100] loss=12.4381 val_loss=12.5469 scale=1.0000 norm=0.5805\n",
      "[iter 200] loss=12.2945 val_loss=12.5157 scale=1.0000 norm=0.5324\n",
      "[iter 300] loss=12.2717 val_loss=12.4683 scale=1.0000 norm=0.5037\n",
      "[iter 400] loss=12.1974 val_loss=12.4198 scale=1.0000 norm=0.4941\n",
      "[iter 500] loss=12.1399 val_loss=12.3757 scale=1.0000 norm=0.4743\n",
      "[iter 600] loss=12.0656 val_loss=12.3342 scale=1.0000 norm=0.4590\n",
      "[iter 700] loss=11.9959 val_loss=12.2870 scale=1.0000 norm=0.4662\n",
      "[iter 800] loss=11.9669 val_loss=12.2427 scale=1.0000 norm=0.4607\n",
      "[iter 900] loss=11.8596 val_loss=12.1920 scale=2.0000 norm=0.8916\n",
      "[iter 1000] loss=11.8533 val_loss=12.1427 scale=1.0000 norm=0.4468\n",
      "[iter 1100] loss=11.7615 val_loss=12.0991 scale=2.0000 norm=0.8823\n",
      "[iter 1200] loss=11.6984 val_loss=12.0545 scale=1.0000 norm=0.4500\n",
      "[iter 1300] loss=11.6501 val_loss=12.0130 scale=2.0000 norm=0.8719\n",
      "[iter 1400] loss=11.6097 val_loss=11.9779 scale=1.0000 norm=0.4387\n",
      "[iter 1500] loss=11.5666 val_loss=11.9479 scale=1.0000 norm=0.4377\n",
      "[iter 1600] loss=11.5259 val_loss=11.9241 scale=2.0000 norm=0.8428\n",
      "[iter 1700] loss=11.4376 val_loss=11.9060 scale=2.0000 norm=0.8446\n",
      "[iter 1800] loss=11.3787 val_loss=11.8938 scale=1.0000 norm=0.4188\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1806 (val_loss=11.8935)\n",
      "[iter 0] loss=12.5878 val_loss=12.5674 scale=1.0000 norm=0.6487\n",
      "[iter 100] loss=12.4737 val_loss=12.5350 scale=1.0000 norm=0.5805\n",
      "[iter 200] loss=12.3391 val_loss=12.5037 scale=1.0000 norm=0.5300\n",
      "[iter 300] loss=12.2951 val_loss=12.4752 scale=1.0000 norm=0.5022\n",
      "[iter 400] loss=12.2190 val_loss=12.4317 scale=1.0000 norm=0.4865\n",
      "[iter 500] loss=12.1604 val_loss=12.3954 scale=1.0000 norm=0.4716\n",
      "[iter 600] loss=12.0862 val_loss=12.3560 scale=2.0000 norm=0.9166\n",
      "[iter 700] loss=12.0432 val_loss=12.3154 scale=1.0000 norm=0.4607\n",
      "[iter 800] loss=12.0159 val_loss=12.2692 scale=1.0000 norm=0.4544\n",
      "[iter 900] loss=11.9092 val_loss=12.2239 scale=1.0000 norm=0.4474\n",
      "[iter 1000] loss=11.8702 val_loss=12.1764 scale=1.0000 norm=0.4427\n",
      "[iter 1100] loss=11.8010 val_loss=12.1311 scale=2.0000 norm=0.8814\n",
      "[iter 1200] loss=11.7209 val_loss=12.0901 scale=2.0000 norm=0.8980\n",
      "[iter 1300] loss=11.6750 val_loss=12.0503 scale=2.0000 norm=0.8714\n",
      "[iter 1400] loss=11.6453 val_loss=12.0167 scale=2.0000 norm=0.8818\n",
      "[iter 1500] loss=11.5803 val_loss=11.9880 scale=1.0000 norm=0.4342\n",
      "[iter 1600] loss=11.5573 val_loss=11.9675 scale=1.0000 norm=0.4265\n",
      "[iter 1700] loss=11.4708 val_loss=11.9523 scale=2.0000 norm=0.8365\n",
      "[iter 1800] loss=11.4103 val_loss=11.9437 scale=2.0000 norm=0.8319\n",
      "[iter 1900] loss=11.3686 val_loss=11.9388 scale=2.0000 norm=0.8465\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1898 (val_loss=11.9385)\n",
      "[iter 0] loss=12.5284 val_loss=12.5664 scale=1.0000 norm=0.6281\n",
      "[iter 100] loss=12.4245 val_loss=12.5186 scale=1.0000 norm=0.5623\n",
      "[iter 200] loss=12.3086 val_loss=12.4831 scale=1.0000 norm=0.5162\n",
      "[iter 300] loss=12.3015 val_loss=12.4481 scale=1.0000 norm=0.4990\n",
      "[iter 400] loss=12.2477 val_loss=12.4003 scale=1.0000 norm=0.4834\n",
      "[iter 500] loss=12.1287 val_loss=12.3612 scale=1.0000 norm=0.4693\n",
      "[iter 600] loss=12.0825 val_loss=12.3138 scale=1.0000 norm=0.4536\n",
      "[iter 700] loss=12.0268 val_loss=12.2668 scale=2.0000 norm=0.9057\n",
      "[iter 800] loss=12.0270 val_loss=12.2171 scale=1.0000 norm=0.4478\n",
      "[iter 900] loss=11.9165 val_loss=12.1692 scale=1.0000 norm=0.4447\n",
      "[iter 1000] loss=11.8529 val_loss=12.1225 scale=1.0000 norm=0.4395\n",
      "[iter 1100] loss=11.7872 val_loss=12.0761 scale=2.0000 norm=0.8555\n",
      "[iter 1200] loss=11.7283 val_loss=12.0325 scale=2.0000 norm=0.8784\n",
      "[iter 1300] loss=11.6678 val_loss=11.9903 scale=2.0000 norm=0.8660\n",
      "[iter 1400] loss=11.6262 val_loss=11.9541 scale=1.0000 norm=0.4330\n",
      "[iter 1500] loss=11.5707 val_loss=11.9216 scale=2.0000 norm=0.8449\n",
      "[iter 1600] loss=11.5376 val_loss=11.8966 scale=1.0000 norm=0.4164\n",
      "[iter 1700] loss=11.4473 val_loss=11.8778 scale=1.0000 norm=0.4030\n",
      "[iter 1800] loss=11.4254 val_loss=11.8641 scale=2.0000 norm=0.8207\n",
      "[iter 1900] loss=11.3411 val_loss=11.8540 scale=2.0000 norm=0.8227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:28:45,715]\u001B[0m Trial 0 finished with value: -1019096471.3456799 and parameters: {'base_learner': 'DecTree_depth2', 'Dist': 'LogNormal', 'n_estimators': 4404, 'minibatch_frac': 0.49536208443784413, 'learning_rate': 0.001243217289603259}. Best is trial 0 with value: -1019096471.3456799.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1934 (val_loss=11.8521)\n",
      "[iter 0] loss=12.7294 val_loss=12.6339 scale=2.0000 norm=118399.6778\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL44 (val_loss=11.6119)\n",
      "[iter 0] loss=12.7011 val_loss=12.6284 scale=2.0000 norm=114683.9170\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL44 (val_loss=11.6194)\n",
      "[iter 0] loss=12.6908 val_loss=12.6372 scale=2.0000 norm=114442.7898\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL43 (val_loss=11.6215)\n",
      "[iter 0] loss=12.7151 val_loss=12.6663 scale=2.0000 norm=120330.4293\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL43 (val_loss=11.6629)\n",
      "[iter 0] loss=12.6949 val_loss=12.6130 scale=2.0000 norm=116834.8951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:29:45,050]\u001B[0m Trial 1 finished with value: -867447890.998807 and parameters: {'base_learner': 'GradientBoost_depth5', 'Dist': 'Normal', 'n_estimators': 28127, 'minibatch_frac': 0.9989427742472475, 'learning_rate': 0.032408633065690313}. Best is trial 1 with value: -867447890.998807.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL43 (val_loss=11.6405)\n",
      "[iter 0] loss=12.5804 val_loss=12.5523 scale=2.0000 norm=1.3147\n",
      "[iter 100] loss=11.8305 val_loss=11.9853 scale=2.0000 norm=0.8820\n",
      "[iter 200] loss=11.3470 val_loss=11.6640 scale=2.0000 norm=0.8600\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL265 (val_loss=11.5968)\n",
      "[iter 0] loss=12.5643 val_loss=12.5493 scale=2.0000 norm=1.2937\n",
      "[iter 100] loss=11.8190 val_loss=11.9821 scale=2.0000 norm=0.8783\n",
      "[iter 200] loss=11.3153 val_loss=11.6698 scale=2.0000 norm=0.8688\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL256 (val_loss=11.6094)\n",
      "[iter 0] loss=12.5709 val_loss=12.5559 scale=2.0000 norm=1.3300\n",
      "[iter 100] loss=11.8110 val_loss=11.9842 scale=2.0000 norm=0.8822\n",
      "[iter 200] loss=11.2975 val_loss=11.6682 scale=2.0000 norm=0.8626\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL258 (val_loss=11.6159)\n",
      "[iter 0] loss=12.5894 val_loss=12.5549 scale=2.0000 norm=1.3065\n",
      "[iter 100] loss=11.8415 val_loss=12.0084 scale=2.0000 norm=0.8865\n",
      "[iter 200] loss=11.3362 val_loss=11.7006 scale=2.0000 norm=0.8650\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL257 (val_loss=11.6538)\n",
      "[iter 0] loss=12.5314 val_loss=12.5537 scale=2.0000 norm=1.2674\n",
      "[iter 100] loss=11.8096 val_loss=11.9805 scale=2.0000 norm=0.8763\n",
      "[iter 200] loss=11.3246 val_loss=11.6705 scale=2.0000 norm=0.8453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:30:59,331]\u001B[0m Trial 2 finished with value: -794654355.9055008 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 7576, 'minibatch_frac': 0.5025601990624651, 'learning_rate': 0.006024282780836509}. Best is trial 2 with value: -794654355.9055008.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL257 (val_loss=11.6140)\n",
      "[iter 0] loss=13.1280 val_loss=13.1314 scale=1.0000 norm=0.3292\n",
      "[iter 100] loss=13.0432 val_loss=13.0648 scale=2.0000 norm=0.1779\n",
      "[iter 200] loss=13.0443 val_loss=13.0598 scale=1.0000 norm=0.0717\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL205 (val_loss=13.0596)\n",
      "[iter 0] loss=13.1372 val_loss=13.1273 scale=1.0000 norm=0.3301\n",
      "[iter 100] loss=13.0478 val_loss=13.0636 scale=2.0000 norm=0.1677\n",
      "[iter 200] loss=13.0247 val_loss=13.0587 scale=2.0000 norm=0.1407\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL247 (val_loss=13.0578)\n",
      "[iter 0] loss=13.1100 val_loss=13.1277 scale=1.0000 norm=0.3419\n",
      "[iter 100] loss=13.0283 val_loss=13.0652 scale=2.0000 norm=0.1842\n",
      "[iter 200] loss=12.9958 val_loss=13.0598 scale=2.0000 norm=0.1479\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL279 (val_loss=13.0581)\n",
      "[iter 0] loss=13.1292 val_loss=13.1324 scale=1.0000 norm=0.3403\n",
      "[iter 100] loss=13.0443 val_loss=13.0670 scale=2.0000 norm=0.1743\n",
      "[iter 200] loss=13.0183 val_loss=13.0614 scale=2.0000 norm=0.1459\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL253 (val_loss=13.0606)\n",
      "[iter 0] loss=13.1010 val_loss=13.1285 scale=1.0000 norm=0.3191\n",
      "[iter 100] loss=13.0465 val_loss=13.0626 scale=1.0000 norm=0.0874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:31:05,316]\u001B[0m Trial 3 finished with value: -781252470.1794515 and parameters: {'base_learner': 'DecTree_depth2', 'Dist': 'Exponential', 'n_estimators': 11327, 'minibatch_frac': 0.4326644867915231, 'learning_rate': 0.018531207881149824}. Best is trial 3 with value: -781252470.1794515.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 200] loss=13.0188 val_loss=13.0579 scale=2.0000 norm=0.1502\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL213 (val_loss=13.0577)\n",
      "[iter 0] loss=12.7476 val_loss=12.5833 scale=2.0000 norm=119389.7737\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL30 (val_loss=11.7553)\n",
      "[iter 0] loss=12.7037 val_loss=12.5650 scale=2.0000 norm=114240.8691\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL30 (val_loss=11.7264)\n",
      "[iter 0] loss=12.6862 val_loss=12.5851 scale=2.0000 norm=113130.3872\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL29 (val_loss=11.7567)\n",
      "[iter 0] loss=12.7038 val_loss=12.5954 scale=2.0000 norm=117867.9878\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL34 (val_loss=11.7274)\n",
      "[iter 0] loss=12.6870 val_loss=12.5689 scale=2.0000 norm=114834.7264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:31:24,226]\u001B[0m Trial 4 finished with value: -845235030.6029098 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'Normal', 'n_estimators': 14070, 'minibatch_frac': 0.8868924597597899, 'learning_rate': 0.046301840048130816}. Best is trial 3 with value: -781252470.1794515.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL29 (val_loss=11.8119)\n",
      "[iter 0] loss=13.1292 val_loss=13.1292 scale=2.0000 norm=0.6613\n",
      "[iter 100] loss=13.0747 val_loss=13.0994 scale=2.0000 norm=0.4624\n",
      "[iter 200] loss=13.0603 val_loss=13.0835 scale=2.0000 norm=0.3519\n",
      "[iter 300] loss=13.0485 val_loss=13.0740 scale=2.0000 norm=0.2715\n",
      "[iter 400] loss=13.0384 val_loss=13.0677 scale=2.0000 norm=0.2158\n",
      "[iter 500] loss=13.0384 val_loss=13.0635 scale=2.0000 norm=0.1789\n",
      "[iter 600] loss=13.0307 val_loss=13.0609 scale=2.0000 norm=0.1570\n",
      "[iter 700] loss=13.0244 val_loss=13.0592 scale=2.0000 norm=0.1388\n",
      "[iter 800] loss=13.0413 val_loss=13.0580 scale=4.0000 norm=0.2580\n",
      "[iter 900] loss=13.0400 val_loss=13.0570 scale=4.0000 norm=0.2389\n",
      "[iter 1000] loss=13.0384 val_loss=13.0563 scale=4.0000 norm=0.2316\n",
      "[iter 1100] loss=13.0300 val_loss=13.0557 scale=4.0000 norm=0.2257\n",
      "[iter 1200] loss=13.0270 val_loss=13.0554 scale=4.0000 norm=0.2134\n",
      "[iter 1300] loss=13.0373 val_loss=13.0552 scale=4.0000 norm=0.2187\n",
      "[iter 1400] loss=13.0252 val_loss=13.0550 scale=4.0000 norm=0.2022\n",
      "[iter 1500] loss=13.0433 val_loss=13.0548 scale=4.0000 norm=0.1996\n",
      "[iter 1600] loss=13.0436 val_loss=13.0548 scale=8.0000 norm=0.3846\n",
      "[iter 1700] loss=13.0239 val_loss=13.0547 scale=8.0000 norm=0.3822\n",
      "[iter 1800] loss=13.0351 val_loss=13.0546 scale=8.0000 norm=0.3691\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1866 (val_loss=13.0545)\n",
      "[iter 0] loss=13.1183 val_loss=13.1293 scale=2.0000 norm=0.6446\n",
      "[iter 100] loss=13.0728 val_loss=13.0988 scale=2.0000 norm=0.4495\n",
      "[iter 200] loss=13.0521 val_loss=13.0832 scale=2.0000 norm=0.3410\n",
      "[iter 300] loss=13.0427 val_loss=13.0739 scale=2.0000 norm=0.2638\n",
      "[iter 400] loss=13.0344 val_loss=13.0679 scale=2.0000 norm=0.2087\n",
      "[iter 500] loss=13.0323 val_loss=13.0640 scale=2.0000 norm=0.1792\n",
      "[iter 600] loss=13.0257 val_loss=13.0615 scale=2.0000 norm=0.1592\n",
      "[iter 700] loss=13.0232 val_loss=13.0599 scale=2.0000 norm=0.1388\n",
      "[iter 800] loss=13.0362 val_loss=13.0587 scale=4.0000 norm=0.2589\n",
      "[iter 900] loss=13.0438 val_loss=13.0578 scale=4.0000 norm=0.2397\n",
      "[iter 1000] loss=13.0400 val_loss=13.0570 scale=4.0000 norm=0.2294\n",
      "[iter 1100] loss=13.0193 val_loss=13.0565 scale=4.0000 norm=0.2185\n",
      "[iter 1200] loss=13.0173 val_loss=13.0561 scale=4.0000 norm=0.2061\n",
      "[iter 1300] loss=13.0312 val_loss=13.0559 scale=8.0000 norm=0.4293\n",
      "[iter 1400] loss=13.0289 val_loss=13.0557 scale=8.0000 norm=0.4038\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1422 (val_loss=13.0557)\n",
      "[iter 0] loss=13.0972 val_loss=13.1298 scale=2.0000 norm=0.6484\n",
      "[iter 100] loss=13.0508 val_loss=13.0993 scale=2.0000 norm=0.4574\n",
      "[iter 200] loss=13.0354 val_loss=13.0834 scale=2.0000 norm=0.3497\n",
      "[iter 300] loss=13.0305 val_loss=13.0739 scale=2.0000 norm=0.2611\n",
      "[iter 400] loss=13.0160 val_loss=13.0677 scale=2.0000 norm=0.2102\n",
      "[iter 500] loss=13.0158 val_loss=13.0637 scale=2.0000 norm=0.1776\n",
      "[iter 600] loss=13.0172 val_loss=13.0611 scale=2.0000 norm=0.1582\n",
      "[iter 700] loss=13.0033 val_loss=13.0595 scale=2.0000 norm=0.1387\n",
      "[iter 800] loss=13.0166 val_loss=13.0583 scale=2.0000 norm=0.1277\n",
      "[iter 900] loss=13.0202 val_loss=13.0574 scale=4.0000 norm=0.2346\n",
      "[iter 1000] loss=13.0141 val_loss=13.0566 scale=4.0000 norm=0.2306\n",
      "[iter 1100] loss=12.9931 val_loss=13.0561 scale=4.0000 norm=0.2192\n",
      "[iter 1200] loss=13.0057 val_loss=13.0558 scale=4.0000 norm=0.2089\n",
      "[iter 1300] loss=13.0082 val_loss=13.0556 scale=4.0000 norm=0.2211\n",
      "[iter 1400] loss=13.0127 val_loss=13.0554 scale=8.0000 norm=0.4108\n",
      "[iter 1500] loss=13.0203 val_loss=13.0553 scale=4.0000 norm=0.1963\n",
      "[iter 1600] loss=13.0152 val_loss=13.0552 scale=8.0000 norm=0.3747\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1676 (val_loss=13.0551)\n",
      "[iter 0] loss=13.1149 val_loss=13.1293 scale=1.0000 norm=0.3296\n",
      "[iter 100] loss=13.0688 val_loss=13.0999 scale=2.0000 norm=0.4758\n",
      "[iter 200] loss=13.0511 val_loss=13.0854 scale=2.0000 norm=0.3511\n",
      "[iter 300] loss=13.0509 val_loss=13.0766 scale=2.0000 norm=0.2649\n",
      "[iter 400] loss=13.0319 val_loss=13.0704 scale=2.0000 norm=0.2174\n",
      "[iter 500] loss=13.0428 val_loss=13.0663 scale=2.0000 norm=0.1803\n",
      "[iter 600] loss=13.0271 val_loss=13.0635 scale=2.0000 norm=0.1604\n",
      "[iter 700] loss=13.0232 val_loss=13.0616 scale=2.0000 norm=0.1430\n",
      "[iter 800] loss=13.0290 val_loss=13.0604 scale=2.0000 norm=0.1287\n",
      "[iter 900] loss=13.0302 val_loss=13.0594 scale=4.0000 norm=0.2421\n",
      "[iter 1000] loss=13.0376 val_loss=13.0586 scale=4.0000 norm=0.2309\n",
      "[iter 1100] loss=13.0174 val_loss=13.0581 scale=4.0000 norm=0.2243\n",
      "[iter 1200] loss=13.0233 val_loss=13.0577 scale=4.0000 norm=0.2145\n",
      "[iter 1300] loss=13.0193 val_loss=13.0575 scale=8.0000 norm=0.4393\n",
      "[iter 1400] loss=13.0280 val_loss=13.0574 scale=4.0000 norm=0.2078\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1436 (val_loss=13.0573)\n",
      "[iter 0] loss=13.1154 val_loss=13.1290 scale=2.0000 norm=0.6376\n",
      "[iter 100] loss=13.0698 val_loss=13.0984 scale=2.0000 norm=0.4563\n",
      "[iter 200] loss=13.0595 val_loss=13.0831 scale=2.0000 norm=0.3431\n",
      "[iter 300] loss=13.0541 val_loss=13.0738 scale=2.0000 norm=0.2629\n",
      "[iter 400] loss=13.0497 val_loss=13.0678 scale=2.0000 norm=0.2141\n",
      "[iter 500] loss=13.0477 val_loss=13.0638 scale=2.0000 norm=0.1746\n",
      "[iter 600] loss=13.0350 val_loss=13.0613 scale=2.0000 norm=0.1590\n",
      "[iter 700] loss=13.0321 val_loss=13.0597 scale=2.0000 norm=0.1422\n",
      "[iter 800] loss=13.0327 val_loss=13.0587 scale=2.0000 norm=0.1301\n",
      "[iter 900] loss=13.0362 val_loss=13.0577 scale=4.0000 norm=0.2406\n",
      "[iter 1000] loss=13.0385 val_loss=13.0571 scale=4.0000 norm=0.2350\n",
      "[iter 1100] loss=13.0269 val_loss=13.0567 scale=4.0000 norm=0.2240\n",
      "[iter 1200] loss=13.0349 val_loss=13.0564 scale=4.0000 norm=0.2209\n",
      "[iter 1300] loss=13.0312 val_loss=13.0562 scale=8.0000 norm=0.4444\n",
      "[iter 1400] loss=13.0269 val_loss=13.0561 scale=4.0000 norm=0.2110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:36:44,947]\u001B[0m Trial 5 finished with value: -773888593.8144524 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'Exponential', 'n_estimators': 33362, 'minibatch_frac': 0.8203362758286394, 'learning_rate': 0.0017523568619570945}. Best is trial 5 with value: -773888593.8144524.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1405 (val_loss=13.0561)\n",
      "[iter 0] loss=12.7814 val_loss=12.7079 scale=2.0000 norm=121198.9051\n",
      "[iter 100] loss=12.0637 val_loss=12.2108 scale=2.0000 norm=55169.1470\n",
      "[iter 200] loss=11.6291 val_loss=11.9076 scale=2.0000 norm=30364.8344\n",
      "[iter 300] loss=11.2846 val_loss=11.7623 scale=2.0000 norm=24542.7224\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL320 (val_loss=11.7596)\n",
      "[iter 0] loss=12.7760 val_loss=12.7079 scale=2.0000 norm=119924.3276\n",
      "[iter 100] loss=12.0311 val_loss=12.1937 scale=2.0000 norm=52592.4209\n",
      "[iter 200] loss=11.5992 val_loss=11.9012 scale=2.0000 norm=28641.2871\n",
      "[iter 300] loss=11.2523 val_loss=11.7757 scale=2.0000 norm=22949.7343\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL302 (val_loss=11.7756)\n",
      "[iter 0] loss=12.7554 val_loss=12.7287 scale=1.0000 norm=59606.5206\n",
      "[iter 100] loss=12.0224 val_loss=12.1569 scale=2.0000 norm=52020.0831\n",
      "[iter 200] loss=11.5856 val_loss=11.8291 scale=2.0000 norm=27887.4251\n",
      "[iter 300] loss=11.2300 val_loss=11.6628 scale=2.0000 norm=21649.6192\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL321 (val_loss=11.6555)\n",
      "[iter 0] loss=12.7560 val_loss=12.7179 scale=2.0000 norm=123262.6578\n",
      "[iter 100] loss=12.0501 val_loss=12.2021 scale=2.0000 norm=53231.8233\n",
      "[iter 200] loss=11.6041 val_loss=11.8928 scale=2.0000 norm=26958.4435\n",
      "[iter 300] loss=11.2650 val_loss=11.7461 scale=2.0000 norm=21935.6580\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL314 (val_loss=11.7405)\n",
      "[iter 0] loss=12.6654 val_loss=12.7129 scale=2.0000 norm=115573.8836\n",
      "[iter 100] loss=12.0265 val_loss=12.1889 scale=2.0000 norm=52291.4526\n",
      "[iter 200] loss=11.6015 val_loss=11.8887 scale=2.0000 norm=28439.9503\n",
      "[iter 300] loss=11.2760 val_loss=11.7478 scale=2.0000 norm=23776.8214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:38:57,563]\u001B[0m Trial 6 finished with value: -838033197.2358072 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'Normal', 'n_estimators': 18307, 'minibatch_frac': 0.6622771296096203, 'learning_rate': 0.004857568069423301}. Best is trial 5 with value: -773888593.8144524.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL318 (val_loss=11.7427)\n",
      "[iter 0] loss=12.5537 val_loss=12.5652 scale=1.0000 norm=0.6537\n",
      "[iter 100] loss=12.2255 val_loss=12.3999 scale=2.0000 norm=0.9425\n",
      "[iter 200] loss=11.9696 val_loss=12.2409 scale=2.0000 norm=0.8839\n",
      "[iter 300] loss=11.7346 val_loss=12.0928 scale=2.0000 norm=0.8762\n",
      "[iter 400] loss=11.5195 val_loss=11.9714 scale=2.0000 norm=0.8766\n",
      "[iter 500] loss=11.3189 val_loss=11.9056 scale=2.0000 norm=0.8741\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL542 (val_loss=11.8998)\n",
      "[iter 0] loss=12.5595 val_loss=12.5637 scale=1.0000 norm=0.6631\n",
      "[iter 100] loss=12.1973 val_loss=12.3705 scale=2.0000 norm=0.9303\n",
      "[iter 200] loss=11.9492 val_loss=12.2016 scale=2.0000 norm=0.8809\n",
      "[iter 300] loss=11.7221 val_loss=12.0482 scale=2.0000 norm=0.8738\n",
      "[iter 400] loss=11.5054 val_loss=11.9143 scale=2.0000 norm=0.8771\n",
      "[iter 500] loss=11.3142 val_loss=11.8311 scale=2.0000 norm=0.8714\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL563 (val_loss=11.8134)\n",
      "[iter 0] loss=12.5506 val_loss=12.5696 scale=1.0000 norm=0.6682\n",
      "[iter 100] loss=12.1941 val_loss=12.4165 scale=2.0000 norm=0.9410\n",
      "[iter 200] loss=11.9431 val_loss=12.2546 scale=2.0000 norm=0.8828\n",
      "[iter 300] loss=11.7229 val_loss=12.0900 scale=2.0000 norm=0.8760\n",
      "[iter 400] loss=11.5066 val_loss=11.9647 scale=2.0000 norm=0.8755\n",
      "[iter 500] loss=11.2983 val_loss=11.8938 scale=2.0000 norm=0.8733\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL542 (val_loss=11.8852)\n",
      "[iter 0] loss=12.5820 val_loss=12.5655 scale=1.0000 norm=0.6597\n",
      "[iter 100] loss=12.2372 val_loss=12.4052 scale=2.0000 norm=0.9395\n",
      "[iter 200] loss=11.9700 val_loss=12.2558 scale=2.0000 norm=0.8798\n",
      "[iter 300] loss=11.7547 val_loss=12.1131 scale=2.0000 norm=0.8768\n",
      "[iter 400] loss=11.5462 val_loss=11.9946 scale=2.0000 norm=0.8744\n",
      "[iter 500] loss=11.3527 val_loss=11.9279 scale=2.0000 norm=0.8692\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL534 (val_loss=11.9208)\n",
      "[iter 0] loss=12.5374 val_loss=12.5644 scale=1.0000 norm=0.6392\n",
      "[iter 100] loss=12.2092 val_loss=12.3704 scale=2.0000 norm=0.9228\n",
      "[iter 200] loss=11.9611 val_loss=12.2029 scale=2.0000 norm=0.8724\n",
      "[iter 300] loss=11.7461 val_loss=12.0491 scale=2.0000 norm=0.8715\n",
      "[iter 400] loss=11.5445 val_loss=11.9145 scale=2.0000 norm=0.8707\n",
      "[iter 500] loss=11.3257 val_loss=11.8336 scale=2.0000 norm=0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:39:26,800]\u001B[0m Trial 7 finished with value: -952557728.0646244 and parameters: {'base_learner': 'DecTree_depth5', 'Dist': 'LogNormal', 'n_estimators': 45658, 'minibatch_frac': 0.7312127139074223, 'learning_rate': 0.0023795839977098884}. Best is trial 5 with value: -773888593.8144524.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL569 (val_loss=11.8163)\n",
      "[iter 0] loss=13.1292 val_loss=13.1258 scale=1.0000 norm=0.3293\n",
      "[iter 100] loss=13.0367 val_loss=13.0658 scale=2.0000 norm=0.0119\n",
      "[iter 200] loss=13.0341 val_loss=13.0653 scale=2.0000 norm=0.0007\n",
      "== Quitting at iteration / GRAD 248\n",
      "[iter 0] loss=13.1210 val_loss=13.1262 scale=1.0000 norm=0.3297\n",
      "[iter 100] loss=13.0432 val_loss=13.0645 scale=2.0000 norm=0.0110\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL169 (val_loss=13.0641)\n",
      "[iter 0] loss=13.1026 val_loss=13.1266 scale=1.0000 norm=0.3368\n",
      "[iter 100] loss=13.0148 val_loss=13.0660 scale=2.0000 norm=0.0127\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL171 (val_loss=13.0656)\n",
      "[iter 0] loss=13.1181 val_loss=13.1265 scale=1.0000 norm=0.3403\n",
      "[iter 100] loss=13.0320 val_loss=13.0690 scale=2.0000 norm=0.0120\n",
      "[iter 200] loss=13.0004 val_loss=13.0685 scale=1.0000 norm=0.0004\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL193 (val_loss=13.0685)\n",
      "[iter 0] loss=13.1006 val_loss=13.1241 scale=2.0000 norm=0.6352\n",
      "[iter 100] loss=13.0268 val_loss=13.0622 scale=2.0000 norm=0.0118\n",
      "[iter 200] loss=13.0101 val_loss=13.0616 scale=2.0000 norm=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:39:39,425]\u001B[0m Trial 8 finished with value: -930022811.04256 and parameters: {'base_learner': 'DecTree_depthNone', 'Dist': 'Exponential', 'n_estimators': 19259, 'minibatch_frac': 0.6345984518250455, 'learning_rate': 0.02399528063447809}. Best is trial 5 with value: -773888593.8144524.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL215 (val_loss=13.0616)\n",
      "[iter 0] loss=12.5601 val_loss=12.5651 scale=1.0000 norm=0.6563\n",
      "[iter 100] loss=12.3282 val_loss=12.4804 scale=1.0000 norm=0.5222\n",
      "[iter 200] loss=12.1783 val_loss=12.3705 scale=1.0000 norm=0.4849\n",
      "[iter 300] loss=12.0325 val_loss=12.2674 scale=1.0000 norm=0.4603\n",
      "[iter 400] loss=11.8895 val_loss=12.1610 scale=1.0000 norm=0.4553\n",
      "[iter 500] loss=11.7485 val_loss=12.0536 scale=2.0000 norm=0.8811\n",
      "[iter 600] loss=11.6110 val_loss=11.9629 scale=2.0000 norm=0.8589\n",
      "[iter 700] loss=11.4650 val_loss=11.8982 scale=1.0000 norm=0.4220\n",
      "[iter 800] loss=11.3755 val_loss=11.8667 scale=1.0000 norm=0.4137\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL872 (val_loss=11.8598)\n",
      "[iter 0] loss=12.5578 val_loss=12.5663 scale=1.0000 norm=0.6612\n",
      "[iter 100] loss=12.2858 val_loss=12.4614 scale=1.0000 norm=0.5066\n",
      "[iter 200] loss=12.1433 val_loss=12.3663 scale=1.0000 norm=0.4757\n",
      "[iter 300] loss=12.0064 val_loss=12.2669 scale=1.0000 norm=0.4537\n",
      "[iter 400] loss=11.8640 val_loss=12.1670 scale=1.0000 norm=0.4494\n",
      "[iter 500] loss=11.7404 val_loss=12.0628 scale=1.0000 norm=0.4411\n",
      "[iter 600] loss=11.5827 val_loss=11.9722 scale=2.0000 norm=0.8631\n",
      "[iter 700] loss=11.4302 val_loss=11.9087 scale=1.0000 norm=0.4273\n",
      "[iter 800] loss=11.3461 val_loss=11.8816 scale=1.0000 norm=0.4227\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL814 (val_loss=11.8808)\n",
      "[iter 0] loss=12.5484 val_loss=12.5700 scale=1.0000 norm=0.6661\n",
      "[iter 100] loss=12.2916 val_loss=12.5185 scale=1.0000 norm=0.5189\n",
      "[iter 200] loss=12.1496 val_loss=12.4158 scale=1.0000 norm=0.4815\n",
      "[iter 300] loss=12.0137 val_loss=12.3121 scale=1.0000 norm=0.4567\n",
      "[iter 400] loss=11.8791 val_loss=12.2088 scale=2.0000 norm=0.8997\n",
      "[iter 500] loss=11.7409 val_loss=12.1079 scale=1.0000 norm=0.4472\n",
      "[iter 600] loss=11.6009 val_loss=12.0271 scale=1.0000 norm=0.4321\n",
      "[iter 700] loss=11.4354 val_loss=11.9785 scale=1.0000 norm=0.4262\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL789 (val_loss=11.9615)\n",
      "[iter 0] loss=12.5836 val_loss=12.5663 scale=1.0000 norm=0.6589\n",
      "[iter 100] loss=12.3398 val_loss=12.5029 scale=1.0000 norm=0.5217\n",
      "[iter 200] loss=12.1720 val_loss=12.4260 scale=1.0000 norm=0.4762\n",
      "[iter 300] loss=12.0417 val_loss=12.3381 scale=1.0000 norm=0.4583\n",
      "[iter 400] loss=11.9086 val_loss=12.2329 scale=2.0000 norm=0.8971\n",
      "[iter 500] loss=11.7824 val_loss=12.1347 scale=2.0000 norm=0.8942\n",
      "[iter 600] loss=11.6156 val_loss=12.0540 scale=2.0000 norm=0.8622\n",
      "[iter 700] loss=11.4596 val_loss=12.0058 scale=1.0000 norm=0.4221\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL765 (val_loss=11.9932)\n",
      "[iter 0] loss=12.5403 val_loss=12.5664 scale=1.0000 norm=0.6402\n",
      "[iter 100] loss=12.3015 val_loss=12.4689 scale=1.0000 norm=0.5079\n",
      "[iter 200] loss=12.1597 val_loss=12.3800 scale=1.0000 norm=0.4733\n",
      "[iter 300] loss=12.0405 val_loss=12.2766 scale=1.0000 norm=0.4566\n",
      "[iter 400] loss=11.9134 val_loss=12.1618 scale=2.0000 norm=0.8854\n",
      "[iter 500] loss=11.7659 val_loss=12.0592 scale=2.0000 norm=0.8833\n",
      "[iter 600] loss=11.6128 val_loss=11.9657 scale=1.0000 norm=0.4220\n",
      "[iter 700] loss=11.4560 val_loss=11.9008 scale=1.0000 norm=0.4179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:40:09,440]\u001B[0m Trial 9 finished with value: -1049561728.2178093 and parameters: {'base_learner': 'DecTree_depth2', 'Dist': 'LogNormal', 'n_estimators': 19619, 'minibatch_frac': 0.7374021355651805, 'learning_rate': 0.0030404504334331337}. Best is trial 5 with value: -773888593.8144524.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 800] loss=11.3857 val_loss=11.8675 scale=1.0000 norm=0.4136\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL800 (val_loss=11.8675)\n",
      "[iter 0] loss=13.1232 val_loss=13.1166 scale=1.0000 norm=0.3262\n",
      "[iter 100] loss=13.0318 val_loss=13.0608 scale=2.0000 norm=0.0172\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL94 (val_loss=13.0608)\n",
      "[iter 0] loss=13.1109 val_loss=13.1164 scale=1.0000 norm=0.3145\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL59 (val_loss=13.0619)\n",
      "[iter 0] loss=13.0887 val_loss=13.1204 scale=1.0000 norm=0.3170\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL64 (val_loss=13.0617)\n",
      "[iter 0] loss=13.1095 val_loss=13.1188 scale=1.0000 norm=0.3246\n",
      "[iter 100] loss=13.0226 val_loss=13.0634 scale=1.0000 norm=0.0084\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL99 (val_loss=13.0634)\n",
      "[iter 0] loss=13.1137 val_loss=13.1190 scale=1.0000 norm=0.3151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:40:12,550]\u001B[0m Trial 10 finished with value: -962342166.5626017 and parameters: {'base_learner': 'DecTree_depth5', 'Dist': 'Exponential', 'n_estimators': 36732, 'minibatch_frac': 0.897035533531652, 'learning_rate': 0.0959741951039767}. Best is trial 5 with value: -773888593.8144524.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL32 (val_loss=13.0602)\n",
      "[iter 0] loss=13.1359 val_loss=13.1310 scale=1.0000 norm=0.3314\n",
      "[iter 100] loss=13.0413 val_loss=13.0694 scale=2.0000 norm=0.2080\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL127 (val_loss=13.0650)\n",
      "[iter 0] loss=13.1424 val_loss=13.1285 scale=1.0000 norm=0.3300\n",
      "[iter 100] loss=13.0436 val_loss=13.0676 scale=2.0000 norm=0.1950\n",
      "[iter 200] loss=13.0174 val_loss=13.0598 scale=2.0000 norm=0.1509\n",
      "[iter 300] loss=13.0092 val_loss=13.0581 scale=2.0000 norm=0.1321\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL347 (val_loss=13.0578)\n",
      "[iter 0] loss=13.1157 val_loss=13.1282 scale=1.0000 norm=0.3432\n",
      "[iter 100] loss=13.0254 val_loss=13.0703 scale=2.0000 norm=0.2141\n",
      "[iter 200] loss=12.9885 val_loss=13.0616 scale=2.0000 norm=0.1554\n",
      "[iter 300] loss=13.0382 val_loss=13.0592 scale=1.0000 norm=0.0681\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL297 (val_loss=13.0592)\n",
      "[iter 0] loss=13.1366 val_loss=13.1317 scale=1.0000 norm=0.3433\n",
      "[iter 100] loss=13.0416 val_loss=13.0720 scale=2.0000 norm=0.1980\n",
      "[iter 200] loss=13.0149 val_loss=13.0631 scale=2.0000 norm=0.1538\n",
      "[iter 300] loss=13.0517 val_loss=13.0614 scale=2.0000 norm=0.1310\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL332 (val_loss=13.0611)\n",
      "[iter 0] loss=13.1040 val_loss=13.1287 scale=1.0000 norm=0.3207\n",
      "[iter 100] loss=13.0468 val_loss=13.0673 scale=1.0000 norm=0.1000\n",
      "[iter 200] loss=13.0153 val_loss=13.0594 scale=2.0000 norm=0.1594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:40:19,585]\u001B[0m Trial 11 finished with value: -847572919.9242351 and parameters: {'base_learner': 'DecTree_depth2', 'Dist': 'Exponential', 'n_estimators': 31241, 'minibatch_frac': 0.41247847734530385, 'learning_rate': 0.014268388670860749}. Best is trial 5 with value: -773888593.8144524.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL259 (val_loss=13.0582)\n",
      "[iter 0] loss=13.1282 val_loss=13.1269 scale=2.0000 norm=0.6580\n",
      "[iter 100] loss=13.0327 val_loss=13.0583 scale=2.0000 norm=0.1334\n",
      "[iter 200] loss=13.0323 val_loss=13.0548 scale=8.0000 norm=0.3965\n",
      "[iter 300] loss=13.0321 val_loss=13.0543 scale=8.0000 norm=0.3420\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL315 (val_loss=13.0543)\n",
      "[iter 0] loss=13.1174 val_loss=13.1278 scale=1.0000 norm=0.3207\n",
      "[iter 100] loss=13.0324 val_loss=13.0590 scale=2.0000 norm=0.1321\n",
      "[iter 200] loss=13.0254 val_loss=13.0556 scale=8.0000 norm=0.3855\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL214 (val_loss=13.0555)\n",
      "[iter 0] loss=13.0967 val_loss=13.1283 scale=1.0000 norm=0.3222\n",
      "[iter 100] loss=13.0112 val_loss=13.0592 scale=2.0000 norm=0.1349\n",
      "[iter 200] loss=13.0085 val_loss=13.0555 scale=4.0000 norm=0.2017\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL275 (val_loss=13.0551)\n",
      "[iter 0] loss=13.1140 val_loss=13.1279 scale=1.0000 norm=0.3280\n",
      "[iter 100] loss=13.0271 val_loss=13.0607 scale=2.0000 norm=0.1346\n",
      "[iter 200] loss=13.0260 val_loss=13.0573 scale=8.0000 norm=0.3987\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL193 (val_loss=13.0571)\n",
      "[iter 0] loss=13.1143 val_loss=13.1277 scale=1.0000 norm=0.3171\n",
      "[iter 100] loss=13.0326 val_loss=13.0589 scale=2.0000 norm=0.1333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:41:06,714]\u001B[0m Trial 12 finished with value: -773100957.8694904 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'Exponential', 'n_estimators': 36037, 'minibatch_frac': 0.8302938290038407, 'learning_rate': 0.01321489123948739}. Best is trial 12 with value: -773100957.8694904.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 200] loss=13.0366 val_loss=13.0560 scale=4.0000 norm=0.2055\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL193 (val_loss=13.0559)\n",
      "[iter 0] loss=13.1250 val_loss=13.1286 scale=1.0000 norm=0.3276\n",
      "[iter 100] loss=13.0371 val_loss=13.0643 scale=2.0000 norm=0.1820\n",
      "[iter 200] loss=13.0354 val_loss=13.0567 scale=4.0000 norm=0.2330\n",
      "[iter 300] loss=13.0340 val_loss=13.0551 scale=4.0000 norm=0.1989\n",
      "[iter 400] loss=13.0335 val_loss=13.0547 scale=4.0000 norm=0.1828\n",
      "[iter 500] loss=13.0332 val_loss=13.0545 scale=8.0000 norm=0.3271\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL531 (val_loss=13.0544)\n",
      "[iter 0] loss=13.1152 val_loss=13.1283 scale=1.0000 norm=0.3185\n",
      "[iter 100] loss=13.0372 val_loss=13.0641 scale=2.0000 norm=0.1785\n",
      "[iter 200] loss=13.0283 val_loss=13.0572 scale=4.0000 norm=0.2282\n",
      "[iter 300] loss=13.0298 val_loss=13.0555 scale=8.0000 norm=0.3954\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL305 (val_loss=13.0555)\n",
      "[iter 0] loss=13.0948 val_loss=13.1290 scale=1.0000 norm=0.3200\n",
      "[iter 100] loss=13.0159 val_loss=13.0647 scale=2.0000 norm=0.1787\n",
      "[iter 200] loss=13.0127 val_loss=13.0573 scale=4.0000 norm=0.2299\n",
      "[iter 300] loss=13.0189 val_loss=13.0557 scale=8.0000 norm=0.3940\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL376 (val_loss=13.0554)\n",
      "[iter 0] loss=13.1118 val_loss=13.1286 scale=1.0000 norm=0.3258\n",
      "[iter 100] loss=13.0316 val_loss=13.0669 scale=2.0000 norm=0.1854\n",
      "[iter 200] loss=13.0301 val_loss=13.0590 scale=4.0000 norm=0.2320\n",
      "[iter 300] loss=13.0400 val_loss=13.0574 scale=8.0000 norm=0.4115\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL324 (val_loss=13.0573)\n",
      "[iter 0] loss=13.1124 val_loss=13.1272 scale=2.0000 norm=0.6313\n",
      "[iter 100] loss=13.0367 val_loss=13.0642 scale=2.0000 norm=0.1796\n",
      "[iter 200] loss=13.0394 val_loss=13.0572 scale=4.0000 norm=0.2353\n",
      "[iter 300] loss=13.0438 val_loss=13.0559 scale=8.0000 norm=0.4208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:42:24,777]\u001B[0m Trial 13 finished with value: -759714966.183796 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'Exponential', 'n_estimators': 43282, 'minibatch_frac': 0.8429887853629455, 'learning_rate': 0.008382454160324106}. Best is trial 13 with value: -759714966.183796.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL378 (val_loss=13.0556)\n",
      "[iter 0] loss=13.1152 val_loss=13.1273 scale=2.0000 norm=0.6469\n",
      "[iter 100] loss=13.0416 val_loss=13.0638 scale=2.0000 norm=0.1783\n",
      "[iter 200] loss=13.0353 val_loss=13.0566 scale=4.0000 norm=0.2316\n",
      "[iter 300] loss=13.0331 val_loss=13.0550 scale=8.0000 norm=0.3937\n",
      "[iter 400] loss=13.0339 val_loss=13.0547 scale=8.0000 norm=0.3532\n",
      "[iter 500] loss=13.0309 val_loss=13.0544 scale=8.0000 norm=0.3190\n",
      "[iter 600] loss=13.0337 val_loss=13.0542 scale=4.0000 norm=0.1442\n",
      "[iter 700] loss=13.0335 val_loss=13.0541 scale=8.0000 norm=0.2638\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL764 (val_loss=13.0540)\n",
      "[iter 0] loss=13.1090 val_loss=13.1273 scale=2.0000 norm=0.6312\n",
      "[iter 100] loss=13.0373 val_loss=13.0645 scale=2.0000 norm=0.1780\n",
      "[iter 200] loss=13.0309 val_loss=13.0574 scale=4.0000 norm=0.2308\n",
      "[iter 300] loss=13.0298 val_loss=13.0558 scale=8.0000 norm=0.3946\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL311 (val_loss=13.0558)\n",
      "[iter 0] loss=13.0924 val_loss=13.1283 scale=2.0000 norm=0.6403\n",
      "[iter 100] loss=13.0171 val_loss=13.0643 scale=2.0000 norm=0.1772\n",
      "[iter 200] loss=13.0133 val_loss=13.0571 scale=4.0000 norm=0.2333\n",
      "[iter 300] loss=13.0116 val_loss=13.0555 scale=8.0000 norm=0.4008\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL377 (val_loss=13.0553)\n",
      "[iter 0] loss=13.1133 val_loss=13.1273 scale=2.0000 norm=0.6609\n",
      "[iter 100] loss=13.0338 val_loss=13.0675 scale=2.0000 norm=0.1812\n",
      "[iter 200] loss=13.0298 val_loss=13.0595 scale=4.0000 norm=0.2333\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL289 (val_loss=13.0580)\n",
      "[iter 0] loss=13.1154 val_loss=13.1271 scale=2.0000 norm=0.6404\n",
      "[iter 100] loss=13.0406 val_loss=13.0646 scale=2.0000 norm=0.1768\n",
      "[iter 200] loss=13.0360 val_loss=13.0577 scale=4.0000 norm=0.2380\n",
      "[iter 300] loss=13.0359 val_loss=13.0563 scale=8.0000 norm=0.4075\n",
      "[iter 400] loss=13.0362 val_loss=13.0561 scale=4.0000 norm=0.1794\n",
      "[iter 500] loss=13.0351 val_loss=13.0559 scale=4.0000 norm=0.1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:43:58,050]\u001B[0m Trial 14 finished with value: -765313680.8414676 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'Exponential', 'n_estimators': 49236, 'minibatch_frac': 0.9978818834328608, 'learning_rate': 0.008582365690576277}. Best is trial 13 with value: -759714966.183796.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL515 (val_loss=13.0558)\n",
      "[iter 0] loss=13.1151 val_loss=13.1285 scale=1.0000 norm=0.3232\n",
      "[iter 100] loss=13.0461 val_loss=13.0665 scale=2.0000 norm=0.2042\n",
      "[iter 200] loss=13.0362 val_loss=13.0576 scale=4.0000 norm=0.2500\n",
      "[iter 300] loss=13.0344 val_loss=13.0553 scale=8.0000 norm=0.4167\n",
      "[iter 400] loss=13.0354 val_loss=13.0547 scale=8.0000 norm=0.3740\n",
      "[iter 500] loss=13.0344 val_loss=13.0545 scale=8.0000 norm=0.3415\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL527 (val_loss=13.0544)\n",
      "[iter 0] loss=13.1084 val_loss=13.1279 scale=2.0000 norm=0.6267\n",
      "[iter 100] loss=13.0410 val_loss=13.0671 scale=2.0000 norm=0.2009\n",
      "[iter 200] loss=13.0319 val_loss=13.0587 scale=2.0000 norm=0.1253\n",
      "[iter 300] loss=13.0311 val_loss=13.0563 scale=8.0000 norm=0.4204\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL336 (val_loss=13.0559)\n",
      "[iter 0] loss=13.0916 val_loss=13.1292 scale=1.0000 norm=0.3179\n",
      "[iter 100] loss=13.0206 val_loss=13.0669 scale=2.0000 norm=0.2014\n",
      "[iter 200] loss=13.0135 val_loss=13.0581 scale=4.0000 norm=0.2502\n",
      "[iter 300] loss=13.0136 val_loss=13.0558 scale=8.0000 norm=0.4210\n",
      "[iter 400] loss=13.0111 val_loss=13.0552 scale=8.0000 norm=0.3739\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL440 (val_loss=13.0552)\n",
      "[iter 0] loss=13.1124 val_loss=13.1279 scale=2.0000 norm=0.6574\n",
      "[iter 100] loss=13.0351 val_loss=13.0700 scale=2.0000 norm=0.2028\n",
      "[iter 200] loss=13.0280 val_loss=13.0609 scale=2.0000 norm=0.1234\n",
      "[iter 300] loss=13.0318 val_loss=13.0583 scale=8.0000 norm=0.4201\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL337 (val_loss=13.0580)\n",
      "[iter 0] loss=13.1145 val_loss=13.1285 scale=1.0000 norm=0.3183\n",
      "[iter 100] loss=13.0418 val_loss=13.0669 scale=2.0000 norm=0.2023\n",
      "[iter 200] loss=13.0339 val_loss=13.0586 scale=2.0000 norm=0.1278\n",
      "[iter 300] loss=13.0408 val_loss=13.0566 scale=8.0000 norm=0.4376\n",
      "[iter 400] loss=13.0347 val_loss=13.0560 scale=8.0000 norm=0.3874\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL398 (val_loss=13.0560)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:45:33,335]\u001B[0m Trial 15 finished with value: -767941613.2870761 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'Exponential', 'n_estimators': 49677, 'minibatch_frac': 0.9860866017748082, 'learning_rate': 0.007364076470348008}. Best is trial 13 with value: -759714966.183796.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=13.1172 val_loss=13.1284 scale=2.0000 norm=0.6489\n",
      "[iter 100] loss=13.0530 val_loss=13.0801 scale=2.0000 norm=0.3075\n",
      "[iter 200] loss=13.0350 val_loss=13.0673 scale=2.0000 norm=0.1629\n",
      "[iter 300] loss=13.0339 val_loss=13.0621 scale=2.0000 norm=0.0898\n",
      "[iter 400] loss=13.0324 val_loss=13.0596 scale=2.0000 norm=0.0572\n",
      "[iter 500] loss=13.0375 val_loss=13.0585 scale=2.0000 norm=0.0420\n",
      "[iter 600] loss=13.0343 val_loss=13.0580 scale=2.0000 norm=0.0339\n",
      "[iter 700] loss=13.0205 val_loss=13.0575 scale=4.0000 norm=0.0512\n",
      "[iter 800] loss=13.0333 val_loss=13.0572 scale=4.0000 norm=0.0416\n",
      "[iter 900] loss=13.0321 val_loss=13.0571 scale=4.0000 norm=0.0342\n",
      "[iter 1000] loss=13.0354 val_loss=13.0571 scale=4.0000 norm=0.0281\n",
      "[iter 1100] loss=13.0322 val_loss=13.0570 scale=4.0000 norm=0.0229\n",
      "[iter 1200] loss=13.0278 val_loss=13.0570 scale=4.0000 norm=0.0187\n",
      "[iter 1300] loss=13.0301 val_loss=13.0569 scale=8.0000 norm=0.0301\n",
      "[iter 1400] loss=13.0272 val_loss=13.0569 scale=4.0000 norm=0.0124\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1398 (val_loss=13.0569)\n",
      "[iter 0] loss=13.1090 val_loss=13.1287 scale=2.0000 norm=0.6254\n",
      "[iter 100] loss=13.0497 val_loss=13.0796 scale=2.0000 norm=0.2976\n",
      "[iter 200] loss=13.0304 val_loss=13.0667 scale=2.0000 norm=0.1603\n",
      "[iter 300] loss=13.0281 val_loss=13.0616 scale=2.0000 norm=0.0894\n",
      "[iter 400] loss=13.0266 val_loss=13.0594 scale=2.0000 norm=0.0572\n",
      "[iter 500] loss=13.0309 val_loss=13.0585 scale=2.0000 norm=0.0424\n",
      "[iter 600] loss=13.0244 val_loss=13.0580 scale=2.0000 norm=0.0345\n",
      "[iter 700] loss=13.0163 val_loss=13.0576 scale=4.0000 norm=0.0519\n",
      "[iter 800] loss=13.0275 val_loss=13.0574 scale=4.0000 norm=0.0429\n",
      "[iter 900] loss=13.0301 val_loss=13.0573 scale=8.0000 norm=0.0693\n",
      "[iter 1000] loss=13.0322 val_loss=13.0572 scale=4.0000 norm=0.0281\n",
      "[iter 1100] loss=13.0263 val_loss=13.0572 scale=4.0000 norm=0.0230\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1129 (val_loss=13.0572)\n",
      "[iter 0] loss=13.0900 val_loss=13.1292 scale=2.0000 norm=0.6335\n",
      "[iter 100] loss=13.0302 val_loss=13.0814 scale=2.0000 norm=0.3024\n",
      "[iter 200] loss=13.0130 val_loss=13.0684 scale=2.0000 norm=0.1623\n",
      "[iter 300] loss=13.0161 val_loss=13.0629 scale=2.0000 norm=0.0895\n",
      "[iter 400] loss=13.0056 val_loss=13.0604 scale=2.0000 norm=0.0587\n",
      "[iter 500] loss=13.0115 val_loss=13.0593 scale=2.0000 norm=0.0433\n",
      "[iter 600] loss=13.0069 val_loss=13.0587 scale=2.0000 norm=0.0348\n",
      "[iter 700] loss=12.9965 val_loss=13.0582 scale=4.0000 norm=0.0518\n",
      "[iter 800] loss=13.0119 val_loss=13.0580 scale=4.0000 norm=0.0421\n",
      "[iter 900] loss=13.0119 val_loss=13.0579 scale=4.0000 norm=0.0340\n",
      "[iter 1000] loss=13.0111 val_loss=13.0579 scale=4.0000 norm=0.0278\n",
      "[iter 1100] loss=13.0066 val_loss=13.0578 scale=4.0000 norm=0.0226\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1157 (val_loss=13.0578)\n",
      "[iter 0] loss=13.1109 val_loss=13.1289 scale=1.0000 norm=0.3234\n",
      "[iter 100] loss=13.0445 val_loss=13.0826 scale=2.0000 norm=0.3122\n",
      "[iter 200] loss=13.0285 val_loss=13.0700 scale=2.0000 norm=0.1655\n",
      "[iter 300] loss=13.0336 val_loss=13.0647 scale=2.0000 norm=0.0908\n",
      "[iter 400] loss=13.0246 val_loss=13.0621 scale=2.0000 norm=0.0597\n",
      "[iter 500] loss=13.0327 val_loss=13.0609 scale=2.0000 norm=0.0439\n",
      "[iter 600] loss=13.0209 val_loss=13.0603 scale=2.0000 norm=0.0352\n",
      "[iter 700] loss=13.0201 val_loss=13.0597 scale=4.0000 norm=0.0529\n",
      "[iter 800] loss=13.0263 val_loss=13.0595 scale=4.0000 norm=0.0425\n",
      "[iter 900] loss=13.0276 val_loss=13.0594 scale=8.0000 norm=0.0697\n",
      "[iter 1000] loss=13.0240 val_loss=13.0593 scale=4.0000 norm=0.0282\n",
      "[iter 1100] loss=13.0216 val_loss=13.0593 scale=4.0000 norm=0.0232\n",
      "[iter 1200] loss=13.0191 val_loss=13.0593 scale=8.0000 norm=0.0374\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1285 (val_loss=13.0593)\n",
      "[iter 0] loss=13.1132 val_loss=13.1283 scale=2.0000 norm=0.6250\n",
      "[iter 100] loss=13.0512 val_loss=13.0785 scale=2.0000 norm=0.3031\n",
      "[iter 200] loss=13.0404 val_loss=13.0657 scale=2.0000 norm=0.1593\n",
      "[iter 300] loss=13.0414 val_loss=13.0607 scale=2.0000 norm=0.0875\n",
      "[iter 400] loss=13.0336 val_loss=13.0585 scale=2.0000 norm=0.0584\n",
      "[iter 500] loss=13.0358 val_loss=13.0576 scale=2.0000 norm=0.0429\n",
      "[iter 600] loss=13.0273 val_loss=13.0571 scale=2.0000 norm=0.0342\n",
      "[iter 700] loss=13.0341 val_loss=13.0567 scale=4.0000 norm=0.0510\n",
      "[iter 800] loss=13.0340 val_loss=13.0565 scale=4.0000 norm=0.0415\n",
      "[iter 900] loss=13.0356 val_loss=13.0564 scale=4.0000 norm=0.0340\n",
      "[iter 1000] loss=13.0268 val_loss=13.0564 scale=4.0000 norm=0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:52:05,423]\u001B[0m Trial 16 finished with value: -819284494.2819 and parameters: {'base_learner': 'GradientBoost_depth5', 'Dist': 'Exponential', 'n_estimators': 43368, 'minibatch_frac': 0.9498775729674107, 'learning_rate': 0.0038382562778499878}. Best is trial 13 with value: -759714966.183796.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1066 (val_loss=13.0564)\n",
      "[iter 0] loss=13.1305 val_loss=13.1281 scale=1.0000 norm=0.3315\n",
      "[iter 100] loss=13.0300 val_loss=13.0815 scale=2.0000 norm=0.1305\n",
      "[iter 200] loss=13.0283 val_loss=13.0756 scale=2.0000 norm=0.0262\n",
      "[iter 300] loss=13.0252 val_loss=13.0741 scale=2.0000 norm=0.0053\n",
      "[iter 400] loss=13.0269 val_loss=13.0737 scale=2.0000 norm=0.0012\n",
      "[iter 500] loss=13.0291 val_loss=13.0736 scale=2.0000 norm=0.0003\n",
      "== Quitting at iteration / GRAD 523\n",
      "[iter 0] loss=13.1214 val_loss=13.1280 scale=1.0000 norm=0.3251\n",
      "[iter 100] loss=13.0297 val_loss=13.0760 scale=2.0000 norm=0.1244\n",
      "[iter 200] loss=13.0191 val_loss=13.0705 scale=2.0000 norm=0.0256\n",
      "[iter 300] loss=13.0208 val_loss=13.0690 scale=2.0000 norm=0.0053\n",
      "[iter 400] loss=13.0282 val_loss=13.0687 scale=2.0000 norm=0.0011\n",
      "[iter 500] loss=13.0215 val_loss=13.0687 scale=2.0000 norm=0.0003\n",
      "== Quitting at iteration / GRAD 523\n",
      "[iter 0] loss=13.0980 val_loss=13.1289 scale=1.0000 norm=0.3277\n",
      "[iter 100] loss=13.0062 val_loss=13.0896 scale=2.0000 norm=0.1296\n",
      "[iter 200] loss=12.9998 val_loss=13.0832 scale=2.0000 norm=0.0261\n",
      "[iter 300] loss=13.0072 val_loss=13.0816 scale=2.0000 norm=0.0051\n",
      "[iter 400] loss=13.0120 val_loss=13.0812 scale=2.0000 norm=0.0011\n",
      "[iter 500] loss=13.0023 val_loss=13.0811 scale=2.0000 norm=0.0003\n",
      "== Quitting at iteration / GRAD 523\n",
      "[iter 0] loss=13.1179 val_loss=13.1283 scale=1.0000 norm=0.3335\n",
      "[iter 100] loss=13.0219 val_loss=13.0858 scale=2.0000 norm=0.1348\n",
      "[iter 200] loss=13.0150 val_loss=13.0809 scale=2.0000 norm=0.0263\n",
      "[iter 300] loss=13.0298 val_loss=13.0790 scale=2.0000 norm=0.0052\n",
      "[iter 400] loss=13.0243 val_loss=13.0786 scale=2.0000 norm=0.0011\n",
      "[iter 500] loss=13.0311 val_loss=13.0785 scale=2.0000 norm=0.0003\n",
      "== Quitting at iteration / GRAD 517\n",
      "[iter 0] loss=13.1132 val_loss=13.1283 scale=1.0000 norm=0.3177\n",
      "[iter 100] loss=13.0267 val_loss=13.0795 scale=2.0000 norm=0.1281\n",
      "[iter 200] loss=13.0273 val_loss=13.0741 scale=2.0000 norm=0.0252\n",
      "[iter 300] loss=13.0382 val_loss=13.0722 scale=2.0000 norm=0.0051\n",
      "[iter 400] loss=13.0442 val_loss=13.0719 scale=2.0000 norm=0.0011\n",
      "[iter 500] loss=13.0392 val_loss=13.0718 scale=2.0000 norm=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:52:36,081]\u001B[0m Trial 17 finished with value: -974326937.3519484 and parameters: {'base_learner': 'DecTree_depthNone', 'Dist': 'Exponential', 'n_estimators': 41867, 'minibatch_frac': 0.7948435197618333, 'learning_rate': 0.00873714601779402}. Best is trial 13 with value: -759714966.183796.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Quitting at iteration / GRAD 523\n",
      "[iter 0] loss=13.1215 val_loss=13.1283 scale=1.0000 norm=0.3252\n",
      "[iter 100] loss=13.0359 val_loss=13.0617 scale=2.0000 norm=0.1599\n",
      "[iter 200] loss=13.0321 val_loss=13.0557 scale=4.0000 norm=0.2207\n",
      "[iter 300] loss=13.0333 val_loss=13.0546 scale=8.0000 norm=0.3788\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL346 (val_loss=13.0545)\n",
      "[iter 0] loss=13.1107 val_loss=13.1268 scale=2.0000 norm=0.6261\n",
      "[iter 100] loss=13.0372 val_loss=13.0620 scale=2.0000 norm=0.1572\n",
      "[iter 200] loss=13.0272 val_loss=13.0563 scale=4.0000 norm=0.2187\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL277 (val_loss=13.0554)\n",
      "[iter 0] loss=13.0887 val_loss=13.1288 scale=1.0000 norm=0.3157\n",
      "[iter 100] loss=13.0187 val_loss=13.0624 scale=2.0000 norm=0.1572\n",
      "[iter 200] loss=13.0121 val_loss=13.0564 scale=4.0000 norm=0.2184\n",
      "[iter 300] loss=13.0164 val_loss=13.0554 scale=8.0000 norm=0.3707\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL306 (val_loss=13.0554)\n",
      "[iter 0] loss=13.1112 val_loss=13.1285 scale=1.0000 norm=0.3241\n",
      "[iter 100] loss=13.0320 val_loss=13.0644 scale=2.0000 norm=0.1627\n",
      "[iter 200] loss=13.0289 val_loss=13.0580 scale=4.0000 norm=0.2181\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL259 (val_loss=13.0574)\n",
      "[iter 0] loss=13.1145 val_loss=13.1270 scale=2.0000 norm=0.6252\n",
      "[iter 100] loss=13.0376 val_loss=13.0619 scale=2.0000 norm=0.1577\n",
      "[iter 200] loss=13.0376 val_loss=13.0568 scale=4.0000 norm=0.2254\n",
      "[iter 300] loss=13.0404 val_loss=13.0558 scale=8.0000 norm=0.3866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:53:44,694]\u001B[0m Trial 18 finished with value: -760649421.5226641 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'Exponential', 'n_estimators': 48416, 'minibatch_frac': 0.9166975046897456, 'learning_rate': 0.00971058627465138}. Best is trial 13 with value: -759714966.183796.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL310 (val_loss=13.0558)\n",
      "[iter 0] loss=13.1212 val_loss=13.1181 scale=2.0000 norm=0.6516\n",
      "[iter 100] loss=13.0299 val_loss=13.0545 scale=8.0000 norm=0.2837\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL159 (val_loss=13.0541)\n",
      "[iter 0] loss=13.1107 val_loss=13.1153 scale=2.0000 norm=0.6266\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL65 (val_loss=13.0561)\n",
      "[iter 0] loss=13.0886 val_loss=13.1233 scale=1.0000 norm=0.3159\n",
      "[iter 100] loss=13.0125 val_loss=13.0552 scale=8.0000 norm=0.2710\n",
      "[iter 200] loss=13.0119 val_loss=13.0545 scale=8.0000 norm=0.1626\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL214 (val_loss=13.0545)\n",
      "[iter 0] loss=13.1112 val_loss=13.1227 scale=1.0000 norm=0.3244\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL57 (val_loss=13.0574)\n",
      "[iter 0] loss=13.1152 val_loss=13.1223 scale=1.0000 norm=0.3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-07-17 15:54:03,239]\u001B[0m Trial 19 finished with value: -781938407.7865041 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'Exponential', 'n_estimators': 39816, 'minibatch_frac': 0.913343037503142, 'learning_rate': 0.05434061494139847}. Best is trial 13 with value: -759714966.183796.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL43 (val_loss=13.0566)\n",
      "[iter 0] loss=13.1133 val_loss=13.1284 scale=1.0000 norm=0.3110\n",
      "[iter 100] loss=13.0443 val_loss=13.0640 scale=2.0000 norm=0.1828\n",
      "[iter 200] loss=13.0262 val_loss=13.0568 scale=4.0000 norm=0.2369\n",
      "[iter 300] loss=13.0355 val_loss=13.0553 scale=8.0000 norm=0.4322\n",
      "[iter 400] loss=13.0308 val_loss=13.0549 scale=8.0000 norm=0.3827\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL400 (val_loss=13.0549)\n",
      "Started Predict with Ngboost at 15:54:22.\n",
      "The R2 score is 0.881090207248117\n",
      "The MAE score is 18410.6021790463\n",
      "The Median absolute error score is 13386.005325548263\n",
      "The MSE score is 28260.229837864565\n",
      "The RMSE score is 798640590.4889307\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this case we chose Ngboost, which is uses natural gradient. It is really strong for regression problem, but\n",
    "does not have GPU acceleration at all unfortunately. However we always recommend trying Ngboost if posible.\n",
    "\"\"\"\n",
    "housing_ml.ml_bp14_regressions_full_processing_ngboost(preprocessing_type='nlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pipeline\n",
    "save_to_production(housing_ml, file_name='housing_automl_instance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on new data\n",
    "In the beginning we kept a holdout dataset. We use this to simulate prediction on completely new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stored pipeline\n",
    "housing_ml_loaded = load_for_production(file_name='housing_automl_instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Execute test train split at 15:54:23.\n",
      "Started Apply datetime transformation at 15:54:23.\n",
      "Started Handle rare features at 15:54:23.\n",
      "Started Remove cardinality at 15:54:23.\n",
      "Started Onehot + PCA categorical features at 15:54:23.\n",
      "Started Execute categorical encoding at 15:54:23.\n",
      "Started  Delete columns with high share of NULLs at 15:54:23.\n",
      "Started Fill nulls at 15:54:23.\n",
      "Started Execute numerical binning at 15:54:23.\n",
      "Started Handle outliers at 15:54:24.\n",
      "Started Remove collinearity at 15:54:24.\n",
      "Started Execute clustering as a feature at 15:54:24.\n",
      "Started Execute clustering as a feature at 15:54:24.\n",
      "Started Execute clustering as a feature at 15:54:24.\n",
      "Started Execute clustering as a feature at 15:54:24.\n",
      "Started Execute clustering as a feature at 15:54:24.\n",
      "Started Execute clustering as a feature at 15:54:25.\n",
      "Started Execute clustering as a feature at 15:54:25.\n",
      "Started Execute clustering as a feature at 15:54:25.\n",
      "Started Execute clustering as a feature at 15:54:25.\n",
      "Started Select best features at 15:54:26.\n",
      "Started Sort columns alphabetically at 15:54:26.\n",
      "Started Predict with Ngboost at 15:54:26.\n"
     ]
    }
   ],
   "source": [
    "# predict on new data\n",
    "housing_ml_loaded.ml_bp14_regressions_full_processing_ngboost(val_df, preprocessing_type='full')\n",
    "\n",
    "# access predicted labels\n",
    "val_y_hat = housing_ml_loaded.predicted_values['ngboost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18038.33933308294\n"
     ]
    }
   ],
   "source": [
    "# Assess prediction quality on holdout data\n",
    "mae = mean_absolute_error(val_df_target, val_y_hat)\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Housing prices regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/thomas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/thomas/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/thomas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/thomas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "from e2eml.regression import regression_blueprints as rb\n",
    "from e2eml.full_processing.postprocessing import save_to_production, load_for_production\n",
    "from e2eml.test.regression_blueprints_test import load_housingprices_data\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "Load & preprocess housing prices dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do dataframe splits.\n"
     ]
    }
   ],
   "source": [
    "# load Housing price data\n",
    "test_df, test_target, val_df, val_df_target, test_categorical_cols = load_housingprices_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using e2eml - Run and save a pipeline\n",
    "We only need a few steps to get ur full pipeline:\n",
    "- Instantiate class\n",
    "- Run chosen blueprint\n",
    "- Save blueprint for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ml task is regression\n",
      "Preferred training mode auto has been chosen. e2eml will automatically detect, if LGBM and Xgboost can use GPU acceleration and optimize the workflow accordingly.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate class\n",
    "housing_ml = rb.RegressionBluePrint(datasource=test_df,\n",
    "                                         target_variable=test_target, # only a string with the target column name within the dataframe\n",
    "                                         categorical_columns=test_categorical_cols, # here we specify cat columns (that is optional however)\n",
    "                                         tune_mode='accurate',\n",
    "                                         ml_task='regression') # usually not needed, but sometimes it might have to be called explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some target classes have less members than allowed. You can ignore this message, if you\n",
      "            are running a blueprint without NLP transformers.\n",
      "            \n",
      "            In order to create a strong model e2eml splits the data into several folds. Please provide data with at least\n",
      "             6 class members for each target class. Otherwise the model is likely to fail to a CUDA error on runtime. \n",
      "             You can use the following function on your dataframe before passing it to e2eml:\n",
      "            \n",
      "            def handle_rarity(all_data, threshold=6, mask_as='miscellaneous', rarity_cols=None, normalize=False):\n",
      "                if isinstance(rarity_cols, list):\n",
      "                    for col in rarity_cols:\n",
      "                        frequencies = all_data[col].value_counts(normalize=normalize)\n",
      "                        condition = frequencies < threshold\n",
      "                        mask_obs = frequencies[condition].index\n",
      "                        mask_dict = dict.fromkeys(mask_obs, mask_as)\n",
      "                        all_data[col] = all_data[col].replace(mask_dict)\n",
      "                    del rarity_cols\n",
      "                else:\n",
      "                    pass\n",
      "                return all_data\n",
      "                \n",
      "            Example usage:\n",
      "            train_df = handle_rarity(train_df, rarity_cols=[\"your_target_column_name\"])\n",
      "            \n",
      "            Important:\n",
      "            This function modifies the original data. It is recommended to create a copy of your data first.\n",
      "            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Execute test train split at 15:19:57.\n",
      "Started Apply datetime transformation at 15:19:57.\n",
      "Started Start Spacy, POS tagging at 15:19:58.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 800 entries, 29 to 102\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             800 non-null    int64  \n",
      " 1   MSSubClass     800 non-null    int64  \n",
      " 2   MSZoning       800 non-null    object \n",
      " 3   LotFrontage    663 non-null    float64\n",
      " 4   LotArea        800 non-null    int64  \n",
      " 5   Street         800 non-null    object \n",
      " 6   Alley          50 non-null     object \n",
      " 7   LotShape       800 non-null    object \n",
      " 8   LandContour    800 non-null    object \n",
      " 9   Utilities      800 non-null    object \n",
      " 10  LotConfig      800 non-null    object \n",
      " 11  LandSlope      800 non-null    object \n",
      " 12  Neighborhood   800 non-null    object \n",
      " 13  Condition1     800 non-null    object \n",
      " 14  Condition2     800 non-null    object \n",
      " 15  BldgType       800 non-null    object \n",
      " 16  HouseStyle     800 non-null    object \n",
      " 17  OverallQual    800 non-null    int64  \n",
      " 18  OverallCond    800 non-null    int64  \n",
      " 19  YearBuilt      800 non-null    int64  \n",
      " 20  YearRemodAdd   800 non-null    int64  \n",
      " 21  RoofStyle      800 non-null    object \n",
      " 22  RoofMatl       800 non-null    object \n",
      " 23  Exterior1st    800 non-null    object \n",
      " 24  Exterior2nd    800 non-null    object \n",
      " 25  MasVnrType     799 non-null    object \n",
      " 26  MasVnrArea     799 non-null    float64\n",
      " 27  ExterQual      800 non-null    object \n",
      " 28  ExterCond      800 non-null    object \n",
      " 29  Foundation     800 non-null    object \n",
      " 30  BsmtQual       780 non-null    object \n",
      " 31  BsmtCond       780 non-null    object \n",
      " 32  BsmtExposure   780 non-null    object \n",
      " 33  BsmtFinType1   780 non-null    object \n",
      " 34  BsmtFinSF1     800 non-null    int64  \n",
      " 35  BsmtFinType2   780 non-null    object \n",
      " 36  BsmtFinSF2     800 non-null    int64  \n",
      " 37  BsmtUnfSF      800 non-null    int64  \n",
      " 38  TotalBsmtSF    800 non-null    int64  \n",
      " 39  Heating        800 non-null    object \n",
      " 40  HeatingQC      800 non-null    object \n",
      " 41  CentralAir     800 non-null    object \n",
      " 42  Electrical     800 non-null    object \n",
      " 43  1stFlrSF       800 non-null    int64  \n",
      " 44  2ndFlrSF       800 non-null    int64  \n",
      " 45  LowQualFinSF   800 non-null    int64  \n",
      " 46  GrLivArea      800 non-null    int64  \n",
      " 47  BsmtFullBath   800 non-null    int64  \n",
      " 48  BsmtHalfBath   800 non-null    int64  \n",
      " 49  FullBath       800 non-null    int64  \n",
      " 50  HalfBath       800 non-null    int64  \n",
      " 51  BedroomAbvGr   800 non-null    int64  \n",
      " 52  KitchenAbvGr   800 non-null    int64  \n",
      " 53  KitchenQual    800 non-null    object \n",
      " 54  TotRmsAbvGrd   800 non-null    int64  \n",
      " 55  Functional     800 non-null    object \n",
      " 56  Fireplaces     800 non-null    int64  \n",
      " 57  FireplaceQu    428 non-null    object \n",
      " 58  GarageType     757 non-null    object \n",
      " 59  GarageYrBlt    757 non-null    float64\n",
      " 60  GarageFinish   757 non-null    object \n",
      " 61  GarageCars     800 non-null    int64  \n",
      " 62  GarageArea     800 non-null    int64  \n",
      " 63  GarageQual     757 non-null    object \n",
      " 64  GarageCond     757 non-null    object \n",
      " 65  PavedDrive     800 non-null    object \n",
      " 66  WoodDeckSF     800 non-null    int64  \n",
      " 67  OpenPorchSF    800 non-null    int64  \n",
      " 68  EnclosedPorch  800 non-null    int64  \n",
      " 69  3SsnPorch      800 non-null    int64  \n",
      " 70  ScreenPorch    800 non-null    int64  \n",
      " 71  PoolArea       800 non-null    int64  \n",
      " 72  PoolQC         1 non-null      object \n",
      " 73  Fence          154 non-null    object \n",
      " 74  MiscFeature    35 non-null     object \n",
      " 75  MiscVal        800 non-null    int64  \n",
      " 76  MoSold         800 non-null    int64  \n",
      " 77  YrSold         800 non-null    int64  \n",
      " 78  SaleType       800 non-null    object \n",
      " 79  SaleCondition  800 non-null    object \n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 506.2+ KB\n",
      "None\n",
      "Started Handle rare features at 15:19:58.\n",
      "Started Remove cardinality at 15:19:58.\n",
      "Started Onehot + PCA categorical features at 15:19:58.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Execute categorical encoding at 15:19:59.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started  Delete columns with high share of NULLs at 15:20:00.\n",
      "Started Fill nulls at 15:20:00.\n",
      "Started Execute numerical binning at 15:20:00.\n",
      "Started Handle outliers at 15:20:01.\n",
      "Started Remove collinearity at 15:20:01.\n",
      "Started Execute clustering as a feature at 15:20:02.\n",
      "Started Scale data at 15:20:02.\n",
      "Started Execute clustering as a feature at 15:20:02.\n",
      "Started Execute clustering as a feature at 15:20:03.\n",
      "Started Execute clustering as a feature at 15:20:04.\n",
      "Started Execute clustering as a feature at 15:20:04.\n",
      "Started Execute clustering as a feature at 15:20:05.\n",
      "Started Execute clustering as a feature at 15:20:06.\n",
      "Started Execute clustering as a feature at 15:20:06.\n",
      "Started Execute clustering as a feature at 15:20:07.\n",
      "Started Select best features at 15:20:08.\n",
      "Features before selection are...Id\n",
      "Features before selection are...MSSubClass\n",
      "Features before selection are...MSZoning\n",
      "Features before selection are...LotFrontage\n",
      "Features before selection are...LotArea\n",
      "Features before selection are...Street\n",
      "Features before selection are...Alley\n",
      "Features before selection are...LotShape\n",
      "Features before selection are...LandContour\n",
      "Features before selection are...Utilities\n",
      "Features before selection are...LotConfig\n",
      "Features before selection are...LandSlope\n",
      "Features before selection are...Neighborhood\n",
      "Features before selection are...Condition1\n",
      "Features before selection are...Condition2\n",
      "Features before selection are...BldgType\n",
      "Features before selection are...HouseStyle\n",
      "Features before selection are...OverallQual\n",
      "Features before selection are...OverallCond\n",
      "Features before selection are...YearBuilt\n",
      "Features before selection are...YearRemodAdd\n",
      "Features before selection are...RoofStyle\n",
      "Features before selection are...RoofMatl\n",
      "Features before selection are...Exterior1st\n",
      "Features before selection are...MasVnrType\n",
      "Features before selection are...MasVnrArea\n",
      "Features before selection are...ExterQual\n",
      "Features before selection are...ExterCond\n",
      "Features before selection are...Foundation\n",
      "Features before selection are...BsmtQual\n",
      "Features before selection are...BsmtCond\n",
      "Features before selection are...BsmtExposure\n",
      "Features before selection are...BsmtFinType1\n",
      "Features before selection are...BsmtFinSF1\n",
      "Features before selection are...BsmtFinType2\n",
      "Features before selection are...BsmtFinSF2\n",
      "Features before selection are...BsmtUnfSF\n",
      "Features before selection are...TotalBsmtSF\n",
      "Features before selection are...Heating\n",
      "Features before selection are...HeatingQC\n",
      "Features before selection are...CentralAir\n",
      "Features before selection are...Electrical\n",
      "Features before selection are...2ndFlrSF\n",
      "Features before selection are...LowQualFinSF\n",
      "Features before selection are...GrLivArea\n",
      "Features before selection are...BsmtFullBath\n",
      "Features before selection are...BsmtHalfBath\n",
      "Features before selection are...FullBath\n",
      "Features before selection are...HalfBath\n",
      "Features before selection are...BedroomAbvGr\n",
      "Features before selection are...KitchenAbvGr\n",
      "Features before selection are...KitchenQual\n",
      "Features before selection are...Functional\n",
      "Features before selection are...Fireplaces\n",
      "Features before selection are...FireplaceQu\n",
      "Features before selection are...GarageType\n",
      "Features before selection are...GarageYrBlt\n",
      "Features before selection are...GarageFinish\n",
      "Features before selection are...GarageCars\n",
      "Features before selection are...PavedDrive\n",
      "Features before selection are...WoodDeckSF\n",
      "Features before selection are...OpenPorchSF\n",
      "Features before selection are...EnclosedPorch\n",
      "Features before selection are...3SsnPorch\n",
      "Features before selection are...ScreenPorch\n",
      "Features before selection are...PoolArea\n",
      "Features before selection are...Fence\n",
      "Features before selection are...MiscFeature\n",
      "Features before selection are...MiscVal\n",
      "Features before selection are...MoSold\n",
      "Features before selection are...YrSold\n",
      "Features before selection are...SaleType\n",
      "Features before selection are...PC-1_pca\n",
      "Features before selection are...PC-2_pca\n",
      "Features before selection are...isolation_probs\n",
      "Features before selection are...isolation_class\n",
      "Features before selection are...dbscan_cluster\n",
      "Features before selection are...kmeans_clusters2\n",
      "Features before selection are...kmeans_clusters3\n",
      "Features before selection are...kmeans_clusters4\n",
      "Features before selection are...kmeans_clusters5\n",
      "Features before selection are...kmeans_clusters6\n",
      "Features before selection are...kmeans_clusters7\n",
      "Features before selection are...kmeans_clusters8\n",
      "Features before selection are...kmeans_clusters9\n",
      "[15:20:08] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  1\n",
      "[15:20:12] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  2\n",
      "[15:20:17] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  3\n",
      "[15:20:20] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  4\n",
      "[15:20:22] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  5\n",
      "[15:20:27] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  6\n",
      "[15:20:32] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  7\n",
      "[15:20:35] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  8\n",
      "[15:20:39] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  9\n",
      "[15:20:41] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  1  iteration:  10\n",
      "[15:20:45] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  1\n",
      "[15:20:48] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  2\n",
      "[15:20:51] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  3\n",
      "[15:20:56] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  4\n",
      "[15:21:00] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  5\n",
      "[15:21:03] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  6\n",
      "[15:21:05] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  7\n",
      "[15:21:10] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  8\n",
      "[15:21:15] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  9\n",
      "[15:21:19] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  2  iteration:  10\n",
      "BoostARoota ran successfully! Algorithm went through  2  rounds.\n",
      " Selected features are... Id.\n",
      " Selected features are... MSSubClass.\n",
      " Selected features are... MSZoning.\n",
      " Selected features are... LotFrontage.\n",
      " Selected features are... LotArea.\n",
      " Selected features are... Alley.\n",
      " Selected features are... LotShape.\n",
      " Selected features are... LandContour.\n",
      " Selected features are... LotConfig.\n",
      " Selected features are... LandSlope.\n",
      " Selected features are... Neighborhood.\n",
      " Selected features are... Condition1.\n",
      " Selected features are... BldgType.\n",
      " Selected features are... HouseStyle.\n",
      " Selected features are... OverallQual.\n",
      " Selected features are... OverallCond.\n",
      " Selected features are... YearBuilt.\n",
      " Selected features are... YearRemodAdd.\n",
      " Selected features are... RoofStyle.\n",
      " Selected features are... RoofMatl.\n",
      " Selected features are... Exterior1st.\n",
      " Selected features are... MasVnrType.\n",
      " Selected features are... MasVnrArea.\n",
      " Selected features are... ExterQual.\n",
      " Selected features are... ExterCond.\n",
      " Selected features are... Foundation.\n",
      " Selected features are... BsmtQual.\n",
      " Selected features are... BsmtCond.\n",
      " Selected features are... BsmtExposure.\n",
      " Selected features are... BsmtFinType1.\n",
      " Selected features are... BsmtFinSF1.\n",
      " Selected features are... BsmtFinType2.\n",
      " Selected features are... BsmtFinSF2.\n",
      " Selected features are... BsmtUnfSF.\n",
      " Selected features are... TotalBsmtSF.\n",
      " Selected features are... Heating.\n",
      " Selected features are... HeatingQC.\n",
      " Selected features are... CentralAir.\n",
      " Selected features are... Electrical.\n",
      " Selected features are... 2ndFlrSF.\n",
      " Selected features are... GrLivArea.\n",
      " Selected features are... BsmtFullBath.\n",
      " Selected features are... BsmtHalfBath.\n",
      " Selected features are... FullBath.\n",
      " Selected features are... HalfBath.\n",
      " Selected features are... BedroomAbvGr.\n",
      " Selected features are... KitchenQual.\n",
      " Selected features are... Functional.\n",
      " Selected features are... Fireplaces.\n",
      " Selected features are... FireplaceQu.\n",
      " Selected features are... GarageType.\n",
      " Selected features are... GarageYrBlt.\n",
      " Selected features are... GarageFinish.\n",
      " Selected features are... GarageCars.\n",
      " Selected features are... PavedDrive.\n",
      " Selected features are... WoodDeckSF.\n",
      " Selected features are... OpenPorchSF.\n",
      " Selected features are... EnclosedPorch.\n",
      " Selected features are... 3SsnPorch.\n",
      " Selected features are... ScreenPorch.\n",
      " Selected features are... Fence.\n",
      " Selected features are... MiscFeature.\n",
      " Selected features are... MoSold.\n",
      " Selected features are... YrSold.\n",
      " Selected features are... SaleType.\n",
      " Selected features are... PC-1_pca.\n",
      " Selected features are... PC-2_pca.\n",
      " Selected features are... isolation_probs.\n",
      " Selected features are... kmeans_clusters2.\n",
      " Selected features are... kmeans_clusters4.\n",
      " Selected features are... kmeans_clusters5.\n",
      " Selected features are... kmeans_clusters6.\n",
      " Selected features are... kmeans_clusters7.\n",
      " Selected features are... kmeans_clusters8.\n",
      " Selected features are... kmeans_clusters9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:21:24,052]\u001b[0m A new study created in memory with name: no-name-d2394aad-a8ef-4ad3-8a22-100ea6e1adaf\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Sort columns alphabetically at 15:21:23.\n",
      "Started Train Ngboost at 15:21:24.\n",
      "[iter 0] loss=12.7239 val_loss=12.5511 scale=2.0000 norm=122749.4355\n",
      "[iter 100] loss=11.6251 val_loss=11.8475 scale=2.0000 norm=26081.2832\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL158 (val_loss=11.6608)\n",
      "[iter 0] loss=12.7273 val_loss=12.5571 scale=2.0000 norm=121870.0809\n",
      "[iter 100] loss=11.6261 val_loss=11.8129 scale=2.0000 norm=26801.7708\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL169 (val_loss=11.5620)\n",
      "[iter 0] loss=12.7366 val_loss=12.5597 scale=2.0000 norm=122737.8371\n",
      "[iter 100] loss=11.6376 val_loss=11.8228 scale=2.0000 norm=27725.4771\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL168 (val_loss=11.5804)\n",
      "[iter 0] loss=12.6929 val_loss=12.5313 scale=2.0000 norm=119340.3685\n",
      "[iter 100] loss=11.5830 val_loss=11.7714 scale=2.0000 norm=25765.2758\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL173 (val_loss=11.5076)\n",
      "[iter 0] loss=12.7076 val_loss=12.5535 scale=2.0000 norm=119673.3465\n",
      "[iter 100] loss=11.6402 val_loss=11.8052 scale=2.0000 norm=27649.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:23:52,398]\u001b[0m Trial 0 finished with value: -889824897.7742364 and parameters: {'base_learner': 'GradientBoost_depth5', 'Dist': 'Normal', 'n_estimators': 48198, 'minibatch_frac': 0.5210588095817861, 'learning_rate': 0.009437275576101205}. Best is trial 0 with value: -889824897.7742364.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL174 (val_loss=11.5358)\n",
      "[iter 0] loss=12.5540 val_loss=12.4041 scale=2.0000 norm=1.2846\n",
      "[iter 100] loss=11.5363 val_loss=11.6515 scale=2.0000 norm=0.8683\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL179 (val_loss=11.4309)\n",
      "[iter 0] loss=12.5371 val_loss=12.4022 scale=2.0000 norm=1.2697\n",
      "[iter 100] loss=11.5342 val_loss=11.6346 scale=2.0000 norm=0.8665\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL185 (val_loss=11.3830)\n",
      "[iter 0] loss=12.5844 val_loss=12.4050 scale=2.0000 norm=1.3177\n",
      "[iter 100] loss=11.5461 val_loss=11.6431 scale=2.0000 norm=0.8711\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL184 (val_loss=11.3978)\n",
      "[iter 0] loss=12.5557 val_loss=12.3982 scale=2.0000 norm=1.2946\n",
      "[iter 100] loss=11.5189 val_loss=11.6087 scale=2.0000 norm=0.8700\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL187 (val_loss=11.3367)\n",
      "[iter 0] loss=12.5656 val_loss=12.4083 scale=2.0000 norm=1.2763\n",
      "[iter 100] loss=11.5514 val_loss=11.6294 scale=2.0000 norm=0.8878\n",
      "[iter 200] loss=10.9745 val_loss=11.3412 scale=2.0000 norm=0.8157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:25:20,882]\u001b[0m Trial 1 finished with value: -841773693.6131566 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 35005, 'minibatch_frac': 0.5147808490055511, 'learning_rate': 0.00994760328924329}. Best is trial 1 with value: -841773693.6131566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL195 (val_loss=11.3398)\n",
      "[iter 0] loss=12.5714 val_loss=12.4181 scale=1.0000 norm=0.6541\n",
      "[iter 100] loss=12.4204 val_loss=12.3342 scale=1.0000 norm=0.5375\n",
      "[iter 200] loss=12.2690 val_loss=12.2549 scale=2.0000 norm=0.9528\n",
      "[iter 300] loss=12.1154 val_loss=12.1675 scale=2.0000 norm=0.8960\n",
      "[iter 400] loss=11.9922 val_loss=12.0952 scale=2.0000 norm=0.8825\n",
      "[iter 500] loss=11.8892 val_loss=12.0244 scale=2.0000 norm=0.8825\n",
      "[iter 600] loss=11.7720 val_loss=11.9554 scale=2.0000 norm=0.8810\n",
      "[iter 700] loss=11.6649 val_loss=11.8890 scale=2.0000 norm=0.8781\n",
      "[iter 800] loss=11.5439 val_loss=11.8289 scale=2.0000 norm=0.8767\n",
      "[iter 900] loss=11.4384 val_loss=11.7780 scale=2.0000 norm=0.8740\n",
      "[iter 1000] loss=11.3348 val_loss=11.7407 scale=2.0000 norm=0.8690\n",
      "[iter 1100] loss=11.2065 val_loss=11.7216 scale=2.0000 norm=0.8650\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1132 (val_loss=11.7201)\n",
      "[iter 0] loss=12.5700 val_loss=12.4169 scale=1.0000 norm=0.6529\n",
      "[iter 100] loss=12.4205 val_loss=12.3309 scale=1.0000 norm=0.5399\n",
      "[iter 200] loss=12.3008 val_loss=12.2542 scale=1.0000 norm=0.4831\n",
      "[iter 300] loss=12.1520 val_loss=12.1561 scale=2.0000 norm=0.9127\n",
      "[iter 400] loss=12.0184 val_loss=12.0680 scale=2.0000 norm=0.8830\n",
      "[iter 500] loss=11.9209 val_loss=11.9860 scale=2.0000 norm=0.8833\n",
      "[iter 600] loss=11.7858 val_loss=11.9108 scale=2.0000 norm=0.8809\n",
      "[iter 700] loss=11.6692 val_loss=11.8386 scale=2.0000 norm=0.8828\n",
      "[iter 800] loss=11.5639 val_loss=11.7687 scale=2.0000 norm=0.8811\n",
      "[iter 900] loss=11.4509 val_loss=11.7050 scale=2.0000 norm=0.8794\n",
      "[iter 1000] loss=11.3464 val_loss=11.6509 scale=2.0000 norm=0.8779\n",
      "[iter 1100] loss=11.2162 val_loss=11.6109 scale=2.0000 norm=0.8764\n",
      "[iter 1200] loss=11.1188 val_loss=11.5888 scale=2.0000 norm=0.8697\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1250 (val_loss=11.5861)\n",
      "[iter 0] loss=12.5983 val_loss=12.4209 scale=1.0000 norm=0.6600\n",
      "[iter 100] loss=12.4325 val_loss=12.3451 scale=1.0000 norm=0.5381\n",
      "[iter 200] loss=12.3043 val_loss=12.2747 scale=2.0000 norm=0.9583\n",
      "[iter 300] loss=12.1528 val_loss=12.1855 scale=2.0000 norm=0.9075\n",
      "[iter 400] loss=12.0168 val_loss=12.1110 scale=2.0000 norm=0.8837\n",
      "[iter 500] loss=11.9145 val_loss=12.0323 scale=2.0000 norm=0.8840\n",
      "[iter 600] loss=11.7822 val_loss=11.9560 scale=2.0000 norm=0.8808\n",
      "[iter 700] loss=11.6551 val_loss=11.8856 scale=2.0000 norm=0.8841\n",
      "[iter 800] loss=11.5435 val_loss=11.8194 scale=2.0000 norm=0.8834\n",
      "[iter 900] loss=11.4449 val_loss=11.7608 scale=2.0000 norm=0.8807\n",
      "[iter 1000] loss=11.3390 val_loss=11.7147 scale=2.0000 norm=0.8789\n",
      "[iter 1100] loss=11.2208 val_loss=11.6848 scale=2.0000 norm=0.8730\n",
      "[iter 1200] loss=11.1216 val_loss=11.6736 scale=2.0000 norm=0.8649\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1201 (val_loss=11.6735)\n",
      "[iter 0] loss=12.5851 val_loss=12.4151 scale=1.0000 norm=0.6671\n",
      "[iter 100] loss=12.3969 val_loss=12.3194 scale=2.0000 norm=1.0610\n",
      "[iter 200] loss=12.2293 val_loss=12.2143 scale=2.0000 norm=0.9285\n",
      "[iter 300] loss=12.0936 val_loss=12.1120 scale=2.0000 norm=0.8913\n",
      "[iter 400] loss=11.9456 val_loss=12.0220 scale=2.0000 norm=0.8787\n",
      "[iter 500] loss=11.8479 val_loss=11.9358 scale=2.0000 norm=0.8769\n",
      "[iter 600] loss=11.7138 val_loss=11.8501 scale=2.0000 norm=0.8765\n",
      "[iter 700] loss=11.5936 val_loss=11.7688 scale=2.0000 norm=0.8820\n",
      "[iter 800] loss=11.4834 val_loss=11.6931 scale=2.0000 norm=0.8805\n",
      "[iter 900] loss=11.3774 val_loss=11.6254 scale=2.0000 norm=0.8811\n",
      "[iter 1000] loss=11.2712 val_loss=11.5700 scale=2.0000 norm=0.8761\n",
      "[iter 1100] loss=11.1652 val_loss=11.5285 scale=2.0000 norm=0.8684\n",
      "[iter 1200] loss=11.0669 val_loss=11.5050 scale=2.0000 norm=0.8610\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1269 (val_loss=11.4997)\n",
      "[iter 0] loss=12.6006 val_loss=12.4228 scale=1.0000 norm=0.6611\n",
      "[iter 100] loss=12.4360 val_loss=12.3378 scale=1.0000 norm=0.5433\n",
      "[iter 200] loss=12.3056 val_loss=12.2550 scale=2.0000 norm=0.9596\n",
      "[iter 300] loss=12.1609 val_loss=12.1537 scale=2.0000 norm=0.9110\n",
      "[iter 400] loss=11.9961 val_loss=12.0644 scale=2.0000 norm=0.8882\n",
      "[iter 500] loss=11.9136 val_loss=11.9798 scale=2.0000 norm=0.8813\n",
      "[iter 600] loss=11.7686 val_loss=11.8971 scale=2.0000 norm=0.8784\n",
      "[iter 700] loss=11.6540 val_loss=11.8147 scale=2.0000 norm=0.8849\n",
      "[iter 800] loss=11.5565 val_loss=11.7355 scale=2.0000 norm=0.8853\n",
      "[iter 900] loss=11.4522 val_loss=11.6642 scale=2.0000 norm=0.8832\n",
      "[iter 1000] loss=11.3294 val_loss=11.6028 scale=2.0000 norm=0.8785\n",
      "[iter 1100] loss=11.2313 val_loss=11.5560 scale=2.0000 norm=0.8744\n",
      "[iter 1200] loss=11.1350 val_loss=11.5255 scale=2.0000 norm=0.8666\n",
      "[iter 1300] loss=11.0242 val_loss=11.5140 scale=2.0000 norm=0.8544\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1292 (val_loss=11.5140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:27:14,078]\u001b[0m Trial 2 finished with value: -971877667.4856697 and parameters: {'base_learner': 'DecTree_depth5', 'Dist': 'LogNormal', 'n_estimators': 30502, 'minibatch_frac': 0.7963646418605659, 'learning_rate': 0.0012676525847053462}. Best is trial 1 with value: -841773693.6131566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=13.1317 val_loss=13.0547 scale=1.0000 norm=0.3322\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL29 (val_loss=13.0054)\n",
      "[iter 0] loss=13.1207 val_loss=13.0540 scale=1.0000 norm=0.3358\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL29 (val_loss=13.0042)\n",
      "[iter 0] loss=13.1296 val_loss=13.0559 scale=1.0000 norm=0.3386\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL53 (val_loss=13.0048)\n",
      "[iter 0] loss=13.1205 val_loss=13.0481 scale=2.0000 norm=0.6527\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL60 (val_loss=13.0036)\n",
      "[iter 0] loss=13.1217 val_loss=13.0460 scale=2.0000 norm=0.6587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:27:25,495]\u001b[0m Trial 3 finished with value: -909607496.5930477 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'Exponential', 'n_estimators': 35532, 'minibatch_frac': 0.9090002851415449, 'learning_rate': 0.0992613096587529}. Best is trial 1 with value: -841773693.6131566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL25 (val_loss=13.0036)\n",
      "[iter 0] loss=12.5803 val_loss=12.4162 scale=2.0000 norm=1.3178\n",
      "[iter 100] loss=12.2427 val_loss=12.2317 scale=2.0000 norm=0.9283\n",
      "[iter 200] loss=12.0435 val_loss=12.0991 scale=2.0000 norm=0.8897\n",
      "[iter 300] loss=11.8752 val_loss=11.9772 scale=2.0000 norm=0.8935\n",
      "[iter 400] loss=11.7232 val_loss=11.8652 scale=2.0000 norm=0.9085\n",
      "[iter 500] loss=11.5654 val_loss=11.7662 scale=2.0000 norm=0.9210\n",
      "[iter 600] loss=11.4076 val_loss=11.6848 scale=2.0000 norm=0.9319\n",
      "[iter 700] loss=11.2580 val_loss=11.6272 scale=2.0000 norm=0.9374\n",
      "[iter 800] loss=11.0977 val_loss=11.6036 scale=2.0000 norm=0.9405\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL805 (val_loss=11.6034)\n",
      "[iter 0] loss=12.5771 val_loss=12.4149 scale=2.0000 norm=1.3083\n",
      "[iter 100] loss=12.2365 val_loss=12.2260 scale=2.0000 norm=0.9291\n",
      "[iter 200] loss=12.0401 val_loss=12.0857 scale=2.0000 norm=0.8897\n",
      "[iter 300] loss=11.8719 val_loss=11.9569 scale=2.0000 norm=0.8944\n",
      "[iter 400] loss=11.7255 val_loss=11.8387 scale=2.0000 norm=0.9071\n",
      "[iter 500] loss=11.5632 val_loss=11.7326 scale=2.0000 norm=0.9208\n",
      "[iter 600] loss=11.4047 val_loss=11.6428 scale=2.0000 norm=0.9304\n",
      "[iter 700] loss=11.2548 val_loss=11.5760 scale=2.0000 norm=0.9369\n",
      "[iter 800] loss=11.0969 val_loss=11.5393 scale=2.0000 norm=0.9398\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL843 (val_loss=11.5354)\n",
      "[iter 0] loss=12.5913 val_loss=12.4189 scale=2.0000 norm=1.3099\n",
      "[iter 100] loss=12.2589 val_loss=12.2374 scale=2.0000 norm=0.9333\n",
      "[iter 200] loss=12.0591 val_loss=12.1019 scale=2.0000 norm=0.8903\n",
      "[iter 300] loss=11.8914 val_loss=11.9765 scale=2.0000 norm=0.8959\n",
      "[iter 400] loss=11.7406 val_loss=11.8602 scale=2.0000 norm=0.9082\n",
      "[iter 500] loss=11.5808 val_loss=11.7553 scale=2.0000 norm=0.9214\n",
      "[iter 600] loss=11.4234 val_loss=11.6658 scale=2.0000 norm=0.9302\n",
      "[iter 700] loss=11.2696 val_loss=11.5985 scale=2.0000 norm=0.9379\n",
      "[iter 800] loss=11.1094 val_loss=11.5620 scale=2.0000 norm=0.9406\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL837 (val_loss=11.5578)\n",
      "[iter 0] loss=12.5677 val_loss=12.4130 scale=2.0000 norm=1.3074\n",
      "[iter 100] loss=12.2324 val_loss=12.2064 scale=2.0000 norm=0.9339\n",
      "[iter 200] loss=12.0363 val_loss=12.0591 scale=2.0000 norm=0.8901\n",
      "[iter 300] loss=11.8700 val_loss=11.9246 scale=2.0000 norm=0.8958\n",
      "[iter 400] loss=11.7157 val_loss=11.7993 scale=2.0000 norm=0.9069\n",
      "[iter 500] loss=11.5575 val_loss=11.6855 scale=2.0000 norm=0.9209\n",
      "[iter 600] loss=11.3983 val_loss=11.5858 scale=2.0000 norm=0.9299\n",
      "[iter 700] loss=11.2423 val_loss=11.5050 scale=2.0000 norm=0.9369\n",
      "[iter 800] loss=11.0835 val_loss=11.4503 scale=2.0000 norm=0.9400\n",
      "[iter 900] loss=10.9355 val_loss=11.4306 scale=2.0000 norm=0.9406\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL893 (val_loss=11.4305)\n",
      "[iter 0] loss=12.5908 val_loss=12.4206 scale=2.0000 norm=1.3114\n",
      "[iter 100] loss=12.2645 val_loss=12.2262 scale=2.0000 norm=0.9427\n",
      "[iter 200] loss=12.0712 val_loss=12.0810 scale=2.0000 norm=0.8965\n",
      "[iter 300] loss=11.9043 val_loss=11.9475 scale=2.0000 norm=0.9007\n",
      "[iter 400] loss=11.7353 val_loss=11.8230 scale=2.0000 norm=0.9087\n",
      "[iter 500] loss=11.5861 val_loss=11.7094 scale=2.0000 norm=0.9221\n",
      "[iter 600] loss=11.4241 val_loss=11.6092 scale=2.0000 norm=0.9315\n",
      "[iter 700] loss=11.2660 val_loss=11.5279 scale=2.0000 norm=0.9378\n",
      "[iter 800] loss=11.1184 val_loss=11.4720 scale=2.0000 norm=0.9422\n",
      "[iter 900] loss=10.9677 val_loss=11.4509 scale=2.0000 norm=0.9427\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL900 (val_loss=11.4509)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:44:35,093]\u001b[0m Trial 4 finished with value: -942595260.8079674 and parameters: {'base_learner': 'GradientBoost_depth5', 'Dist': 'LogNormal', 'n_estimators': 42483, 'minibatch_frac': 0.9351310305514687, 'learning_rate': 0.0016038139590983558}. Best is trial 1 with value: -841773693.6131566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=12.5784 val_loss=12.4134 scale=2.0000 norm=1.3065\n",
      "[iter 100] loss=12.1163 val_loss=12.1197 scale=2.0000 norm=0.9008\n",
      "[iter 200] loss=11.7899 val_loss=11.8910 scale=2.0000 norm=0.8952\n",
      "[iter 300] loss=11.5208 val_loss=11.6915 scale=2.0000 norm=0.8886\n",
      "[iter 400] loss=11.3010 val_loss=11.5443 scale=2.0000 norm=0.8751\n",
      "[iter 500] loss=11.1450 val_loss=11.4675 scale=2.0000 norm=0.8552\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL546 (val_loss=11.4587)\n",
      "[iter 0] loss=12.5745 val_loss=12.4117 scale=2.0000 norm=1.3161\n",
      "[iter 100] loss=12.1135 val_loss=12.1100 scale=2.0000 norm=0.9001\n",
      "[iter 200] loss=11.7938 val_loss=11.8739 scale=2.0000 norm=0.8905\n",
      "[iter 300] loss=11.5260 val_loss=11.6688 scale=2.0000 norm=0.8876\n",
      "[iter 400] loss=11.2983 val_loss=11.5137 scale=2.0000 norm=0.8691\n",
      "[iter 500] loss=11.1307 val_loss=11.4262 scale=2.0000 norm=0.8509\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL558 (val_loss=11.4108)\n",
      "[iter 0] loss=12.5917 val_loss=12.4171 scale=2.0000 norm=1.3190\n",
      "[iter 100] loss=12.1247 val_loss=12.1249 scale=2.0000 norm=0.9014\n",
      "[iter 200] loss=11.8109 val_loss=11.8887 scale=2.0000 norm=0.8855\n",
      "[iter 300] loss=11.5515 val_loss=11.6811 scale=2.0000 norm=0.8843\n",
      "[iter 400] loss=11.3046 val_loss=11.5258 scale=2.0000 norm=0.8609\n",
      "[iter 500] loss=11.1210 val_loss=11.4416 scale=2.0000 norm=0.8410\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL549 (val_loss=11.4310)\n",
      "[iter 0] loss=12.5765 val_loss=12.4100 scale=2.0000 norm=1.3349\n",
      "[iter 100] loss=12.0907 val_loss=12.0907 scale=2.0000 norm=0.9006\n",
      "[iter 200] loss=11.7922 val_loss=11.8480 scale=2.0000 norm=0.8796\n",
      "[iter 300] loss=11.5370 val_loss=11.6364 scale=2.0000 norm=0.8744\n",
      "[iter 400] loss=11.2957 val_loss=11.4751 scale=2.0000 norm=0.8475\n",
      "[iter 500] loss=11.1137 val_loss=11.3786 scale=2.0000 norm=0.8249\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL590 (val_loss=11.3550)\n",
      "[iter 0] loss=12.6013 val_loss=12.4180 scale=2.0000 norm=1.3337\n",
      "[iter 100] loss=12.1198 val_loss=12.1116 scale=2.0000 norm=0.9125\n",
      "[iter 200] loss=11.8483 val_loss=11.8736 scale=2.0000 norm=0.8894\n",
      "[iter 300] loss=11.5711 val_loss=11.6618 scale=2.0000 norm=0.8885\n",
      "[iter 400] loss=11.3223 val_loss=11.4953 scale=2.0000 norm=0.8499\n",
      "[iter 500] loss=11.1600 val_loss=11.3910 scale=2.0000 norm=0.8304\n",
      "[iter 600] loss=10.9862 val_loss=11.3577 scale=2.0000 norm=0.7952\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL600 (val_loss=11.3577)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:49:12,391]\u001b[0m Trial 5 finished with value: -852791221.6538063 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 16345, 'minibatch_frac': 0.6927252002019952, 'learning_rate': 0.0031472832802177976}. Best is trial 1 with value: -841773693.6131566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=12.5768 val_loss=12.3729 scale=1.0000 norm=0.6542\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL25 (val_loss=11.6017)\n",
      "[iter 0] loss=12.5723 val_loss=12.3739 scale=1.0000 norm=0.6555\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL25 (val_loss=11.6551)\n",
      "[iter 0] loss=12.5937 val_loss=12.4335 scale=1.0000 norm=0.6574\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL26 (val_loss=11.6347)\n",
      "[iter 0] loss=12.5822 val_loss=12.3712 scale=1.0000 norm=0.6655\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL26 (val_loss=11.5452)\n",
      "[iter 0] loss=12.5999 val_loss=12.3799 scale=1.0000 norm=0.6612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:49:15,069]\u001b[0m Trial 6 finished with value: -1014399278.4598761 and parameters: {'base_learner': 'DecTree_depth5', 'Dist': 'LogNormal', 'n_estimators': 34124, 'minibatch_frac': 0.7174860556671294, 'learning_rate': 0.05776598615807477}. Best is trial 1 with value: -841773693.6131566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL28 (val_loss=11.5494)\n",
      "[iter 0] loss=12.5660 val_loss=12.3612 scale=1.0000 norm=0.6481\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL20 (val_loss=11.6038)\n",
      "[iter 0] loss=12.5660 val_loss=12.3540 scale=1.0000 norm=0.6522\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL19 (val_loss=11.6138)\n",
      "[iter 0] loss=12.5877 val_loss=12.3840 scale=1.0000 norm=0.6557\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL20 (val_loss=11.7205)\n",
      "[iter 0] loss=12.5841 val_loss=12.3805 scale=1.0000 norm=0.6686\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL19 (val_loss=11.7248)\n",
      "[iter 0] loss=12.5858 val_loss=12.3850 scale=1.0000 norm=0.6549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:49:17,221]\u001b[0m Trial 7 finished with value: -995635562.5387728 and parameters: {'base_learner': 'DecTree_depth5', 'Dist': 'LogNormal', 'n_estimators': 30357, 'minibatch_frac': 0.6520306452412628, 'learning_rate': 0.07443859965572573}. Best is trial 1 with value: -841773693.6131566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL21 (val_loss=11.5337)\n",
      "[iter 0] loss=12.7383 val_loss=12.5604 scale=1.0000 norm=61992.1285\n",
      "[iter 100] loss=11.7581 val_loss=11.9936 scale=2.0000 norm=33983.7433\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL174 (val_loss=11.7593)\n",
      "[iter 0] loss=12.7322 val_loss=12.5565 scale=1.0000 norm=61246.7926\n",
      "[iter 100] loss=11.7533 val_loss=11.9337 scale=2.0000 norm=34702.7446\n",
      "[iter 200] loss=11.0545 val_loss=11.6326 scale=2.0000 norm=18093.8642\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL192 (val_loss=11.6246)\n",
      "[iter 0] loss=12.7288 val_loss=12.5635 scale=1.0000 norm=61313.1602\n",
      "[iter 100] loss=11.7579 val_loss=11.9539 scale=2.0000 norm=35731.2121\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL188 (val_loss=11.6735)\n",
      "[iter 0] loss=12.6785 val_loss=12.5330 scale=1.0000 norm=59716.2593\n",
      "[iter 100] loss=11.7157 val_loss=11.9168 scale=2.0000 norm=33569.4674\n",
      "[iter 200] loss=10.9931 val_loss=11.5854 scale=2.0000 norm=16484.9179\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL192 (val_loss=11.5836)\n",
      "[iter 0] loss=12.6890 val_loss=12.5579 scale=1.0000 norm=59224.8221\n",
      "[iter 100] loss=11.7678 val_loss=11.9423 scale=2.0000 norm=35809.1472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:49:27,183]\u001b[0m Trial 8 finished with value: -943536036.9203793 and parameters: {'base_learner': 'DecTree_depth5', 'Dist': 'Normal', 'n_estimators': 20638, 'minibatch_frac': 0.47782438481492934, 'learning_rate': 0.008777099102532467}. Best is trial 1 with value: -841773693.6131566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL188 (val_loss=11.6343)\n",
      "[iter 0] loss=12.7507 val_loss=12.5599 scale=2.0000 norm=123681.6000\n",
      "[iter 100] loss=11.9333 val_loss=12.0695 scale=2.0000 norm=42888.3306\n",
      "[iter 200] loss=11.4091 val_loss=11.7588 scale=2.0000 norm=23604.1355\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL235 (val_loss=11.7276)\n",
      "[iter 0] loss=12.7498 val_loss=12.5569 scale=2.0000 norm=122261.6448\n",
      "[iter 100] loss=11.9366 val_loss=12.0503 scale=2.0000 norm=44484.6595\n",
      "[iter 200] loss=11.4167 val_loss=11.6923 scale=2.0000 norm=24726.0934\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL252 (val_loss=11.6231)\n",
      "[iter 0] loss=12.7534 val_loss=12.5588 scale=2.0000 norm=122801.9737\n",
      "[iter 100] loss=11.9376 val_loss=12.0661 scale=2.0000 norm=44412.5273\n",
      "[iter 200] loss=11.4114 val_loss=11.7311 scale=2.0000 norm=24382.0396\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL243 (val_loss=11.6825)\n",
      "[iter 0] loss=12.7102 val_loss=12.5315 scale=2.0000 norm=119495.7304\n",
      "[iter 100] loss=11.8905 val_loss=12.0017 scale=2.0000 norm=42297.0162\n",
      "[iter 200] loss=11.3811 val_loss=11.6275 scale=2.0000 norm=24225.5461\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL274 (val_loss=11.5253)\n",
      "[iter 0] loss=12.7503 val_loss=12.5575 scale=2.0000 norm=123815.6030\n",
      "[iter 100] loss=11.9475 val_loss=12.0497 scale=2.0000 norm=44729.6928\n",
      "[iter 200] loss=11.4449 val_loss=11.6784 scale=2.0000 norm=26664.2860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:51:45,745]\u001b[0m Trial 9 finished with value: -898811956.2389376 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'Normal', 'n_estimators': 20164, 'minibatch_frac': 0.7013867394187225, 'learning_rate': 0.006402087918758834}. Best is trial 1 with value: -841773693.6131566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL282 (val_loss=11.5640)\n",
      "[iter 0] loss=13.1300 val_loss=13.0619 scale=1.0000 norm=0.3370\n",
      "[iter 100] loss=13.0588 val_loss=13.0050 scale=2.0000 norm=0.0316\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL115 (val_loss=13.0050)\n",
      "[iter 0] loss=13.0959 val_loss=13.0597 scale=1.0000 norm=0.3350\n",
      "[iter 100] loss=13.0411 val_loss=13.0075 scale=2.0000 norm=0.0368\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL108 (val_loss=13.0074)\n",
      "[iter 0] loss=13.1072 val_loss=13.0608 scale=2.0000 norm=0.6665\n",
      "[iter 100] loss=13.0637 val_loss=13.0083 scale=2.0000 norm=0.0336\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL108 (val_loss=13.0082)\n",
      "[iter 0] loss=13.1050 val_loss=13.0610 scale=1.0000 norm=0.3260\n",
      "[iter 100] loss=13.0407 val_loss=13.0064 scale=2.0000 norm=0.0348\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL115 (val_loss=13.0063)\n",
      "[iter 0] loss=13.1164 val_loss=13.0581 scale=2.0000 norm=0.6534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:51:50,285]\u001b[0m Trial 10 finished with value: -955726642.4597628 and parameters: {'base_learner': 'DecTree_depthNone', 'Dist': 'Exponential', 'n_estimators': 2199, 'minibatch_frac': 0.41127841025102024, 'learning_rate': 0.02392285850088981}. Best is trial 1 with value: -841773693.6131566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL81 (val_loss=13.0064)\n",
      "[iter 0] loss=12.5597 val_loss=12.4192 scale=1.0000 norm=0.6425\n",
      "[iter 100] loss=12.3735 val_loss=12.3319 scale=1.0000 norm=0.5244\n",
      "[iter 200] loss=12.1586 val_loss=12.2514 scale=1.0000 norm=0.4790\n",
      "[iter 300] loss=12.0207 val_loss=12.1592 scale=1.0000 norm=0.4590\n",
      "[iter 400] loss=11.8732 val_loss=12.0535 scale=1.0000 norm=0.4527\n",
      "[iter 500] loss=11.7555 val_loss=11.9375 scale=1.0000 norm=0.4505\n",
      "[iter 600] loss=11.5794 val_loss=11.8395 scale=2.0000 norm=0.8859\n",
      "[iter 700] loss=11.4613 val_loss=11.7566 scale=1.0000 norm=0.4378\n",
      "[iter 800] loss=11.3734 val_loss=11.7061 scale=1.0000 norm=0.4333\n",
      "[iter 900] loss=11.2680 val_loss=11.6829 scale=1.0000 norm=0.4236\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL959 (val_loss=11.6762)\n",
      "[iter 0] loss=12.5370 val_loss=12.4161 scale=1.0000 norm=0.6301\n",
      "[iter 100] loss=12.3589 val_loss=12.3055 scale=1.0000 norm=0.5208\n",
      "[iter 200] loss=12.1602 val_loss=12.2135 scale=1.0000 norm=0.4783\n",
      "[iter 300] loss=12.0427 val_loss=12.1144 scale=1.0000 norm=0.4623\n",
      "[iter 400] loss=11.8524 val_loss=11.9868 scale=2.0000 norm=0.9013\n",
      "[iter 500] loss=11.7242 val_loss=11.8515 scale=1.0000 norm=0.4458\n",
      "[iter 600] loss=11.5524 val_loss=11.7381 scale=2.0000 norm=0.8765\n",
      "[iter 700] loss=11.4245 val_loss=11.6467 scale=1.0000 norm=0.4422\n",
      "[iter 800] loss=11.3510 val_loss=11.5872 scale=2.0000 norm=0.8675\n",
      "[iter 900] loss=11.2328 val_loss=11.5518 scale=2.0000 norm=0.8495\n",
      "[iter 1000] loss=11.1971 val_loss=11.5338 scale=1.0000 norm=0.4326\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1007 (val_loss=11.5330)\n",
      "[iter 0] loss=12.5754 val_loss=12.4234 scale=1.0000 norm=0.6473\n",
      "[iter 100] loss=12.3836 val_loss=12.3337 scale=1.0000 norm=0.5293\n",
      "[iter 200] loss=12.1902 val_loss=12.2486 scale=1.0000 norm=0.4738\n",
      "[iter 300] loss=12.0658 val_loss=12.1452 scale=1.0000 norm=0.4610\n",
      "[iter 400] loss=11.8788 val_loss=12.0387 scale=1.0000 norm=0.4455\n",
      "[iter 500] loss=11.7434 val_loss=11.9153 scale=1.0000 norm=0.4441\n",
      "[iter 600] loss=11.5653 val_loss=11.8020 scale=2.0000 norm=0.8567\n",
      "[iter 700] loss=11.4245 val_loss=11.7198 scale=2.0000 norm=0.8631\n",
      "[iter 800] loss=11.3500 val_loss=11.6737 scale=2.0000 norm=0.8388\n",
      "[iter 900] loss=11.2226 val_loss=11.6528 scale=1.0000 norm=0.4032\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL949 (val_loss=11.6468)\n",
      "[iter 0] loss=12.5697 val_loss=12.4142 scale=1.0000 norm=0.6541\n",
      "[iter 100] loss=12.3437 val_loss=12.3103 scale=1.0000 norm=0.5241\n",
      "[iter 200] loss=12.1452 val_loss=12.2107 scale=1.0000 norm=0.4649\n",
      "[iter 300] loss=12.0387 val_loss=12.1059 scale=1.0000 norm=0.4567\n",
      "[iter 400] loss=11.8593 val_loss=11.9962 scale=1.0000 norm=0.4418\n",
      "[iter 500] loss=11.7130 val_loss=11.8659 scale=2.0000 norm=0.8608\n",
      "[iter 600] loss=11.5479 val_loss=11.7391 scale=1.0000 norm=0.4163\n",
      "[iter 700] loss=11.3912 val_loss=11.6371 scale=2.0000 norm=0.8338\n",
      "[iter 800] loss=11.3184 val_loss=11.5708 scale=2.0000 norm=0.8247\n",
      "[iter 900] loss=11.2013 val_loss=11.5315 scale=2.0000 norm=0.8339\n",
      "[iter 1000] loss=11.1721 val_loss=11.5066 scale=1.0000 norm=0.4207\n",
      "[iter 1100] loss=11.1063 val_loss=11.4960 scale=1.0000 norm=0.4230\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1113 (val_loss=11.4951)\n",
      "[iter 0] loss=12.5509 val_loss=12.4217 scale=1.0000 norm=0.6345\n",
      "[iter 100] loss=12.3717 val_loss=12.3066 scale=1.0000 norm=0.5313\n",
      "[iter 200] loss=12.2062 val_loss=12.2114 scale=1.0000 norm=0.4724\n",
      "[iter 300] loss=12.0699 val_loss=12.1152 scale=1.0000 norm=0.4603\n",
      "[iter 400] loss=11.8946 val_loss=12.0012 scale=1.0000 norm=0.4494\n",
      "[iter 500] loss=11.7741 val_loss=11.8671 scale=2.0000 norm=0.8916\n",
      "[iter 600] loss=11.6010 val_loss=11.7485 scale=2.0000 norm=0.8371\n",
      "[iter 700] loss=11.4584 val_loss=11.6456 scale=1.0000 norm=0.4287\n",
      "[iter 800] loss=11.3867 val_loss=11.5753 scale=1.0000 norm=0.4160\n",
      "[iter 900] loss=11.2655 val_loss=11.5281 scale=1.0000 norm=0.4215\n",
      "[iter 1000] loss=11.2212 val_loss=11.4989 scale=1.0000 norm=0.4145\n",
      "[iter 1100] loss=11.1681 val_loss=11.4840 scale=1.0000 norm=0.4188\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL1120 (val_loss=11.4816)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:52:24,331]\u001b[0m Trial 11 finished with value: -957233326.0940228 and parameters: {'base_learner': 'DecTree_depth2', 'Dist': 'LogNormal', 'n_estimators': 9382, 'minibatch_frac': 0.5912806398283483, 'learning_rate': 0.0032738656888004775}. Best is trial 1 with value: -841773693.6131566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=12.5727 val_loss=12.4124 scale=2.0000 norm=1.3095\n",
      "[iter 100] loss=12.0591 val_loss=12.0858 scale=2.0000 norm=0.8973\n",
      "[iter 200] loss=11.7221 val_loss=11.8337 scale=2.0000 norm=0.8888\n",
      "[iter 300] loss=11.4350 val_loss=11.6287 scale=2.0000 norm=0.8785\n",
      "[iter 400] loss=11.1940 val_loss=11.5083 scale=2.0000 norm=0.8609\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL458 (val_loss=11.4878)\n",
      "[iter 0] loss=12.5714 val_loss=12.4109 scale=2.0000 norm=1.3070\n",
      "[iter 100] loss=12.0543 val_loss=12.0754 scale=2.0000 norm=0.8978\n",
      "[iter 200] loss=11.7261 val_loss=11.8179 scale=2.0000 norm=0.8862\n",
      "[iter 300] loss=11.4395 val_loss=11.6046 scale=2.0000 norm=0.8756\n",
      "[iter 400] loss=11.1956 val_loss=11.4703 scale=2.0000 norm=0.8549\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL487 (val_loss=11.4342)\n",
      "[iter 0] loss=12.5990 val_loss=12.4154 scale=2.0000 norm=1.3206\n",
      "[iter 100] loss=12.0656 val_loss=12.0923 scale=2.0000 norm=0.8982\n",
      "[iter 200] loss=11.7336 val_loss=11.8321 scale=2.0000 norm=0.8853\n",
      "[iter 300] loss=11.4471 val_loss=11.6178 scale=2.0000 norm=0.8739\n",
      "[iter 400] loss=11.1959 val_loss=11.4873 scale=2.0000 norm=0.8457\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL472 (val_loss=11.4596)\n",
      "[iter 0] loss=12.5844 val_loss=12.4093 scale=2.0000 norm=1.3313\n",
      "[iter 100] loss=12.0409 val_loss=12.0537 scale=2.0000 norm=0.8925\n",
      "[iter 200] loss=11.7099 val_loss=11.7855 scale=2.0000 norm=0.8784\n",
      "[iter 300] loss=11.4381 val_loss=11.5656 scale=2.0000 norm=0.8665\n",
      "[iter 400] loss=11.1829 val_loss=11.4203 scale=2.0000 norm=0.8367\n",
      "[iter 500] loss=11.0164 val_loss=11.3726 scale=2.0000 norm=0.8115\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL498 (val_loss=11.3725)\n",
      "[iter 0] loss=12.5960 val_loss=12.4172 scale=2.0000 norm=1.3176\n",
      "[iter 100] loss=12.0747 val_loss=12.0769 scale=2.0000 norm=0.9063\n",
      "[iter 200] loss=11.7569 val_loss=11.8126 scale=2.0000 norm=0.8890\n",
      "[iter 300] loss=11.4781 val_loss=11.5882 scale=2.0000 norm=0.8791\n",
      "[iter 400] loss=11.2011 val_loss=11.4351 scale=2.0000 norm=0.8345\n",
      "[iter 500] loss=11.0511 val_loss=11.3752 scale=2.0000 norm=0.8082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:56:00,568]\u001b[0m Trial 12 finished with value: -865269061.8109213 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 14000, 'minibatch_frac': 0.8036426924778791, 'learning_rate': 0.0035865491785189974}. Best is trial 1 with value: -841773693.6131566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL522 (val_loss=11.3731)\n",
      "[iter 0] loss=12.5551 val_loss=12.3832 scale=2.0000 norm=1.2862\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL74 (val_loss=11.4421)\n",
      "[iter 0] loss=12.5423 val_loss=12.3869 scale=2.0000 norm=1.2696\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL74 (val_loss=11.4008)\n",
      "[iter 0] loss=12.5822 val_loss=12.3883 scale=2.0000 norm=1.3055\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL76 (val_loss=11.4197)\n",
      "[iter 0] loss=12.5575 val_loss=12.3790 scale=2.0000 norm=1.2866\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL80 (val_loss=11.3316)\n",
      "[iter 0] loss=12.5482 val_loss=12.3906 scale=2.0000 norm=1.2514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:56:25,882]\u001b[0m Trial 13 finished with value: -862744342.8312544 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 41882, 'minibatch_frac': 0.5693107410185092, 'learning_rate': 0.023449174740242787}. Best is trial 1 with value: -841773693.6131566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL80 (val_loss=11.3411)\n",
      "[iter 0] loss=12.5638 val_loss=12.3855 scale=2.0000 norm=1.3038\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL81 (val_loss=11.4640)\n",
      "[iter 0] loss=12.5393 val_loss=12.3853 scale=2.0000 norm=1.2780\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL87 (val_loss=11.3779)\n",
      "[iter 0] loss=12.5682 val_loss=12.3928 scale=2.0000 norm=1.3120\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL82 (val_loss=11.4112)\n",
      "[iter 0] loss=12.5398 val_loss=12.3831 scale=2.0000 norm=1.2805\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL90 (val_loss=11.3593)\n",
      "[iter 0] loss=12.5480 val_loss=12.3891 scale=2.0000 norm=1.2646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:56:50,271]\u001b[0m Trial 14 finished with value: -838944770.0473243 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 24667, 'minibatch_frac': 0.4841608783288508, 'learning_rate': 0.0212282965443222}. Best is trial 14 with value: -838944770.0473243.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL87 (val_loss=11.3607)\n",
      "[iter 0] loss=13.1276 val_loss=13.0620 scale=1.0000 norm=0.3347\n",
      "[iter 100] loss=13.0514 val_loss=13.0060 scale=2.0000 norm=0.0351\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL128 (val_loss=13.0057)\n",
      "[iter 0] loss=13.0941 val_loss=13.0598 scale=1.0000 norm=0.3327\n",
      "[iter 100] loss=13.0370 val_loss=13.0068 scale=2.0000 norm=0.0395\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL96 (val_loss=13.0067)\n",
      "[iter 0] loss=13.1068 val_loss=13.0609 scale=2.0000 norm=0.6608\n",
      "[iter 100] loss=13.0593 val_loss=13.0077 scale=2.0000 norm=0.0370\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL104 (val_loss=13.0076)\n",
      "[iter 0] loss=13.1030 val_loss=13.0606 scale=2.0000 norm=0.6499\n",
      "[iter 100] loss=13.0376 val_loss=13.0069 scale=2.0000 norm=0.0379\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL104 (val_loss=13.0068)\n",
      "[iter 0] loss=13.1165 val_loss=13.0585 scale=2.0000 norm=0.6555\n",
      "[iter 100] loss=13.0441 val_loss=13.0081 scale=2.0000 norm=0.0386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:56:55,122]\u001b[0m Trial 15 finished with value: -908728780.6353728 and parameters: {'base_learner': 'DecTree_depthNone', 'Dist': 'Exponential', 'n_estimators': 24479, 'minibatch_frac': 0.41734369906144025, 'learning_rate': 0.02262216186594188}. Best is trial 14 with value: -838944770.0473243.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL126 (val_loss=13.0078)\n",
      "[iter 0] loss=12.5734 val_loss=12.3691 scale=2.0000 norm=1.3158\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL44 (val_loss=11.4791)\n",
      "[iter 0] loss=12.5276 val_loss=12.3618 scale=2.0000 norm=1.2463\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL50 (val_loss=11.3704)\n",
      "[iter 0] loss=12.5604 val_loss=12.3713 scale=2.0000 norm=1.2819\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL45 (val_loss=11.4240)\n",
      "[iter 0] loss=12.5310 val_loss=12.3602 scale=2.0000 norm=1.2479\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL50 (val_loss=11.3488)\n",
      "[iter 0] loss=12.5337 val_loss=12.3716 scale=2.0000 norm=1.2291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:57:09,527]\u001b[0m Trial 16 finished with value: -862580789.7945347 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 26898, 'minibatch_frac': 0.47012721743628566, 'learning_rate': 0.03722742594440133}. Best is trial 14 with value: -838944770.0473243.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL50 (val_loss=11.3556)\n",
      "[iter 0] loss=12.5709 val_loss=12.4194 scale=1.0000 norm=0.6445\n",
      "[iter 100] loss=11.7169 val_loss=11.8971 scale=1.0000 norm=0.4324\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL182 (val_loss=11.6511)\n",
      "[iter 0] loss=12.5325 val_loss=12.4051 scale=1.0000 norm=0.6226\n",
      "[iter 100] loss=11.7160 val_loss=11.8426 scale=2.0000 norm=0.8662\n",
      "[iter 200] loss=11.1721 val_loss=11.5553 scale=1.0000 norm=0.4255\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL201 (val_loss=11.5548)\n",
      "[iter 0] loss=12.5703 val_loss=12.4258 scale=1.0000 norm=0.6416\n",
      "[iter 100] loss=11.7650 val_loss=11.9029 scale=1.0000 norm=0.4327\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL169 (val_loss=11.6739)\n",
      "[iter 0] loss=12.5422 val_loss=12.4090 scale=1.0000 norm=0.6210\n",
      "[iter 100] loss=11.7027 val_loss=11.8282 scale=1.0000 norm=0.4282\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL189 (val_loss=11.5641)\n",
      "[iter 0] loss=12.5632 val_loss=12.4136 scale=1.0000 norm=0.6203\n",
      "[iter 100] loss=11.7362 val_loss=11.8524 scale=1.0000 norm=0.4477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:57:15,415]\u001b[0m Trial 17 finished with value: -956382167.5523866 and parameters: {'base_learner': 'DecTree_depth2', 'Dist': 'LogNormal', 'n_estimators': 37520, 'minibatch_frac': 0.4001954173753072, 'learning_rate': 0.01617171566083057}. Best is trial 14 with value: -838944770.0473243.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL189 (val_loss=11.6106)\n",
      "[iter 0] loss=12.5627 val_loss=12.3956 scale=2.0000 norm=1.2930\n",
      "[iter 100] loss=11.2520 val_loss=11.4848 scale=2.0000 norm=0.8410\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL128 (val_loss=11.4355)\n",
      "[iter 0] loss=12.5499 val_loss=12.3966 scale=2.0000 norm=1.2764\n",
      "[iter 100] loss=11.2425 val_loss=11.4453 scale=2.0000 norm=0.8439\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL130 (val_loss=11.3822)\n",
      "[iter 0] loss=12.5900 val_loss=12.3986 scale=2.0000 norm=1.3120\n",
      "[iter 100] loss=11.2411 val_loss=11.4522 scale=2.0000 norm=0.8402\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL130 (val_loss=11.3966)\n",
      "[iter 0] loss=12.5644 val_loss=12.3913 scale=2.0000 norm=1.2935\n",
      "[iter 100] loss=11.2321 val_loss=11.4226 scale=2.0000 norm=0.8421\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL130 (val_loss=11.3477)\n",
      "[iter 0] loss=12.5527 val_loss=12.4015 scale=2.0000 norm=1.2521\n",
      "[iter 100] loss=11.2693 val_loss=11.4266 scale=2.0000 norm=0.8612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:57:58,536]\u001b[0m Trial 18 finished with value: -845962770.3142052 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 48119, 'minibatch_frac': 0.5582798872292, 'learning_rate': 0.0139163392804938}. Best is trial 14 with value: -838944770.0473243.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL134 (val_loss=11.3348)\n",
      "[iter 0] loss=12.5667 val_loss=12.4095 scale=2.0000 norm=1.3061\n",
      "[iter 100] loss=11.9073 val_loss=11.9501 scale=2.0000 norm=0.8865\n",
      "[iter 200] loss=11.4526 val_loss=11.6115 scale=2.0000 norm=0.8699\n",
      "[iter 300] loss=11.1248 val_loss=11.4394 scale=2.0000 norm=0.8644\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL333 (val_loss=11.4260)\n",
      "[iter 0] loss=12.5419 val_loss=12.4086 scale=2.0000 norm=1.2801\n",
      "[iter 100] loss=11.9041 val_loss=11.9391 scale=2.0000 norm=0.8879\n",
      "[iter 200] loss=11.4622 val_loss=11.5877 scale=2.0000 norm=0.8737\n",
      "[iter 300] loss=11.1411 val_loss=11.3933 scale=2.0000 norm=0.8544\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL352 (val_loss=11.3697)\n",
      "[iter 0] loss=12.5710 val_loss=12.4129 scale=2.0000 norm=1.3144\n",
      "[iter 100] loss=11.9318 val_loss=11.9544 scale=2.0000 norm=0.8914\n",
      "[iter 200] loss=11.4634 val_loss=11.5987 scale=2.0000 norm=0.8654\n",
      "[iter 300] loss=11.1431 val_loss=11.4049 scale=2.0000 norm=0.8369\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL346 (val_loss=11.3849)\n",
      "[iter 0] loss=12.5424 val_loss=12.4071 scale=2.0000 norm=1.2825\n",
      "[iter 100] loss=11.8945 val_loss=11.9232 scale=2.0000 norm=0.8918\n",
      "[iter 200] loss=11.4220 val_loss=11.5674 scale=2.0000 norm=0.8647\n",
      "[iter 300] loss=11.1328 val_loss=11.3688 scale=2.0000 norm=0.8279\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL352 (val_loss=11.3386)\n",
      "[iter 0] loss=12.5439 val_loss=12.4153 scale=2.0000 norm=1.2616\n",
      "[iter 100] loss=11.9258 val_loss=11.9455 scale=2.0000 norm=0.9068\n",
      "[iter 200] loss=11.4812 val_loss=11.5880 scale=2.0000 norm=0.8626\n",
      "[iter 300] loss=11.1641 val_loss=11.3736 scale=2.0000 norm=0.8315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-11 15:59:33,900]\u001b[0m Trial 19 finished with value: -861329091.4097408 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 41930, 'minibatch_frac': 0.4809968955761645, 'learning_rate': 0.005350001440076019}. Best is trial 14 with value: -838944770.0473243.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL359 (val_loss=11.3373)\n",
      "[iter 0] loss=12.5725 val_loss=12.3900 scale=2.0000 norm=1.2576\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL87 (val_loss=11.3711)\n",
      "Started Predict with Ngboost at 15:59:40.\n",
      "The R2 score is 0.880364570773793\n",
      "The MAE score is 15853.002350163648\n",
      "The Median absolute error score is 9910.137334882864\n",
      "The MSE score is 22352.23426138616\n",
      "The RMSE score is 499622376.4758852\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this case we chose Ngboost, which is uses natural gradient. It is really strong for regression problem, but\n",
    "does not have GPU acceleration at all unfortunately. However we always recommend trying Ngboost if possible.\n",
    "\"\"\"\n",
    "housing_ml.ml_bp14_regressions_full_processing_ngboost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pipeline\n",
    "save_to_production(housing_ml, file_name='housing_automl_instance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on new data\n",
    "In the beginning we kept a holdout dataset. We use this to simulate prediction on completely new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stored pipeline\n",
    "housing_ml_loaded = load_for_production(file_name='housing_automl_instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Execute test train split at 15:59:41.\n",
      "Started Apply datetime transformation at 15:59:41.\n",
      "Started Start Spacy, POS tagging at 15:59:41.\n",
      "Started Handle rare features at 15:59:41.\n",
      "Started Remove cardinality at 15:59:41.\n",
      "Started Onehot + PCA categorical features at 15:59:41.\n",
      "Started Execute categorical encoding at 15:59:41.\n",
      "Started  Delete columns with high share of NULLs at 15:59:41.\n",
      "Started Fill nulls at 15:59:41.\n",
      "Started Execute numerical binning at 15:59:41.\n",
      "Started Handle outliers at 15:59:41.\n",
      "Started Remove collinearity at 15:59:41.\n",
      "Started Execute clustering as a feature at 15:59:41.\n",
      "Started Execute clustering as a feature at 15:59:41.\n",
      "Started Execute clustering as a feature at 15:59:41.\n",
      "Started Execute clustering as a feature at 15:59:42.\n",
      "Started Execute clustering as a feature at 15:59:42.\n",
      "Started Execute clustering as a feature at 15:59:42.\n",
      "Started Execute clustering as a feature at 15:59:42.\n",
      "Started Execute clustering as a feature at 15:59:42.\n",
      "Started Execute clustering as a feature at 15:59:42.\n",
      "Started Select best features at 15:59:42.\n",
      "Started Sort columns alphabetically at 15:59:42.\n",
      "Started Predict with Ngboost at 15:59:42.\n"
     ]
    }
   ],
   "source": [
    "# predict on new data\n",
    "housing_ml_loaded.ml_bp14_regressions_full_processing_ngboost(val_df)\n",
    "\n",
    "# access predicted labels\n",
    "val_y_hat = housing_ml_loaded.predicted_values['ngboost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15893.900047278938\n"
     ]
    }
   ],
   "source": [
    "# Assess prediction quality on holdout data\n",
    "mae = mean_absolute_error(val_df_target, val_y_hat)\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

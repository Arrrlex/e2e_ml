{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Housing prices regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/thomas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/thomas/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/thomas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/thomas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "from e2eml.regression import regression_blueprints as rb\n",
    "from e2eml.full_processing.postprocessing import save_to_production, load_for_production\n",
    "from e2eml.test.regression_blueprints_test import load_housingprices_data\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "Load & preprocess housing prices dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do dataframe splits.\n"
     ]
    }
   ],
   "source": [
    "# load Housing price data\n",
    "test_df, test_target, val_df, val_df_target, test_categorical_cols = load_housingprices_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using e2eml - Run and save a pipeline\n",
    "We only need a few steps to get ur full pipeline:\n",
    "- Instantiate class\n",
    "- Run chosen blueprint\n",
    "- Save blueprint for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ml task is regression\n",
      "Preferred training mode auto has been chosen. e2eml will automatically detect, if LGBM and Xgboost can use GPU acceleration and optimize the workflow accordingly.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate class\n",
    "housing_ml = rb.RegressionBluePrint(datasource=test_df,\n",
    "                                         target_variable=test_target,\n",
    "                                         categorical_columns=test_categorical_cols, # here we specify cat columns (that is optional however)\n",
    "                                         preferred_training_mode='auto',\n",
    "                                         tune_mode='accurate',\n",
    "                                         ml_task='regression') # usually not needed, but sometimes it might have to be called explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Execute test train split at 19:38:12.\n",
      "Started Apply datetime transformation at 19:38:13.\n",
      "Started Start Spacy, POS tagging at 19:38:13.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 800 entries, 29 to 102\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             800 non-null    int64  \n",
      " 1   MSSubClass     800 non-null    int64  \n",
      " 2   MSZoning       800 non-null    object \n",
      " 3   LotFrontage    663 non-null    float64\n",
      " 4   LotArea        800 non-null    int64  \n",
      " 5   Street         800 non-null    object \n",
      " 6   Alley          50 non-null     object \n",
      " 7   LotShape       800 non-null    object \n",
      " 8   LandContour    800 non-null    object \n",
      " 9   Utilities      800 non-null    object \n",
      " 10  LotConfig      800 non-null    object \n",
      " 11  LandSlope      800 non-null    object \n",
      " 12  Neighborhood   800 non-null    object \n",
      " 13  Condition1     800 non-null    object \n",
      " 14  Condition2     800 non-null    object \n",
      " 15  BldgType       800 non-null    object \n",
      " 16  HouseStyle     800 non-null    object \n",
      " 17  OverallQual    800 non-null    int64  \n",
      " 18  OverallCond    800 non-null    int64  \n",
      " 19  YearBuilt      800 non-null    int64  \n",
      " 20  YearRemodAdd   800 non-null    int64  \n",
      " 21  RoofStyle      800 non-null    object \n",
      " 22  RoofMatl       800 non-null    object \n",
      " 23  Exterior1st    800 non-null    object \n",
      " 24  Exterior2nd    800 non-null    object \n",
      " 25  MasVnrType     799 non-null    object \n",
      " 26  MasVnrArea     799 non-null    float64\n",
      " 27  ExterQual      800 non-null    object \n",
      " 28  ExterCond      800 non-null    object \n",
      " 29  Foundation     800 non-null    object \n",
      " 30  BsmtQual       780 non-null    object \n",
      " 31  BsmtCond       780 non-null    object \n",
      " 32  BsmtExposure   780 non-null    object \n",
      " 33  BsmtFinType1   780 non-null    object \n",
      " 34  BsmtFinSF1     800 non-null    int64  \n",
      " 35  BsmtFinType2   780 non-null    object \n",
      " 36  BsmtFinSF2     800 non-null    int64  \n",
      " 37  BsmtUnfSF      800 non-null    int64  \n",
      " 38  TotalBsmtSF    800 non-null    int64  \n",
      " 39  Heating        800 non-null    object \n",
      " 40  HeatingQC      800 non-null    object \n",
      " 41  CentralAir     800 non-null    object \n",
      " 42  Electrical     800 non-null    object \n",
      " 43  1stFlrSF       800 non-null    int64  \n",
      " 44  2ndFlrSF       800 non-null    int64  \n",
      " 45  LowQualFinSF   800 non-null    int64  \n",
      " 46  GrLivArea      800 non-null    int64  \n",
      " 47  BsmtFullBath   800 non-null    int64  \n",
      " 48  BsmtHalfBath   800 non-null    int64  \n",
      " 49  FullBath       800 non-null    int64  \n",
      " 50  HalfBath       800 non-null    int64  \n",
      " 51  BedroomAbvGr   800 non-null    int64  \n",
      " 52  KitchenAbvGr   800 non-null    int64  \n",
      " 53  KitchenQual    800 non-null    object \n",
      " 54  TotRmsAbvGrd   800 non-null    int64  \n",
      " 55  Functional     800 non-null    object \n",
      " 56  Fireplaces     800 non-null    int64  \n",
      " 57  FireplaceQu    428 non-null    object \n",
      " 58  GarageType     757 non-null    object \n",
      " 59  GarageYrBlt    757 non-null    float64\n",
      " 60  GarageFinish   757 non-null    object \n",
      " 61  GarageCars     800 non-null    int64  \n",
      " 62  GarageArea     800 non-null    int64  \n",
      " 63  GarageQual     757 non-null    object \n",
      " 64  GarageCond     757 non-null    object \n",
      " 65  PavedDrive     800 non-null    object \n",
      " 66  WoodDeckSF     800 non-null    int64  \n",
      " 67  OpenPorchSF    800 non-null    int64  \n",
      " 68  EnclosedPorch  800 non-null    int64  \n",
      " 69  3SsnPorch      800 non-null    int64  \n",
      " 70  ScreenPorch    800 non-null    int64  \n",
      " 71  PoolArea       800 non-null    int64  \n",
      " 72  PoolQC         1 non-null      object \n",
      " 73  Fence          154 non-null    object \n",
      " 74  MiscFeature    35 non-null     object \n",
      " 75  MiscVal        800 non-null    int64  \n",
      " 76  MoSold         800 non-null    int64  \n",
      " 77  YrSold         800 non-null    int64  \n",
      " 78  SaleType       800 non-null    object \n",
      " 79  SaleCondition  800 non-null    object \n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 506.2+ KB\n",
      "None\n",
      "Started Handle rare features at 19:38:13.\n",
      "Started Remove cardinality at 19:38:13.\n",
      "Started Onehot + PCA categorical features at 19:38:13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Execute categorical encoding at 19:38:13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started  Delete columns with high share of NULLs at 19:38:14.\n",
      "Started Fill nulls at 19:38:14.\n",
      "Started Execute numerical binning at 19:38:14.\n",
      "Started Handle outliers at 19:38:14.\n",
      "Started Remove collinearity at 19:38:14.\n",
      "Started Execute clustering as a feature at 19:38:15.\n",
      "Started Scale data at 19:38:15.\n",
      "Started Execute clustering as a feature at 19:38:15.\n",
      "Started Execute clustering as a feature at 19:38:15.\n",
      "Started Execute clustering as a feature at 19:38:16.\n",
      "Started Execute clustering as a feature at 19:38:16.\n",
      "Started Execute clustering as a feature at 19:38:16.\n",
      "Started Execute clustering as a feature at 19:38:17.\n",
      "Started Execute clustering as a feature at 19:38:17.\n",
      "Started Execute clustering as a feature at 19:38:17.\n",
      "Started Select best features at 19:38:18.\n",
      "Features before selection are...Id\n",
      "Features before selection are...MSSubClass\n",
      "Features before selection are...MSZoning\n",
      "Features before selection are...LotFrontage\n",
      "Features before selection are...LotArea\n",
      "Features before selection are...Street\n",
      "Features before selection are...Alley\n",
      "Features before selection are...LotShape\n",
      "Features before selection are...LandContour\n",
      "Features before selection are...Utilities\n",
      "Features before selection are...LotConfig\n",
      "Features before selection are...LandSlope\n",
      "Features before selection are...Neighborhood\n",
      "Features before selection are...Condition1\n",
      "Features before selection are...Condition2\n",
      "Features before selection are...BldgType\n",
      "Features before selection are...HouseStyle\n",
      "Features before selection are...OverallQual\n",
      "Features before selection are...OverallCond\n",
      "Features before selection are...YearBuilt\n",
      "Features before selection are...YearRemodAdd\n",
      "Features before selection are...RoofStyle\n",
      "Features before selection are...RoofMatl\n",
      "Features before selection are...Exterior1st\n",
      "Features before selection are...MasVnrType\n",
      "Features before selection are...MasVnrArea\n",
      "Features before selection are...ExterQual\n",
      "Features before selection are...ExterCond\n",
      "Features before selection are...Foundation\n",
      "Features before selection are...BsmtQual\n",
      "Features before selection are...BsmtCond\n",
      "Features before selection are...BsmtExposure\n",
      "Features before selection are...BsmtFinType1\n",
      "Features before selection are...BsmtFinSF1\n",
      "Features before selection are...BsmtFinType2\n",
      "Features before selection are...BsmtFinSF2\n",
      "Features before selection are...BsmtUnfSF\n",
      "Features before selection are...TotalBsmtSF\n",
      "Features before selection are...Heating\n",
      "Features before selection are...HeatingQC\n",
      "Features before selection are...CentralAir\n",
      "Features before selection are...Electrical\n",
      "Features before selection are...2ndFlrSF\n",
      "Features before selection are...LowQualFinSF\n",
      "Features before selection are...GrLivArea\n",
      "Features before selection are...BsmtFullBath\n",
      "Features before selection are...BsmtHalfBath\n",
      "Features before selection are...FullBath\n",
      "Features before selection are...HalfBath\n",
      "Features before selection are...BedroomAbvGr\n",
      "Features before selection are...KitchenAbvGr\n",
      "Features before selection are...KitchenQual\n",
      "Features before selection are...Functional\n",
      "Features before selection are...Fireplaces\n",
      "Features before selection are...FireplaceQu\n",
      "Features before selection are...GarageType\n",
      "Features before selection are...GarageYrBlt\n",
      "Features before selection are...GarageFinish\n",
      "Features before selection are...GarageCars\n",
      "Features before selection are...PavedDrive\n",
      "Features before selection are...WoodDeckSF\n",
      "Features before selection are...OpenPorchSF\n",
      "Features before selection are...EnclosedPorch\n",
      "Features before selection are...3SsnPorch\n",
      "Features before selection are...ScreenPorch\n",
      "Features before selection are...PoolArea\n",
      "Features before selection are...Fence\n",
      "Features before selection are...MiscFeature\n",
      "Features before selection are...MiscVal\n",
      "Features before selection are...MoSold\n",
      "Features before selection are...YrSold\n",
      "Features before selection are...SaleType\n",
      "Features before selection are...PC-1_pca\n",
      "Features before selection are...PC-2_pca\n",
      "Features before selection are...isolation_probs\n",
      "Features before selection are...isolation_class\n",
      "Features before selection are...dbscan_cluster\n",
      "Features before selection are...kmeans_clusters2\n",
      "Features before selection are...kmeans_clusters3\n",
      "Features before selection are...kmeans_clusters4\n",
      "Features before selection are...kmeans_clusters5\n",
      "Features before selection are...kmeans_clusters6\n",
      "Features before selection are...kmeans_clusters7\n",
      "Features before selection are...kmeans_clusters8\n",
      "Features before selection are...kmeans_clusters9\n",
      "[19:38:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  1\n",
      "[19:38:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  2\n",
      "[19:38:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  3\n",
      "[19:38:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  4\n",
      "[19:38:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  5\n",
      "[19:38:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  6\n",
      "[19:38:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  7\n",
      "[19:38:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  8\n",
      "[19:38:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  9\n",
      "[19:38:18] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1623267594558/work/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Round:  1  iteration:  10\n",
      "BoostARoota ran successfully! Algorithm went through  1  rounds.\n",
      " Selected features are... Id.\n",
      " Selected features are... MSSubClass.\n",
      " Selected features are... MSZoning.\n",
      " Selected features are... LotFrontage.\n",
      " Selected features are... LotArea.\n",
      " Selected features are... Street.\n",
      " Selected features are... Alley.\n",
      " Selected features are... LotShape.\n",
      " Selected features are... LandContour.\n",
      " Selected features are... LotConfig.\n",
      " Selected features are... LandSlope.\n",
      " Selected features are... Neighborhood.\n",
      " Selected features are... Condition1.\n",
      " Selected features are... BldgType.\n",
      " Selected features are... HouseStyle.\n",
      " Selected features are... OverallQual.\n",
      " Selected features are... OverallCond.\n",
      " Selected features are... YearBuilt.\n",
      " Selected features are... YearRemodAdd.\n",
      " Selected features are... RoofStyle.\n",
      " Selected features are... RoofMatl.\n",
      " Selected features are... Exterior1st.\n",
      " Selected features are... MasVnrType.\n",
      " Selected features are... MasVnrArea.\n",
      " Selected features are... ExterQual.\n",
      " Selected features are... ExterCond.\n",
      " Selected features are... Foundation.\n",
      " Selected features are... BsmtQual.\n",
      " Selected features are... BsmtCond.\n",
      " Selected features are... BsmtExposure.\n",
      " Selected features are... BsmtFinType1.\n",
      " Selected features are... BsmtFinSF1.\n",
      " Selected features are... BsmtFinType2.\n",
      " Selected features are... BsmtFinSF2.\n",
      " Selected features are... BsmtUnfSF.\n",
      " Selected features are... TotalBsmtSF.\n",
      " Selected features are... Heating.\n",
      " Selected features are... HeatingQC.\n",
      " Selected features are... CentralAir.\n",
      " Selected features are... Electrical.\n",
      " Selected features are... 2ndFlrSF.\n",
      " Selected features are... GrLivArea.\n",
      " Selected features are... BsmtFullBath.\n",
      " Selected features are... BsmtHalfBath.\n",
      " Selected features are... FullBath.\n",
      " Selected features are... HalfBath.\n",
      " Selected features are... BedroomAbvGr.\n",
      " Selected features are... KitchenQual.\n",
      " Selected features are... Functional.\n",
      " Selected features are... Fireplaces.\n",
      " Selected features are... FireplaceQu.\n",
      " Selected features are... GarageYrBlt.\n",
      " Selected features are... GarageFinish.\n",
      " Selected features are... GarageCars.\n",
      " Selected features are... PavedDrive.\n",
      " Selected features are... WoodDeckSF.\n",
      " Selected features are... OpenPorchSF.\n",
      " Selected features are... EnclosedPorch.\n",
      " Selected features are... 3SsnPorch.\n",
      " Selected features are... ScreenPorch.\n",
      " Selected features are... Fence.\n",
      " Selected features are... MiscFeature.\n",
      " Selected features are... MiscVal.\n",
      " Selected features are... MoSold.\n",
      " Selected features are... YrSold.\n",
      " Selected features are... SaleType.\n",
      " Selected features are... PC-1_pca.\n",
      " Selected features are... PC-2_pca.\n",
      " Selected features are... isolation_probs.\n",
      " Selected features are... kmeans_clusters2.\n",
      " Selected features are... kmeans_clusters3.\n",
      " Selected features are... kmeans_clusters4.\n",
      " Selected features are... kmeans_clusters5.\n",
      " Selected features are... kmeans_clusters6.\n",
      " Selected features are... kmeans_clusters7.\n",
      " Selected features are... kmeans_clusters8.\n",
      " Selected features are... kmeans_clusters9.\n",
      "Started Sort columns alphabetically at 19:38:18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:38:18,552]\u001b[0m A new study created in memory with name: no-name-54c51c2f-c5f3-441f-b75e-70bcc1384875\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Train Ngboost at 19:38:18.\n",
      "[iter 0] loss=12.5783 val_loss=12.4042 scale=2.0000 norm=1.3278\n",
      "[iter 100] loss=11.6037 val_loss=11.7697 scale=2.0000 norm=0.9175\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL178 (val_loss=11.5364)\n",
      "[iter 0] loss=12.5283 val_loss=12.4056 scale=2.0000 norm=1.2518\n",
      "[iter 100] loss=11.5907 val_loss=11.8594 scale=2.0000 norm=0.9193\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL154 (val_loss=11.7491)\n",
      "[iter 0] loss=12.5605 val_loss=12.4089 scale=2.0000 norm=1.2811\n",
      "[iter 100] loss=11.6290 val_loss=11.8220 scale=2.0000 norm=0.9204\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL162 (val_loss=11.6541)\n",
      "[iter 0] loss=12.5306 val_loss=12.4027 scale=2.0000 norm=1.2464\n",
      "[iter 100] loss=11.5859 val_loss=11.7849 scale=2.0000 norm=0.9215\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL173 (val_loss=11.5796)\n",
      "[iter 0] loss=12.5308 val_loss=12.4141 scale=2.0000 norm=1.2127\n",
      "[iter 100] loss=11.6111 val_loss=11.8337 scale=2.0000 norm=0.9234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:38:30,072]\u001b[0m Trial 0 finished with value: -982517592.4782884 and parameters: {'base_learner': 'DecTree_depthNone', 'Dist': 'LogNormal', 'n_estimators': 39639, 'minibatch_frac': 0.45705911818108086, 'learning_rate': 0.007977509434108937}. Best is trial 0 with value: -982517592.4782884.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL163 (val_loss=11.6565)\n",
      "[iter 0] loss=12.5683 val_loss=12.3998 scale=2.0000 norm=1.2922\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL89 (val_loss=11.6469)\n",
      "[iter 0] loss=12.5641 val_loss=12.4035 scale=2.0000 norm=1.3017\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL80 (val_loss=11.8189)\n",
      "[iter 0] loss=12.5824 val_loss=12.4008 scale=2.0000 norm=1.3075\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL73 (val_loss=11.8582)\n",
      "[iter 0] loss=12.5793 val_loss=12.3985 scale=2.0000 norm=1.3418\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL78 (val_loss=11.8181)\n",
      "[iter 0] loss=12.5896 val_loss=12.4139 scale=2.0000 norm=1.3233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:38:37,701]\u001b[0m Trial 1 finished with value: -1080547522.3364635 and parameters: {'base_learner': 'DecTree_depthNone', 'Dist': 'LogNormal', 'n_estimators': 37769, 'minibatch_frac': 0.6817067336254456, 'learning_rate': 0.013319665098625685}. Best is trial 0 with value: -982517592.4782884.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL82 (val_loss=11.8213)\n",
      "[iter 0] loss=13.1231 val_loss=13.0630 scale=1.0000 norm=0.3314\n",
      "[iter 100] loss=13.1467 val_loss=13.0548 scale=1.0000 norm=0.3006\n",
      "[iter 200] loss=13.0841 val_loss=13.0469 scale=2.0000 norm=0.5054\n",
      "[iter 300] loss=13.0806 val_loss=13.0402 scale=2.0000 norm=0.4414\n",
      "[iter 400] loss=13.0596 val_loss=13.0347 scale=2.0000 norm=0.3937\n",
      "[iter 500] loss=13.0884 val_loss=13.0299 scale=2.0000 norm=0.3420\n",
      "[iter 600] loss=13.0711 val_loss=13.0256 scale=2.0000 norm=0.2988\n",
      "[iter 700] loss=13.0582 val_loss=13.0223 scale=2.0000 norm=0.2856\n",
      "[iter 800] loss=13.0671 val_loss=13.0195 scale=2.0000 norm=0.2581\n",
      "[iter 900] loss=13.0744 val_loss=13.0172 scale=2.0000 norm=0.2351\n",
      "[iter 1000] loss=13.0610 val_loss=13.0152 scale=2.0000 norm=0.2141\n",
      "[iter 1100] loss=13.0423 val_loss=13.0136 scale=2.0000 norm=0.2021\n",
      "[iter 1200] loss=13.0432 val_loss=13.0122 scale=2.0000 norm=0.1894\n",
      "[iter 1300] loss=13.0647 val_loss=13.0110 scale=2.0000 norm=0.1934\n",
      "[iter 1400] loss=13.0486 val_loss=13.0101 scale=2.0000 norm=0.1736\n",
      "[iter 1500] loss=13.0670 val_loss=13.0093 scale=1.0000 norm=0.0807\n",
      "[iter 1600] loss=13.0738 val_loss=13.0086 scale=2.0000 norm=0.1684\n",
      "[iter 1700] loss=13.0645 val_loss=13.0081 scale=1.0000 norm=0.0850\n",
      "[iter 1800] loss=13.0505 val_loss=13.0077 scale=2.0000 norm=0.1637\n",
      "[iter 1900] loss=13.0574 val_loss=13.0073 scale=2.0000 norm=0.1562\n",
      "[iter 2000] loss=13.0377 val_loss=13.0070 scale=2.0000 norm=0.1570\n",
      "[iter 2100] loss=13.0821 val_loss=13.0067 scale=2.0000 norm=0.1479\n",
      "[iter 2200] loss=13.0405 val_loss=13.0065 scale=2.0000 norm=0.1489\n",
      "[iter 2300] loss=13.0524 val_loss=13.0064 scale=2.0000 norm=0.1473\n",
      "[iter 2400] loss=13.0385 val_loss=13.0062 scale=2.0000 norm=0.1458\n",
      "[iter 2500] loss=13.0275 val_loss=13.0061 scale=1.0000 norm=0.0745\n",
      "[iter 2600] loss=13.0472 val_loss=13.0060 scale=1.0000 norm=0.0734\n",
      "[iter 2700] loss=13.0533 val_loss=13.0059 scale=1.0000 norm=0.0696\n",
      "[iter 2800] loss=13.0554 val_loss=13.0058 scale=1.0000 norm=0.0700\n",
      "[iter 2900] loss=13.0415 val_loss=13.0057 scale=2.0000 norm=0.1434\n",
      "[iter 3000] loss=13.0581 val_loss=13.0056 scale=2.0000 norm=0.1402\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL3077 (val_loss=13.0056)\n",
      "[iter 0] loss=13.1055 val_loss=13.0622 scale=1.0000 norm=0.3347\n",
      "[iter 100] loss=13.1243 val_loss=13.0551 scale=1.0000 norm=0.3012\n",
      "[iter 200] loss=13.0712 val_loss=13.0490 scale=1.0000 norm=0.2559\n",
      "[iter 300] loss=13.0724 val_loss=13.0433 scale=2.0000 norm=0.4613\n",
      "[iter 400] loss=13.0405 val_loss=13.0388 scale=2.0000 norm=0.3852\n",
      "[iter 500] loss=13.0746 val_loss=13.0341 scale=2.0000 norm=0.3343\n",
      "[iter 600] loss=13.0487 val_loss=13.0300 scale=2.0000 norm=0.3065\n",
      "[iter 700] loss=13.0322 val_loss=13.0264 scale=2.0000 norm=0.2829\n",
      "[iter 800] loss=13.0611 val_loss=13.0233 scale=2.0000 norm=0.2430\n",
      "[iter 900] loss=13.0561 val_loss=13.0207 scale=2.0000 norm=0.2314\n",
      "[iter 1000] loss=13.0504 val_loss=13.0185 scale=2.0000 norm=0.2146\n",
      "[iter 1100] loss=13.0124 val_loss=13.0167 scale=2.0000 norm=0.2026\n",
      "[iter 1200] loss=13.0452 val_loss=13.0152 scale=2.0000 norm=0.1886\n",
      "[iter 1300] loss=13.0511 val_loss=13.0139 scale=2.0000 norm=0.1884\n",
      "[iter 1400] loss=13.0391 val_loss=13.0129 scale=2.0000 norm=0.1729\n",
      "[iter 1500] loss=13.0446 val_loss=13.0121 scale=2.0000 norm=0.1635\n",
      "[iter 1600] loss=13.0502 val_loss=13.0114 scale=2.0000 norm=0.1746\n",
      "[iter 1700] loss=13.0498 val_loss=13.0108 scale=2.0000 norm=0.1707\n",
      "[iter 1800] loss=13.0266 val_loss=13.0103 scale=2.0000 norm=0.1658\n",
      "[iter 1900] loss=13.0380 val_loss=13.0099 scale=2.0000 norm=0.1580\n",
      "[iter 2000] loss=13.0174 val_loss=13.0095 scale=2.0000 norm=0.1595\n",
      "[iter 2100] loss=13.0669 val_loss=13.0092 scale=2.0000 norm=0.1533\n",
      "[iter 2200] loss=13.0375 val_loss=13.0090 scale=2.0000 norm=0.1514\n",
      "[iter 2300] loss=13.0537 val_loss=13.0088 scale=2.0000 norm=0.1519\n",
      "[iter 2400] loss=13.0329 val_loss=13.0086 scale=2.0000 norm=0.1505\n",
      "[iter 2500] loss=13.0168 val_loss=13.0084 scale=1.0000 norm=0.0734\n",
      "[iter 2600] loss=13.0329 val_loss=13.0083 scale=2.0000 norm=0.1522\n",
      "[iter 2700] loss=13.0287 val_loss=13.0082 scale=1.0000 norm=0.0701\n",
      "[iter 2800] loss=13.0460 val_loss=13.0081 scale=1.0000 norm=0.0696\n",
      "[iter 2900] loss=13.0418 val_loss=13.0079 scale=1.0000 norm=0.0720\n",
      "[iter 3000] loss=13.0263 val_loss=13.0078 scale=2.0000 norm=0.1412\n",
      "[iter 3100] loss=13.0402 val_loss=13.0078 scale=2.0000 norm=0.1369\n",
      "[iter 3200] loss=13.0363 val_loss=13.0077 scale=1.0000 norm=0.0699\n",
      "[iter 3300] loss=13.0419 val_loss=13.0076 scale=2.0000 norm=0.1360\n",
      "[iter 3400] loss=13.0449 val_loss=13.0076 scale=2.0000 norm=0.1397\n",
      "[iter 3500] loss=13.0396 val_loss=13.0075 scale=2.0000 norm=0.1304\n",
      "[iter 3600] loss=13.0229 val_loss=13.0075 scale=2.0000 norm=0.1387\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL3633 (val_loss=13.0075)\n",
      "[iter 0] loss=13.1174 val_loss=13.0626 scale=1.0000 norm=0.3367\n",
      "[iter 100] loss=13.1282 val_loss=13.0557 scale=1.0000 norm=0.3055\n",
      "[iter 200] loss=13.0808 val_loss=13.0485 scale=2.0000 norm=0.5168\n",
      "[iter 300] loss=13.0834 val_loss=13.0426 scale=2.0000 norm=0.4544\n",
      "[iter 400] loss=13.0574 val_loss=13.0368 scale=2.0000 norm=0.3656\n",
      "[iter 500] loss=13.0705 val_loss=13.0319 scale=2.0000 norm=0.3271\n",
      "[iter 600] loss=13.0551 val_loss=13.0278 scale=2.0000 norm=0.2955\n",
      "[iter 700] loss=13.0310 val_loss=13.0245 scale=2.0000 norm=0.2687\n",
      "[iter 800] loss=13.0540 val_loss=13.0215 scale=2.0000 norm=0.2443\n",
      "[iter 900] loss=13.0633 val_loss=13.0191 scale=2.0000 norm=0.2252\n",
      "[iter 1000] loss=13.0527 val_loss=13.0172 scale=2.0000 norm=0.2194\n",
      "[iter 1100] loss=13.0262 val_loss=13.0155 scale=2.0000 norm=0.2078\n",
      "[iter 1200] loss=13.0555 val_loss=13.0141 scale=2.0000 norm=0.1917\n",
      "[iter 1300] loss=13.0559 val_loss=13.0130 scale=2.0000 norm=0.1883\n",
      "[iter 1400] loss=13.0492 val_loss=13.0121 scale=2.0000 norm=0.1720\n",
      "[iter 1500] loss=13.0426 val_loss=13.0114 scale=2.0000 norm=0.1710\n",
      "[iter 1600] loss=13.0380 val_loss=13.0108 scale=2.0000 norm=0.1699\n",
      "[iter 1700] loss=13.0454 val_loss=13.0103 scale=2.0000 norm=0.1657\n",
      "[iter 1800] loss=13.0347 val_loss=13.0100 scale=2.0000 norm=0.1658\n",
      "[iter 1900] loss=13.0328 val_loss=13.0097 scale=2.0000 norm=0.1609\n",
      "[iter 2000] loss=13.0200 val_loss=13.0093 scale=2.0000 norm=0.1584\n",
      "[iter 2100] loss=13.0558 val_loss=13.0091 scale=2.0000 norm=0.1552\n",
      "[iter 2200] loss=13.0435 val_loss=13.0089 scale=2.0000 norm=0.1537\n",
      "[iter 2300] loss=13.0600 val_loss=13.0088 scale=2.0000 norm=0.1511\n",
      "[iter 2400] loss=13.0435 val_loss=13.0086 scale=2.0000 norm=0.1483\n",
      "[iter 2500] loss=13.0461 val_loss=13.0085 scale=1.0000 norm=0.0739\n",
      "[iter 2600] loss=13.0371 val_loss=13.0084 scale=2.0000 norm=0.1507\n",
      "[iter 2700] loss=13.0368 val_loss=13.0082 scale=2.0000 norm=0.1424\n",
      "[iter 2800] loss=13.0523 val_loss=13.0081 scale=2.0000 norm=0.1401\n",
      "[iter 2900] loss=13.0492 val_loss=13.0080 scale=2.0000 norm=0.1437\n",
      "[iter 3000] loss=13.0420 val_loss=13.0080 scale=2.0000 norm=0.1408\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL3042 (val_loss=13.0079)\n",
      "[iter 0] loss=13.1062 val_loss=13.0620 scale=1.0000 norm=0.3296\n",
      "[iter 100] loss=13.1106 val_loss=13.0542 scale=1.0000 norm=0.2947\n",
      "[iter 200] loss=13.0724 val_loss=13.0465 scale=2.0000 norm=0.4911\n",
      "[iter 300] loss=13.0742 val_loss=13.0404 scale=2.0000 norm=0.4352\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL341 (val_loss=13.0382)\n",
      "[iter 0] loss=13.0995 val_loss=13.0626 scale=1.0000 norm=0.3214\n",
      "[iter 100] loss=13.1158 val_loss=13.0546 scale=1.0000 norm=0.3008\n",
      "[iter 200] loss=13.1029 val_loss=13.0467 scale=2.0000 norm=0.5176\n",
      "[iter 300] loss=13.0780 val_loss=13.0399 scale=2.0000 norm=0.4367\n",
      "[iter 400] loss=13.0601 val_loss=13.0346 scale=2.0000 norm=0.3739\n",
      "[iter 500] loss=13.0664 val_loss=13.0296 scale=2.0000 norm=0.3456\n",
      "[iter 600] loss=13.0587 val_loss=13.0257 scale=2.0000 norm=0.2988\n",
      "[iter 700] loss=13.0389 val_loss=13.0226 scale=2.0000 norm=0.2727\n",
      "[iter 800] loss=13.0466 val_loss=13.0196 scale=2.0000 norm=0.2484\n",
      "[iter 900] loss=13.0518 val_loss=13.0175 scale=2.0000 norm=0.2219\n",
      "[iter 1000] loss=13.0407 val_loss=13.0155 scale=2.0000 norm=0.2170\n",
      "[iter 1100] loss=13.0447 val_loss=13.0140 scale=2.0000 norm=0.2091\n",
      "[iter 1200] loss=13.0618 val_loss=13.0127 scale=2.0000 norm=0.1980\n",
      "[iter 1300] loss=13.0545 val_loss=13.0117 scale=2.0000 norm=0.1821\n",
      "[iter 1400] loss=13.0654 val_loss=13.0108 scale=2.0000 norm=0.1723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 1500] loss=13.0487 val_loss=13.0101 scale=2.0000 norm=0.1806\n",
      "[iter 1600] loss=13.0284 val_loss=13.0096 scale=2.0000 norm=0.1734\n",
      "[iter 1700] loss=13.0255 val_loss=13.0091 scale=2.0000 norm=0.1708\n",
      "[iter 1800] loss=13.0417 val_loss=13.0087 scale=2.0000 norm=0.1701\n",
      "[iter 1900] loss=13.0436 val_loss=13.0084 scale=1.0000 norm=0.0834\n",
      "[iter 2000] loss=13.0149 val_loss=13.0081 scale=2.0000 norm=0.1679\n",
      "[iter 2100] loss=13.0402 val_loss=13.0079 scale=2.0000 norm=0.1653\n",
      "[iter 2200] loss=13.0449 val_loss=13.0077 scale=2.0000 norm=0.1576\n",
      "[iter 2300] loss=13.0481 val_loss=13.0075 scale=1.0000 norm=0.0777\n",
      "[iter 2400] loss=13.0441 val_loss=13.0074 scale=2.0000 norm=0.1604\n",
      "[iter 2500] loss=13.0433 val_loss=13.0073 scale=2.0000 norm=0.1490\n",
      "[iter 2600] loss=13.0414 val_loss=13.0072 scale=2.0000 norm=0.1626\n",
      "[iter 2700] loss=13.0392 val_loss=13.0070 scale=2.0000 norm=0.1525\n",
      "[iter 2800] loss=13.0429 val_loss=13.0069 scale=2.0000 norm=0.1485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:39:46,168]\u001b[0m Trial 2 finished with value: -1658465215.476712 and parameters: {'base_learner': 'DecTree_depth2', 'Dist': 'Exponential', 'n_estimators': 30050, 'minibatch_frac': 0.6244943204616877, 'learning_rate': 0.001342888372808318}. Best is trial 0 with value: -982517592.4782884.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL2885 (val_loss=13.0069)\n",
      "[iter 0] loss=12.5698 val_loss=12.4123 scale=1.0000 norm=0.6524\n",
      "[iter 100] loss=11.3604 val_loss=11.7615 scale=2.0000 norm=0.8729\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL115 (val_loss=11.7398)\n",
      "[iter 0] loss=12.5671 val_loss=12.4130 scale=1.0000 norm=0.6514\n",
      "[iter 100] loss=11.3732 val_loss=11.8293 scale=2.0000 norm=0.8783\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL110 (val_loss=11.8161)\n",
      "[iter 0] loss=12.5923 val_loss=12.4131 scale=1.0000 norm=0.6573\n",
      "[iter 100] loss=11.3979 val_loss=11.8869 scale=2.0000 norm=0.8811\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL110 (val_loss=11.8802)\n",
      "[iter 0] loss=12.5777 val_loss=12.4086 scale=1.0000 norm=0.6626\n",
      "[iter 100] loss=11.3681 val_loss=11.7930 scale=2.0000 norm=0.8799\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL115 (val_loss=11.7741)\n",
      "[iter 0] loss=12.5915 val_loss=12.4180 scale=1.0000 norm=0.6558\n",
      "[iter 100] loss=11.3987 val_loss=11.7981 scale=2.0000 norm=0.8819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:39:52,996]\u001b[0m Trial 3 finished with value: -1016135254.5126966 and parameters: {'base_learner': 'DecTree_depth5', 'Dist': 'LogNormal', 'n_estimators': 48397, 'minibatch_frac': 0.815053931146642, 'learning_rate': 0.011620994281146262}. Best is trial 0 with value: -982517592.4782884.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL115 (val_loss=11.7732)\n",
      "[iter 0] loss=12.5614 val_loss=12.4052 scale=2.0000 norm=1.2876\n",
      "[iter 100] loss=11.7472 val_loss=11.7804 scale=2.0000 norm=0.8768\n",
      "[iter 200] loss=11.1682 val_loss=11.4233 scale=2.0000 norm=0.8582\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL237 (val_loss=11.3906)\n",
      "[iter 0] loss=12.5386 val_loss=12.4071 scale=2.0000 norm=1.2627\n",
      "[iter 100] loss=11.7351 val_loss=11.8115 scale=2.0000 norm=0.8796\n",
      "[iter 200] loss=11.1800 val_loss=11.4814 scale=2.0000 norm=0.8692\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL229 (val_loss=11.4595)\n",
      "[iter 0] loss=12.5771 val_loss=12.4087 scale=2.0000 norm=1.2971\n",
      "[iter 100] loss=11.7416 val_loss=11.8009 scale=2.0000 norm=0.8830\n",
      "[iter 200] loss=11.1828 val_loss=11.4620 scale=2.0000 norm=0.8521\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL228 (val_loss=11.4442)\n",
      "[iter 0] loss=12.5677 val_loss=12.4027 scale=2.0000 norm=1.3094\n",
      "[iter 100] loss=11.7147 val_loss=11.7829 scale=2.0000 norm=0.8791\n",
      "[iter 200] loss=11.1598 val_loss=11.4381 scale=2.0000 norm=0.8386\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL237 (val_loss=11.4097)\n",
      "[iter 0] loss=12.5489 val_loss=12.4129 scale=2.0000 norm=1.2689\n",
      "[iter 100] loss=11.7444 val_loss=11.8038 scale=2.0000 norm=0.8951\n",
      "[iter 200] loss=11.2103 val_loss=11.4494 scale=2.0000 norm=0.8367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:41:11,872]\u001b[0m Trial 4 finished with value: -913623978.6309942 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 13401, 'minibatch_frac': 0.589057954626008, 'learning_rate': 0.007443427210302614}. Best is trial 4 with value: -913623978.6309942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL245 (val_loss=11.4120)\n",
      "[iter 0] loss=12.7401 val_loss=12.5298 scale=2.0000 norm=123010.2110\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL69 (val_loss=11.4587)\n",
      "[iter 0] loss=12.7404 val_loss=12.5344 scale=2.0000 norm=122229.1229\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL59 (val_loss=11.6529)\n",
      "[iter 0] loss=12.7474 val_loss=12.5332 scale=2.0000 norm=124106.7043\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL67 (val_loss=11.5385)\n",
      "[iter 0] loss=12.7061 val_loss=12.5121 scale=2.0000 norm=119328.6693\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL70 (val_loss=11.4243)\n",
      "[iter 0] loss=12.7258 val_loss=12.5314 scale=2.0000 norm=121297.9366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:42:26,403]\u001b[0m Trial 5 finished with value: -915836696.8694875 and parameters: {'base_learner': 'GradientBoost_depth5', 'Dist': 'Normal', 'n_estimators': 31356, 'minibatch_frac': 0.8279029318909668, 'learning_rate': 0.02287051529133464}. Best is trial 4 with value: -913623978.6309942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL68 (val_loss=11.4725)\n",
      "[iter 0] loss=12.7622 val_loss=12.5615 scale=1.0000 norm=61491.7830\n",
      "[iter 100] loss=12.0063 val_loss=12.1268 scale=2.0000 norm=48276.5585\n",
      "[iter 200] loss=11.4840 val_loss=11.7383 scale=2.0000 norm=22929.6241\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL282 (val_loss=11.6009)\n",
      "[iter 0] loss=12.7639 val_loss=12.5619 scale=1.0000 norm=61217.6751\n",
      "[iter 100] loss=11.9995 val_loss=12.1880 scale=2.0000 norm=47427.8283\n",
      "[iter 200] loss=11.4716 val_loss=11.8380 scale=2.0000 norm=22225.6771\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL261 (val_loss=11.7524)\n",
      "[iter 0] loss=12.7708 val_loss=12.5657 scale=1.0000 norm=61902.9648\n",
      "[iter 100] loss=12.0291 val_loss=12.1899 scale=2.0000 norm=50287.9764\n",
      "[iter 200] loss=11.4954 val_loss=11.8470 scale=2.0000 norm=23074.8481\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL256 (val_loss=11.7772)\n",
      "[iter 0] loss=12.7052 val_loss=12.5374 scale=1.0000 norm=59384.2091\n",
      "[iter 100] loss=11.9682 val_loss=12.1151 scale=2.0000 norm=47371.3100\n",
      "[iter 200] loss=11.4364 val_loss=11.7295 scale=2.0000 norm=21579.1917\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL286 (val_loss=11.5829)\n",
      "[iter 0] loss=12.7630 val_loss=12.5619 scale=1.0000 norm=61559.6363\n",
      "[iter 100] loss=12.0211 val_loss=12.1631 scale=2.0000 norm=49553.1359\n",
      "[iter 200] loss=11.4891 val_loss=11.7797 scale=2.0000 norm=23079.2440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:42:41,287]\u001b[0m Trial 6 finished with value: -991800545.1810688 and parameters: {'base_learner': 'DecTree_depth5', 'Dist': 'Normal', 'n_estimators': 15267, 'minibatch_frac': 0.9540494129922555, 'learning_rate': 0.005775585261760808}. Best is trial 4 with value: -913623978.6309942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL286 (val_loss=11.6351)\n",
      "[iter 0] loss=13.1315 val_loss=13.0629 scale=1.0000 norm=0.3303\n",
      "[iter 100] loss=13.0920 val_loss=13.0392 scale=2.0000 norm=0.4569\n",
      "[iter 200] loss=13.0705 val_loss=13.0258 scale=2.0000 norm=0.3269\n",
      "[iter 300] loss=13.0605 val_loss=13.0185 scale=2.0000 norm=0.2390\n",
      "[iter 400] loss=13.0572 val_loss=13.0143 scale=2.0000 norm=0.1751\n",
      "[iter 500] loss=13.0548 val_loss=13.0116 scale=2.0000 norm=0.1305\n",
      "[iter 600] loss=13.0542 val_loss=13.0099 scale=2.0000 norm=0.0989\n",
      "[iter 700] loss=13.0506 val_loss=13.0086 scale=2.0000 norm=0.0783\n",
      "[iter 800] loss=13.0479 val_loss=13.0078 scale=2.0000 norm=0.0626\n",
      "[iter 900] loss=13.0469 val_loss=13.0073 scale=2.0000 norm=0.0521\n",
      "[iter 0] loss=13.1216 val_loss=13.0621 scale=1.0000 norm=0.3330\n",
      "[iter 100] loss=13.0796 val_loss=13.0398 scale=2.0000 norm=0.4587\n",
      "[iter 200] loss=13.0572 val_loss=13.0280 scale=2.0000 norm=0.3284\n",
      "[iter 300] loss=13.0430 val_loss=13.0213 scale=2.0000 norm=0.2410\n",
      "[iter 400] loss=13.0412 val_loss=13.0173 scale=2.0000 norm=0.1774\n",
      "[iter 500] loss=13.0421 val_loss=13.0147 scale=2.0000 norm=0.1314\n",
      "[iter 600] loss=13.0387 val_loss=13.0129 scale=2.0000 norm=0.1010\n",
      "[iter 700] loss=13.0347 val_loss=13.0117 scale=2.0000 norm=0.0793\n",
      "[iter 800] loss=13.0353 val_loss=13.0108 scale=2.0000 norm=0.0629\n",
      "[iter 900] loss=13.0324 val_loss=13.0102 scale=2.0000 norm=0.0522\n",
      "[iter 0] loss=13.1252 val_loss=13.0623 scale=2.0000 norm=0.6672\n",
      "[iter 100] loss=13.0868 val_loss=13.0401 scale=2.0000 norm=0.4632\n",
      "[iter 200] loss=13.0623 val_loss=13.0286 scale=2.0000 norm=0.3295\n",
      "[iter 300] loss=13.0489 val_loss=13.0217 scale=2.0000 norm=0.2430\n",
      "[iter 400] loss=13.0460 val_loss=13.0175 scale=2.0000 norm=0.1794\n",
      "[iter 500] loss=13.0479 val_loss=13.0147 scale=2.0000 norm=0.1337\n",
      "[iter 600] loss=13.0445 val_loss=13.0127 scale=2.0000 norm=0.1019\n",
      "[iter 700] loss=13.0403 val_loss=13.0114 scale=2.0000 norm=0.0806\n",
      "[iter 800] loss=13.0376 val_loss=13.0104 scale=2.0000 norm=0.0643\n",
      "[iter 900] loss=13.0360 val_loss=13.0098 scale=2.0000 norm=0.0531\n",
      "[iter 0] loss=13.1159 val_loss=13.0616 scale=2.0000 norm=0.6467\n",
      "[iter 100] loss=13.0801 val_loss=13.0377 scale=2.0000 norm=0.4443\n",
      "[iter 200] loss=13.0552 val_loss=13.0263 scale=2.0000 norm=0.3172\n",
      "[iter 300] loss=13.0448 val_loss=13.0198 scale=2.0000 norm=0.2329\n",
      "[iter 400] loss=13.0392 val_loss=13.0156 scale=2.0000 norm=0.1745\n",
      "[iter 500] loss=13.0413 val_loss=13.0128 scale=2.0000 norm=0.1295\n",
      "[iter 600] loss=13.0386 val_loss=13.0110 scale=2.0000 norm=0.0991\n",
      "[iter 700] loss=13.0323 val_loss=13.0097 scale=2.0000 norm=0.0787\n",
      "[iter 800] loss=13.0300 val_loss=13.0089 scale=2.0000 norm=0.0629\n",
      "[iter 900] loss=13.0277 val_loss=13.0083 scale=2.0000 norm=0.0527\n",
      "[iter 0] loss=13.1266 val_loss=13.0625 scale=1.0000 norm=0.3333\n",
      "[iter 100] loss=13.0872 val_loss=13.0386 scale=2.0000 norm=0.4599\n",
      "[iter 200] loss=13.0633 val_loss=13.0267 scale=2.0000 norm=0.3282\n",
      "[iter 300] loss=13.0536 val_loss=13.0201 scale=2.0000 norm=0.2402\n",
      "[iter 400] loss=13.0393 val_loss=13.0161 scale=2.0000 norm=0.1793\n",
      "[iter 500] loss=13.0459 val_loss=13.0135 scale=2.0000 norm=0.1332\n",
      "[iter 600] loss=13.0451 val_loss=13.0117 scale=2.0000 norm=0.1018\n",
      "[iter 700] loss=13.0366 val_loss=13.0105 scale=2.0000 norm=0.0807\n",
      "[iter 800] loss=13.0377 val_loss=13.0097 scale=2.0000 norm=0.0643\n",
      "[iter 900] loss=13.0341 val_loss=13.0091 scale=2.0000 norm=0.0538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:51:07,173]\u001b[0m Trial 7 finished with value: -938623276.1136224 and parameters: {'base_learner': 'GradientBoost_depth5', 'Dist': 'Exponential', 'n_estimators': 967, 'minibatch_frac': 0.9688419571551059, 'learning_rate': 0.0018208405046365333}. Best is trial 4 with value: -913623978.6309942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=12.7258 val_loss=12.5276 scale=1.0000 norm=61012.2551\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL59 (val_loss=11.6895)\n",
      "[iter 0] loss=12.7199 val_loss=12.5783 scale=1.0000 norm=60305.6002\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL32 (val_loss=12.1672)\n",
      "[iter 0] loss=12.7375 val_loss=12.5435 scale=1.0000 norm=61329.2653\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL63 (val_loss=11.8202)\n",
      "[iter 0] loss=12.6911 val_loss=12.5069 scale=1.0000 norm=59861.7434\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL53 (val_loss=11.7132)\n",
      "[iter 0] loss=12.7080 val_loss=12.5294 scale=1.0000 norm=60186.8665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:51:08,711]\u001b[0m Trial 8 finished with value: -1154413557.0301154 and parameters: {'base_learner': 'DecTree_depth2', 'Dist': 'Normal', 'n_estimators': 1540, 'minibatch_frac': 0.49445317217518253, 'learning_rate': 0.05002839091595205}. Best is trial 4 with value: -913623978.6309942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL39 (val_loss=12.0340)\n",
      "[iter 0] loss=12.7350 val_loss=12.5644 scale=1.0000 norm=61646.1121\n",
      "[iter 100] loss=12.3830 val_loss=12.4033 scale=2.0000 norm=88727.7258\n",
      "[iter 200] loss=12.1646 val_loss=12.2429 scale=2.0000 norm=61571.6164\n",
      "[iter 300] loss=11.9788 val_loss=12.0870 scale=2.0000 norm=45458.4435\n",
      "[iter 400] loss=11.8078 val_loss=11.9404 scale=2.0000 norm=34833.9613\n",
      "[iter 500] loss=11.6476 val_loss=11.8077 scale=2.0000 norm=29383.4492\n",
      "[iter 600] loss=11.4607 val_loss=11.6955 scale=2.0000 norm=22527.0800\n",
      "[iter 700] loss=11.3062 val_loss=11.6085 scale=2.0000 norm=20668.4343\n",
      "[iter 800] loss=11.1707 val_loss=11.5539 scale=2.0000 norm=19615.0912\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL881 (val_loss=11.5409)\n",
      "[iter 0] loss=12.7365 val_loss=12.5627 scale=1.0000 norm=61005.9811\n",
      "[iter 100] loss=12.3840 val_loss=12.4376 scale=2.0000 norm=88495.1351\n",
      "[iter 200] loss=12.1742 val_loss=12.2919 scale=2.0000 norm=62182.1439\n",
      "[iter 300] loss=11.9987 val_loss=12.1597 scale=2.0000 norm=48133.2985\n",
      "[iter 400] loss=11.8014 val_loss=12.0260 scale=2.0000 norm=34156.9071\n",
      "[iter 500] loss=11.6369 val_loss=11.9121 scale=2.0000 norm=28601.8147\n",
      "[iter 600] loss=11.4630 val_loss=11.8264 scale=2.0000 norm=23148.5315\n",
      "[iter 700] loss=11.2957 val_loss=11.7782 scale=2.0000 norm=19985.9008\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL712 (val_loss=11.7740)\n",
      "[iter 0] loss=12.7484 val_loss=12.5667 scale=1.0000 norm=61783.8955\n",
      "[iter 100] loss=12.4170 val_loss=12.4330 scale=2.0000 norm=93638.6912\n",
      "[iter 200] loss=12.2046 val_loss=12.2790 scale=2.0000 norm=67430.1607\n",
      "[iter 300] loss=12.0245 val_loss=12.1280 scale=2.0000 norm=50597.3772\n",
      "[iter 400] loss=11.8112 val_loss=11.9860 scale=2.0000 norm=34632.6557\n",
      "[iter 500] loss=11.6552 val_loss=11.8569 scale=2.0000 norm=29836.6217\n",
      "[iter 600] loss=11.4805 val_loss=11.7494 scale=2.0000 norm=24133.1671\n",
      "[iter 700] loss=11.3069 val_loss=11.6699 scale=2.0000 norm=20286.2966\n",
      "[iter 800] loss=11.1833 val_loss=11.6246 scale=2.0000 norm=19544.3325\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL842 (val_loss=11.6179)\n",
      "[iter 0] loss=12.7091 val_loss=12.5408 scale=1.0000 norm=59979.9354\n",
      "[iter 100] loss=12.3630 val_loss=12.3942 scale=2.0000 norm=89099.9706\n",
      "[iter 200] loss=12.1379 val_loss=12.2350 scale=2.0000 norm=61503.1335\n",
      "[iter 300] loss=11.9702 val_loss=12.0811 scale=2.0000 norm=48253.9954\n",
      "[iter 400] loss=11.7571 val_loss=11.9336 scale=2.0000 norm=33238.8588\n",
      "[iter 500] loss=11.6015 val_loss=11.7965 scale=2.0000 norm=28344.9336\n",
      "[iter 600] loss=11.4319 val_loss=11.6798 scale=2.0000 norm=22899.5541\n",
      "[iter 700] loss=11.2471 val_loss=11.5874 scale=2.0000 norm=18931.8472\n",
      "[iter 800] loss=11.1152 val_loss=11.5278 scale=2.0000 norm=17729.9989\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL888 (val_loss=11.5082)\n",
      "[iter 0] loss=12.6939 val_loss=12.5643 scale=1.0000 norm=59238.4021\n",
      "[iter 100] loss=12.4194 val_loss=12.4410 scale=2.0000 norm=94652.1216\n",
      "[iter 200] loss=12.2009 val_loss=12.2881 scale=2.0000 norm=66923.3855\n",
      "[iter 300] loss=12.0133 val_loss=12.1369 scale=2.0000 norm=48381.5230\n",
      "[iter 400] loss=11.8089 val_loss=11.9926 scale=2.0000 norm=35686.2094\n",
      "[iter 500] loss=11.6622 val_loss=11.8586 scale=2.0000 norm=30873.8587\n",
      "[iter 600] loss=11.4816 val_loss=11.7464 scale=2.0000 norm=24678.7093\n",
      "[iter 700] loss=11.3151 val_loss=11.6544 scale=2.0000 norm=21070.5871\n",
      "[iter 800] loss=11.1706 val_loss=11.5958 scale=2.0000 norm=18844.3089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:51:41,766]\u001b[0m Trial 9 finished with value: -955606041.3322674 and parameters: {'base_learner': 'DecTree_depth5', 'Dist': 'Normal', 'n_estimators': 9160, 'minibatch_frac': 0.5700684725641546, 'learning_rate': 0.001972024099562782}. Best is trial 4 with value: -913623978.6309942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL872 (val_loss=11.5786)\n",
      "[iter 0] loss=12.5707 val_loss=12.2929 scale=2.0000 norm=1.2897\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL17 (val_loss=11.4265)\n",
      "[iter 0] loss=12.5273 val_loss=12.3051 scale=2.0000 norm=1.2503\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL17 (val_loss=11.4287)\n",
      "[iter 0] loss=12.5622 val_loss=12.3286 scale=2.0000 norm=1.2836\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL17 (val_loss=11.4408)\n",
      "[iter 0] loss=12.5311 val_loss=12.3179 scale=2.0000 norm=1.2376\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL17 (val_loss=11.4340)\n",
      "[iter 0] loss=12.5558 val_loss=12.3138 scale=2.0000 norm=1.2370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:51:47,557]\u001b[0m Trial 10 finished with value: -883653368.6968629 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 18765, 'minibatch_frac': 0.4123721284410168, 'learning_rate': 0.09417560187424806}. Best is trial 10 with value: -883653368.6968629.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL20 (val_loss=11.4127)\n",
      "[iter 0] loss=12.5709 val_loss=12.2922 scale=2.0000 norm=1.2889\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL18 (val_loss=11.3673)\n",
      "[iter 0] loss=12.5325 val_loss=12.3131 scale=2.0000 norm=1.2451\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL17 (val_loss=11.4382)\n",
      "[iter 0] loss=12.5703 val_loss=12.3450 scale=2.0000 norm=1.2831\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL21 (val_loss=11.4072)\n",
      "[iter 0] loss=12.5422 val_loss=12.3041 scale=2.0000 norm=1.2420\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL18 (val_loss=11.4089)\n",
      "[iter 0] loss=12.5632 val_loss=12.3070 scale=2.0000 norm=1.2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:51:53,450]\u001b[0m Trial 11 finished with value: -882124430.7774332 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 18044, 'minibatch_frac': 0.4008902175258032, 'learning_rate': 0.09147517256702006}. Best is trial 11 with value: -882124430.7774332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL20 (val_loss=11.4070)\n",
      "[iter 0] loss=12.5707 val_loss=12.2949 scale=2.0000 norm=1.2875\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL18 (val_loss=11.3681)\n",
      "[iter 0] loss=12.5300 val_loss=12.3213 scale=2.0000 norm=1.2477\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL17 (val_loss=11.4723)\n",
      "[iter 0] loss=12.5652 val_loss=12.3303 scale=2.0000 norm=1.2815\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL17 (val_loss=11.4221)\n",
      "[iter 0] loss=12.5373 val_loss=12.2946 scale=2.0000 norm=1.2410\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL18 (val_loss=11.3396)\n",
      "[iter 0] loss=12.5591 val_loss=12.2995 scale=2.0000 norm=1.2411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:51:59,260]\u001b[0m Trial 12 finished with value: -839782425.3162731 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 20872, 'minibatch_frac': 0.40746035676868947, 'learning_rate': 0.09725433680775422}. Best is trial 12 with value: -839782425.3162731.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL21 (val_loss=11.3886)\n",
      "[iter 0] loss=12.5707 val_loss=12.2934 scale=2.0000 norm=1.2875\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL17 (val_loss=11.3652)\n",
      "[iter 0] loss=12.5300 val_loss=12.3201 scale=2.0000 norm=1.2477\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL17 (val_loss=11.4939)\n",
      "[iter 0] loss=12.5652 val_loss=12.3292 scale=2.0000 norm=1.2815\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL17 (val_loss=11.4009)\n",
      "[iter 0] loss=12.5373 val_loss=12.2931 scale=2.0000 norm=1.2410\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL17 (val_loss=11.3469)\n",
      "[iter 0] loss=12.5591 val_loss=12.2979 scale=2.0000 norm=1.2411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:52:05,062]\u001b[0m Trial 13 finished with value: -847551456.3812597 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 21890, 'minibatch_frac': 0.40716888076951757, 'learning_rate': 0.09889559588555788}. Best is trial 12 with value: -839782425.3162731.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL20 (val_loss=11.3993)\n",
      "[iter 0] loss=12.5547 val_loss=12.3454 scale=2.0000 norm=1.2868\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL36 (val_loss=11.4140)\n",
      "[iter 0] loss=12.5320 val_loss=12.3492 scale=2.0000 norm=1.2620\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL33 (val_loss=11.4364)\n",
      "[iter 0] loss=12.5804 val_loss=12.3514 scale=2.0000 norm=1.3117\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL36 (val_loss=11.4067)\n",
      "[iter 0] loss=12.5525 val_loss=12.3467 scale=2.0000 norm=1.2873\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL36 (val_loss=11.3889)\n",
      "[iter 0] loss=12.5619 val_loss=12.3685 scale=2.0000 norm=1.2747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:52:17,113]\u001b[0m Trial 14 finished with value: -885386501.6433289 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 24367, 'minibatch_frac': 0.5044246268912617, 'learning_rate': 0.0473579561407795}. Best is trial 12 with value: -839782425.3162731.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL39 (val_loss=11.4047)\n",
      "[iter 0] loss=12.5740 val_loss=12.3491 scale=2.0000 norm=1.2885\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL42 (val_loss=11.3858)\n",
      "[iter 0] loss=12.5333 val_loss=12.3637 scale=2.0000 norm=1.2487\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL39 (val_loss=11.4387)\n",
      "[iter 0] loss=12.5709 val_loss=12.3727 scale=2.0000 norm=1.2865\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL39 (val_loss=11.4023)\n",
      "[iter 0] loss=12.5429 val_loss=12.3535 scale=2.0000 norm=1.2456\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL44 (val_loss=11.3846)\n",
      "[iter 0] loss=12.5638 val_loss=12.3671 scale=2.0000 norm=1.2440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:52:28,472]\u001b[0m Trial 15 finished with value: -903438357.270965 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 26009, 'minibatch_frac': 0.40179068247417593, 'learning_rate': 0.04245773742181925}. Best is trial 12 with value: -839782425.3162731.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL42 (val_loss=11.3988)\n",
      "[iter 0] loss=13.1160 val_loss=13.0464 scale=2.0000 norm=0.6560\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL22 (val_loss=13.0035)\n",
      "[iter 0] loss=13.0965 val_loss=13.0462 scale=2.0000 norm=0.6589\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL26 (val_loss=13.0045)\n",
      "[iter 0] loss=13.1092 val_loss=13.0462 scale=2.0000 norm=0.6616\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL26 (val_loss=13.0039)\n",
      "[iter 0] loss=13.1033 val_loss=13.0444 scale=2.0000 norm=0.6500\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL26 (val_loss=13.0035)\n",
      "[iter 0] loss=13.1103 val_loss=13.0446 scale=2.0000 norm=0.6446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:52:33,412]\u001b[0m Trial 16 finished with value: -919178361.884399 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'Exponential', 'n_estimators': 7569, 'minibatch_frac': 0.5258601707695173, 'learning_rate': 0.09876934600452908}. Best is trial 12 with value: -839782425.3162731.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL26 (val_loss=13.0035)\n",
      "[iter 0] loss=12.5743 val_loss=12.3721 scale=2.0000 norm=1.3058\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL66 (val_loss=11.4048)\n",
      "[iter 0] loss=12.5711 val_loss=12.3750 scale=2.0000 norm=1.3077\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL63 (val_loss=11.5017)\n",
      "[iter 0] loss=12.5924 val_loss=12.3833 scale=2.0000 norm=1.3117\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL63 (val_loss=11.4617)\n",
      "[iter 0] loss=12.5803 val_loss=12.3719 scale=2.0000 norm=1.3278\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL65 (val_loss=11.4277)\n",
      "[iter 0] loss=12.5980 val_loss=12.3842 scale=2.0000 norm=1.3184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:53:01,119]\u001b[0m Trial 17 finished with value: -929319563.0802523 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 22875, 'minibatch_frac': 0.7235456091583856, 'learning_rate': 0.025626019034005947}. Best is trial 12 with value: -839782425.3162731.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL68 (val_loss=11.4282)\n",
      "[iter 0] loss=12.5739 val_loss=12.4114 scale=2.0000 norm=1.3256\n",
      "[iter 100] loss=12.0199 val_loss=12.0167 scale=2.0000 norm=0.8926\n",
      "[iter 200] loss=11.6297 val_loss=11.7131 scale=2.0000 norm=0.8828\n",
      "[iter 300] loss=11.3137 val_loss=11.4891 scale=2.0000 norm=0.8843\n",
      "[iter 400] loss=11.1033 val_loss=11.3837 scale=2.0000 norm=0.8850\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL438 (val_loss=11.3731)\n",
      "[iter 0] loss=12.5226 val_loss=12.4121 scale=2.0000 norm=1.2477\n",
      "[iter 100] loss=12.0057 val_loss=12.0333 scale=2.0000 norm=0.8946\n",
      "[iter 200] loss=11.6455 val_loss=11.7387 scale=2.0000 norm=0.8793\n",
      "[iter 300] loss=11.3282 val_loss=11.5221 scale=2.0000 norm=0.8806\n",
      "[iter 400] loss=11.0858 val_loss=11.4290 scale=2.0000 norm=0.8786\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL419 (val_loss=11.4253)\n",
      "[iter 0] loss=12.5568 val_loss=12.4157 scale=2.0000 norm=1.2777\n",
      "[iter 100] loss=12.0440 val_loss=12.0295 scale=2.0000 norm=0.9008\n",
      "[iter 200] loss=11.6462 val_loss=11.7252 scale=2.0000 norm=0.8737\n",
      "[iter 300] loss=11.3350 val_loss=11.5037 scale=2.0000 norm=0.8677\n",
      "[iter 400] loss=11.0771 val_loss=11.4103 scale=2.0000 norm=0.8509\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL415 (val_loss=11.4069)\n",
      "[iter 0] loss=12.5258 val_loss=12.4096 scale=2.0000 norm=1.2419\n",
      "[iter 100] loss=12.0003 val_loss=12.0116 scale=2.0000 norm=0.8992\n",
      "[iter 200] loss=11.6076 val_loss=11.7102 scale=2.0000 norm=0.8740\n",
      "[iter 300] loss=11.3295 val_loss=11.4908 scale=2.0000 norm=0.8565\n",
      "[iter 400] loss=11.0678 val_loss=11.3913 scale=2.0000 norm=0.8115\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL426 (val_loss=11.3854)\n",
      "[iter 0] loss=12.5384 val_loss=12.4178 scale=2.0000 norm=1.2181\n",
      "[iter 100] loss=12.0301 val_loss=12.0358 scale=2.0000 norm=0.9154\n",
      "[iter 200] loss=11.6592 val_loss=11.7324 scale=2.0000 norm=0.8727\n",
      "[iter 300] loss=11.3656 val_loss=11.5091 scale=2.0000 norm=0.8680\n",
      "[iter 400] loss=11.0981 val_loss=11.4020 scale=2.0000 norm=0.8041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:54:48,670]\u001b[0m Trial 18 finished with value: -902679384.7894685 and parameters: {'base_learner': 'GradientBoost_depth2', 'Dist': 'LogNormal', 'n_estimators': 35777, 'minibatch_frac': 0.447676221891831, 'learning_rate': 0.004275250562539325}. Best is trial 12 with value: -839782425.3162731.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL433 (val_loss=11.3943)\n",
      "[iter 0] loss=12.5646 val_loss=12.3411 scale=2.0000 norm=1.2950\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL19 (val_loss=11.6639)\n",
      "[iter 0] loss=12.5644 val_loss=12.3621 scale=2.0000 norm=1.3095\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL16 (val_loss=11.8389)\n",
      "[iter 0] loss=12.5865 val_loss=12.3386 scale=2.0000 norm=1.3169\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL18 (val_loss=11.6800)\n",
      "[iter 0] loss=12.5776 val_loss=12.3565 scale=2.0000 norm=1.3359\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL19 (val_loss=11.7163)\n",
      "[iter 0] loss=12.5717 val_loss=12.3611 scale=2.0000 norm=1.3024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-01 19:54:51,109]\u001b[0m Trial 19 finished with value: -1027735212.3609196 and parameters: {'base_learner': 'DecTree_depthNone', 'Dist': 'LogNormal', 'n_estimators': 21262, 'minibatch_frac': 0.6416818354150133, 'learning_rate': 0.061151242718555314}. Best is trial 12 with value: -839782425.3162731.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Early stopping achieved.\n",
      "== Best iteration / VAL18 (val_loss=11.8152)\n",
      "[iter 0] loss=12.5958 val_loss=12.3067 scale=2.0000 norm=1.3252\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL17 (val_loss=11.3779)\n",
      "Started Predict with Ngboost at 19:54:53.\n",
      "The R2 score is 0.8820978416974048\n",
      "The MAE score is 14927.931999567378\n",
      "The Median absolute error score is 10130.38403799045\n",
      "The MSE score is 22189.724591573104\n",
      "The RMSE score is 492383877.4498642\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this case we chose Ngboost, which is uses natural gradient. It is really strong for regression problem, but\n",
    "does not have GPU acceleration at all unfortunately. However we always recommend trying Ngboost if possible.\n",
    "\"\"\"\n",
    "housing_ml.ml_bp14_regressions_full_processing_ngboost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pipeline\n",
    "save_to_production(housing_ml, file_name='housing_automl_instance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on new data\n",
    "In the beginning we kept a holdout dataset. We use this to simulate prediction on completely new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stored pipeline\n",
    "housing_ml_loaded = load_for_production(file_name='housing_automl_instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Execute test train split at 19:54:53.\n",
      "Started Apply datetime transformation at 19:54:53.\n",
      "Started Start Spacy, POS tagging at 19:54:53.\n",
      "Started Handle rare features at 19:54:53.\n",
      "Started Remove cardinality at 19:54:53.\n",
      "Started Onehot + PCA categorical features at 19:54:53.\n",
      "Started Execute categorical encoding at 19:54:53.\n",
      "Started  Delete columns with high share of NULLs at 19:54:53.\n",
      "Started Fill nulls at 19:54:53.\n",
      "Started Execute numerical binning at 19:54:53.\n",
      "Started Handle outliers at 19:54:53.\n",
      "Started Remove collinearity at 19:54:53.\n",
      "Started Execute clustering as a feature at 19:54:53.\n",
      "Started Execute clustering as a feature at 19:54:53.\n",
      "Started Execute clustering as a feature at 19:54:53.\n",
      "Started Execute clustering as a feature at 19:54:53.\n",
      "Started Execute clustering as a feature at 19:54:54.\n",
      "Started Execute clustering as a feature at 19:54:54.\n",
      "Started Execute clustering as a feature at 19:54:54.\n",
      "Started Execute clustering as a feature at 19:54:54.\n",
      "Started Execute clustering as a feature at 19:54:54.\n",
      "Started Select best features at 19:54:54.\n",
      "Started Sort columns alphabetically at 19:54:54.\n",
      "Started Predict with Ngboost at 19:54:54.\n"
     ]
    }
   ],
   "source": [
    "# predict on new data\n",
    "housing_ml_loaded.ml_bp14_regressions_full_processing_ngboost(val_df, preprocessing_type='full')\n",
    "\n",
    "# access predicted labels\n",
    "val_y_hat = housing_ml_loaded.predicted_values['ngboost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15740.063154203399\n"
     ]
    }
   ],
   "source": [
    "# Assess prediction quality on holdout data\n",
    "mae = mean_absolute_error(val_df_target, val_y_hat)\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
